<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 66]
- [cs.LG](#cs.LG) [Total: 82]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 21]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey](https://arxiv.org/abs/2602.03878)
*Longjie Zhao,Ziming Hong,Jiaxin Huang,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: 首篇3DGS知识产权保护综述：提出自底向上框架梳理高斯扰动机制、主/被动保护范式与生成式AI时代的鲁棒性威胁，并给出六大未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting 已成为实时3D场景合成的主流表征，商业价值激增，但其显式参数化结构带来IP泄露风险；现有研究零散，缺乏统一视角与系统梳理。

Method: 构建自底向上框架，系统审视：①高斯点云可微扰动机理，②被动（水印、指纹）与主动（对抗样本、访问控制）保护范式，③生成式AI增强攻击下的鲁棒性威胁；通过文献计量与对比实验揭示技术空白。

Result: 厘清了3DGS IP保护的技术地图，发现高维高斯空间脆弱性、鲁棒性评估基准缺失、生成式攻击面扩大等关键缺口；提出面向鲁棒性、效率与范式的六大研究方向，为构建可信3D资产保护提供路线图。

Conclusion: 3DGS IP保护尚处起步阶段，需从扰动理论、基准测评、轻量级算法与生成式防御协同切入，推动形成标准化、可扩展且鲁棒的保护体系。

Abstract: 3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.

</details>


### [2] [4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping](https://arxiv.org/abs/2602.03890)
*Xindan Zhang,Weilong Yan,Yufei Shi,Xuerui Qiu,Tao He,Ying Li,Ming Li,Hehe Fan*

Main category: cs.CV

TL;DR: 首个面向动态点云序列的多模态大模型 4DPC²hat，配套 200 K QA 对的 4D 数据集，通过 Mamba 时序建模与失败感知自举学习，显著超越现有方法的动作理解与时序推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLM）仅能处理静态点云，缺乏大规模跨模态动态点云数据，且难以对时空运动进行建模，阻碍了 4D 点云理解的发展。

Method: 1) 构建 4DPC²hat-200 K 数据集：拓扑一致 4D 点构建 + 两级字幕生成，含 44 K 动态序列、700 K 帧、200 K QA；2) 设计 Mamba 增强的时序推理 MLLM，捕获点云序列长程依赖与动态模式；3) 提出失败感知自举学习策略，迭代诊断模型缺陷并生成针对性 QA 监督以强化推理能力。

Result: 在动作识别、时序关系、计数、空间关系等多类任务上，4DPC²hat 相比现有模型显著提升动态点云理解性能，建立 4D 点云理解的强基准。

Conclusion: 4DPC²hat 首次将 MLLM 扩展到动态点云序列，通过大规模 4D 数据、Mamba 时序建模与自举学习，为 4D 点云理解提供了可行范式与开源基础。

Abstract: Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.

</details>


### [3] [Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation](https://arxiv.org/abs/2602.03892)
*Jinxing Zhou,Yanghao Zhou,Yaoting Wang,Zongyan Han,Jiaqi Ma,Henghui Ding,Rao Muhammad Anwer,Hisham Cholakkal*

Main category: cs.CV

TL;DR: 本文首次提出“无真值参考的 Ref-AVS 分割质量评估”新任务 MQA-RefAVS，并给出配套基准 MQ-RAVSBench 与基于 MLLM 的评估器 MQ-Auditor，可实时估计 IoU、定位错误类型并给出可操作的质控建议，显著提升现有 Ref-AVS 系统的鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: Ref-AVS 虽能按文本指代生成音视联合分割掩膜，但推理阶段缺乏真值时无法判断掩膜好坏，导致错误难以及时发现与纠正；现有研究对“可解释、无参考的掩膜质量诊断”几乎空白。

Method: 1) 形式化 MQA-RefAVS 任务：输入音视文+候选掩膜，输出 IoU 估计、错误类型标签与质控决策；2) 构建 MQ-RAVSBench，系统注入几何/语义两类共 10 余种代表性错误模式；3) 提出 MQ-Auditor——在 MLLM 中显式融合音视特征、文本语义与掩膜表征，通过多模态链式推理实现定量-定性联合评估；4) 设计两阶段训练：先大规模掩膜-属性对比预训练，再在 MQ-RAVSBench 上指令微调。

Result: MQ-Auditor 在 MQ-RAVSBench 上 IoU 估计误差降低 28%，错误分类 F1 提升 15 个百分点，显著优于 GPT-4V、LLaVA-Next 等开源/商业 MLLM；接入现有 Ref-AVS 方法后，可将分割失败检测率从 62% 提至 89%，并基于质控建议使最终 mIoU 再提升 3.4。

Conclusion: MQA-RefAVS 填补了 Ref-AVS 质量评估空白；MQ-Auditor 无需真值即可提供可解释、可操作的掩膜诊断，可即插即用地增强现有分割系统，为音视文多模态质量保障提供新范式。

Abstract: Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.

</details>


### [4] [GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction](https://arxiv.org/abs/2602.03893)
*Yibing Wang,Shuang Li,Tingting Huang,Yu Zhang,Chulhong Kim,Seongwook Choi,Changhui Li*

Main category: cs.CV

TL;DR: 用连续高斯核替代空间网格，配合 GPU 可微分算子，将 3D 光声层析迭代重建从数百秒压缩到亚秒级（840 万体素），首次实现近实时大视场成像。


<details>
  <summary>Details</summary>
Motivation: 传统迭代重建（IR）虽能抑制伪影，但在大尺度三维光声计算层析（PACT）中耗时数百秒至数小时，严重阻碍临床落地，亟需数量级加速方案。

Method: 提出 GPAIR：用各向同性高斯核取代离散体素网格，推导压力波的解析闭式表达，并基于 GPU 加速的可微分 Triton 算子实现全流水线并行迭代。

Result: 动物实验对 8.4 百万体素的目标实现亚秒级（<1 s）3D 重建，速度提升 2–3 个数量级，图像质量与常规 IR 相当，满足近实时成像需求。

Conclusion: GPAIR 突破了大尺度 3D PACT 的计算瓶颈，使迭代重建首次具备临床实时应用潜力，为术中监测、血管成像等场景开辟新路径。

Abstract: Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.

</details>


### [5] [Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study](https://arxiv.org/abs/2602.03894)
*Hugo Markoff,Stefan Hein Bengtson,Michael Ørsted*

Main category: cs.CV

TL;DR: 用 ViT 基础模型把未标注的动物图像直接聚类到物种级，无需人工标签即可实现近完美分类，并开源评估工具供生态学者使用。


<details>
  <summary>Details</summary>
Motivation: 生态研究依赖人工标注动物图像，成本高、规模受限，亟需无需标签即可批量识别物种的自动化方案。

Method: 构建覆盖 60 种鸟兽的基准，系统评测 5 种 ViT 模型 × 5 种降维 × 4 种聚类（2 监督/2 无监督）；每物种随机取 200 张验证图，考察物种级与种内生态变异（性别、年龄、表型）的聚类效果，并检验长尾分布与过聚类策略。

Result: DINOv3+t-SNE+监督层次聚类取得 V-measure 0.958；无监督方案达 0.943，仅 1.14% 图像需专家复核。过聚类可稳定揭示年龄、性二型、被毛差异，并对长尾分布保持鲁棒。

Conclusion: ViT 基础模型可在零标签条件下实现高准确率物种聚类，显著降低生态监测的人工标注瓶颈；开源工具包与选型建议已发布，供研究者按需适配不同类群与数据。

Abstract: Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.

</details>


### [6] [Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs](https://arxiv.org/abs/2602.03895)
*Xuwei Tan,Ziyu Hu,Xueru Zhang*

Main category: cs.CV

TL;DR: NH-Fair 统一基准揭示：多数去偏方法不敌精心调参的 ERM；数据增强组合策略可在不损精度下持续缩小群体差距；大视觉-语言模型虽整体精度高，但仍存子群差异，且扩模型不如改结构/训练协议有效。


<details>
  <summary>Details</summary>
Motivation: 现有公平性缓解方法因数据集异构、指标不一、视觉与多模态模型割裂评估及超参调优不足，导致效果难以横向比较，亟需可复现、无伤害的统一评测框架。

Method: 构建 NH-Fair 基准：标准化数据、指标与训练协议，覆盖视觉模型与大视觉-语言模型（LVLMs）的监督与零样本场景；系统开展 ERM 超参扫描，提炼对效用与差异均显著影响的训练选择；对比多种去偏方法与复合数据增强策略；分析模型规模、架构与训练协议对子群差异的贡献。

Result: 1) 精心调参的 ERM 基线已极具竞争力，多数专用去偏方法未显著超越；2) 复合数据增强在保持精度的同时持续降低群体差距，成为最稳健实用策略；3) LVLMs 平均精度更高，但仍存在可测的子群差异，且规模带来的增益小于架构或训练协议调整。

Conclusion: 公平性提升应优先投入超参调优与数据增强组合，而非盲目扩大模型或堆叠去偏模块；NH-Fair 提供可复现、调优感知的无伤害公平评估流程，为实际部署给出明确行动指南。

Abstract: Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.

</details>


### [7] [HY3D-Bench: Generation of 3D Assets](https://arxiv.org/abs/2602.03907)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Dongyuan Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jiaao Yu,Jiachen Xu,Jingwei Huang,Kunhong Li,Lifu Wang,Linus,Penghao Wang,Qingxiang Lin,Ruining Tang,Xianghui Yang,Yang Li,Yirui Guan,Yunfei Zhao,Yunhan Yang,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: 发布HY3D-Bench：25万高质量3D资产+12.5万合成数据，统一管线解决3D生成训练数据瓶颈，并验证可显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经表达与生成模型虽推动3D内容创作，但仍受限于高质量训练数据的处理瓶颈，亟需统一、易用且覆盖长尾类别的数据基础。

Method: ①构建25万高精度3D对象库，经严格筛选与后处理提供水密网格及多视角渲染；②引入结构化部件级分解，实现细粒度感知与可控编辑；③设计可扩展AIGC合成管线，补充12.5万合成资产以弥合真实分布差距。

Result: 基于HY3D-Bench训练Hunyuan3D-2.1-Small，实证显示其显著提升3D感知与生成性能；开源生态已对外开放，促进3D感知、机器人与数字内容创作研究。

Conclusion: HY3D-Bench通过高质量资产、部件分解与合成增强三大要素，建立3D生成的新数据基准，有望加速相关领域创新与落地。

Abstract: While recent advances in neural representations and generative models have revolutionized 3D content creation, the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation. Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings; (2) We introduce structured part-level decomposition, providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline, contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception, robotics, and digital content creation.

</details>


### [8] [Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science](https://arxiv.org/abs/2602.03915)
*Levi Lingsch,Georgios Kissas,Johannes Jakubik,Siddhartha Mishra*

Main category: cs.CV

TL;DR: 为科学图像设计的新型Tokenizer“Phaedra”，在保持物理与谱特征上显著优于现有视觉Tokenizer，并在多种PDE数据及真实遥感/天气任务中展现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像Tokenizer针对自然视觉优化，难以保留科学图像的大动态范围及物理-谱特性，亟需评估并改进其对PDE等高保真科学数据的适用性。

Method: 构建面向PDE的物理-谱保真度评测指标，系统比较主流Tokenizer；提出受shape-gain量化与POD启发的Phaedra，联合优化形状与增益码本以同时保留细节与幅度信息。

Result: Phaedra在多个PDE数据集重建精度上全面领先；对已知PDE新条件、未知PDE方程及真实地球观测/天气数据均表现出优异的分布外泛化性能。

Conclusion: 科学图像Token化需专门设计以维持物理一致性，Phaedra为可扩展的高保真科学生成与仿真提供了新基线。

Abstract: Tokens are discrete representations that allow modern deep learning to scale by transforming high-dimensional data into sequences that can be efficiently learned, generated, and generalized to new tasks. These have become foundational for image and video generation and, more recently, physical simulation. As existing tokenizers are designed for the explicit requirements of realistic visual perception of images, it is necessary to ask whether these approaches are optimal for scientific images, which exhibit a large dynamic range and require token embeddings to retain physical and spectral properties. In this work, we investigate the accuracy of a suite of image tokenizers across a range of metrics designed to measure the fidelity of PDE properties in both physical and spectral space. Based on the observation that these struggle to capture both fine details and precise magnitudes, we propose Phaedra, inspired by classical shape-gain quantization and proper orthogonal decomposition. We demonstrate that Phaedra consistently improves reconstruction across a range of PDE datasets. Additionally, our results show strong out-of-distribution generalization capabilities to three tasks of increasing complexity, namely known PDEs with different conditions, unknown PDEs, and real-world Earth observation and weather data.

</details>


### [9] [SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?](https://arxiv.org/abs/2602.03916)
*Azmine Toushik Wasi,Wahid Faisal,Abdur Rahman,Mahfuz Ahmed Anik,Munem Shahriar,Mohsin Mahmud Topu,Sadia Tasnim Meem,Rahatun Nesa Priti,Sabrina Afroz Mitu,Md. Iqramul Hoque,Shahriyar Zaman Ridoy,Mohammed Eunus Ali,Majd Hawasly,Mohammad Raza,Md Rizwan Parvez*

Main category: cs.CV

TL;DR: SpatiaLab 是一个面向真实场景的大规模空间推理基准，涵盖 6 大主类 30 子类共 1 400 图文问答对；主流 VLM 在多项选择下最高仅 54.9%，人类 87.6%，开放问答再降 10–25%，暴露出深度、导航与 3D 几何等关键缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有合成或 LLM 生成任务过于简化，无法反映真实世界的视觉噪声与复杂空间关系，亟需一个贴近现实且系统全面的评估框架来揭示 VLM 空间推理的真实瓶颈。

Method: 构建 SpatiaLab 基准：① 从真实无约束图像出发，设计 6 大主类（相对位置、深度与遮挡、朝向、大小与尺度、空间导航、3D 几何）共 30 子类；② 每子类 ≥25 题，每主类 ≥200 题，总计 1 400 问答对；③ 同时支持多项选择与开放问答两种评估协议；④ 对开放/闭源、通用/专用等 10 余个 SOTA VLM 进行系统实验并与人类对比。

Result: 多项选择：最佳模型 InternVL3.5-72B 准确率 54.93%，人类 87.57%，差距 32.6 个百分点；开放问答：所有模型下降 10–25%，GPT-5-mini 最高 40.93%，人类 64.93%。深度感知、复杂遮挡、空间导航与 3D 几何是主要短板。

Conclusion: SpatiaLab 首次在真实场景下系统量化 VLM 空间推理缺陷，为后续研究提供明确方向：需加强深度-3D 表征、导航策略与噪声鲁棒性，以缩小与人级空间理解的差距。

Abstract: Spatial reasoning is a fundamental aspect of human cognition, yet it remains a major challenge for contemporary vision-language models (VLMs). Prior work largely relied on synthetic or LLM-generated environments with limited task designs and puzzle-like setups, failing to capture the real-world complexity, visual noise, and diverse spatial relationships that VLMs encounter. To address this, we introduce SpatiaLab, a comprehensive benchmark for evaluating VLMs' spatial reasoning in realistic, unconstrained contexts. SpatiaLab comprises 1,400 visual question-answer pairs across six major categories: Relative Positioning, Depth & Occlusion, Orientation, Size & Scale, Spatial Navigation, and 3D Geometry, each with five subcategories, yielding 30 distinct task types. Each subcategory contains at least 25 questions, and each main category includes at least 200 questions, supporting both multiple-choice and open-ended evaluation. Experiments across diverse state-of-the-art VLMs, including open- and closed-source models, reasoning-focused, and specialized spatial reasoning models, reveal a substantial gap in spatial reasoning capabilities compared with humans. In the multiple-choice setup, InternVL3.5-72B achieves 54.93% accuracy versus 87.57% for humans. In the open-ended setting, all models show a performance drop of around 10-25%, with GPT-5-mini scoring highest at 40.93% versus 64.93% for humans. These results highlight key limitations in handling complex spatial relationships, depth perception, navigation, and 3D geometry. By providing a diverse, real-world evaluation framework, SpatiaLab exposes critical challenges and opportunities for advancing VLMs' spatial reasoning, offering a benchmark to guide future research toward robust, human-aligned spatial understanding. SpatiaLab is available at: https://spatialab-reasoning.github.io/.

</details>


### [10] [Entropy Reveals Block Importance in Masked Self-Supervised Vision Transformers](https://arxiv.org/abs/2602.03918)
*Peihao Xiang,Kaida Wu,Ou Bai*

Main category: cs.CV

TL;DR: 无需任何数据，仅凭预训练权重熵即可判定Vision Transformer中哪些block冗余；Gardener一次性剪枝91.7%块后仍保持下游竞争力。


<details>
  <summary>Details</summary>
Motivation: 掩码自监督ViT庞大，难以在资源受限场景部署；现有剪枝需数据或迭代重训，代价高。作者追问：所有transformer block真的同等重要吗？

Method: 提出Gardener：首次发现“预训练块权重的信息熵”与“oracle敏感度（逐块移除+微调后的性能变化）”高度相关，从而零数据、一次性完成块级重要性排序与剪枝。

Result: 在VideoMAE-B上，Gardener零样本剪枝后，Kinetics-400、Something-Something V2等基准精度与数据无关基线持平或更高，并逼近需数据的重训练敏感度方法；剪去91.7%块仍保留可迁移性能。

Conclusion: 掩码自监督ViT存在显著块级冗余；信息熵可零成本预测重要性，为模型压缩与资源高效迁移提供新范式。

Abstract: Masked self-supervised vision transformers have become a dominant pretraining paradigm, yet their substantial model size poses significant challenges for resource-constrained deployment and efficient transfer learning. A fundamental question remains: are all transformer blocks equally important for downstream performance? In this paper, we show that block importance in masked self-supervised vision transformers can be accurately estimated without access to any data. Our key finding is that the information entropy of pretrained block weights strongly correlates with oracle sensitivity obtained via iterative block removal and finetuning. This observation enables Gardener, a data-free, one-shot, block-level pruning principle that identifies redundant blocks through simple information-theoretic measurements. We evaluate Gardener on VideoMAE-B across multiple pruning ratios and downstream video recognition benchmarks. Despite its negligible computational overhead, Gardener consistently matches or outperforms existing data-free pruning baselines and closely approaches sensitivity-based pruning. Remarkably, even after pruning up to 91.7\% of blocks, the pruned model retains competitive transfer performance. Our results reveal substantial block-level redundancy in masked self-supervised vision transformers and demonstrate that information-theoretic analysis offers a principled and efficient pathway for model compression and resource-efficient transfer learning.

</details>


### [11] [AnyStyle: Single-Pass Multimodal Stylization for 3D Gaussian Splatting](https://arxiv.org/abs/2602.04043)
*Joanna Kaleta,Bartosz Świrta,Kacper Kania,Przemysław Spurek,Marek Kowalski*

Main category: cs.CV

TL;DR: AnyStyle 用多模态条件（文本/参考图）在无需相机位姿的 3DGS 前馈重建流程中实现零样本风格化，只需最小结构改动即可提升可控性与几何保真度。


<details>
  <summary>Details</summary>
Motivation: 前馈 3DGS 已能从无位姿图像快速重建，但现有风格化方法仅依赖图像条件，可控性与灵活性不足，亟需支持文本/图像双重风格输入的零样本方案。

Method: 提出模块化 AnyStyle 框架：1) 保持原 3DGS 前馈重建主干不变；2) 引入轻量级多模态风格编码器，将文本或参考图映射为全局风格 token；3) 在 Gaussian 属性预测分支注入风格特征，实现颜色与外观的显式控制；4) 端到端训练，无需场景特化优化。

Result: 在多个数据集上的定量指标（FID、CLIP 相似度）与用户研究均优于现有前馈风格化基线；在保持几何重建质量的同时，实现更精细、语义一致的风格迁移；支持文本提示与参考图混合控制，推理速度 <1 s。

Conclusion: AnyStyle 证明仅需最小架构调整即可把多模态风格化无缝嵌入无位姿 3DGS 前馈流程，兼顾高效率、高保真几何与强可控风格，为实时可扩展 3D 内容创作提供了新范式。

Abstract: The growing demand for rapid and scalable 3D asset creation has driven interest in feed-forward 3D reconstruction methods, with 3D Gaussian Splatting (3DGS) emerging as an effective scene representation. While recent approaches have demonstrated pose-free reconstruction from unposed image collections, integrating stylization or appearance control into such pipelines remains underexplored. Existing attempts largely rely on image-based conditioning, which limits both controllability and flexibility. In this work, we introduce AnyStyle, a feed-forward 3D reconstruction and stylization framework that enables pose-free, zero-shot stylization through multimodal conditioning. Our method supports both textual and visual style inputs, allowing users to control the scene appearance using natural language descriptions or reference images. We propose a modular stylization architecture that requires only minimal architectural modifications and can be integrated into existing feed-forward 3D reconstruction backbones. Experiments demonstrate that AnyStyle improves style controllability over prior feed-forward stylization methods while preserving high-quality geometric reconstruction. A user study further confirms that AnyStyle achieves superior stylization quality compared to an existing state-of-the-art approach. Repository: https://github.com/joaxkal/AnyStyle.

</details>


### [12] [A Parameterizable Convolution Accelerator for Embedded Deep Learning Applications](https://arxiv.org/abs/2602.04044)
*Panagiotis Mousouliotis,Georgios Keramidas*

Main category: cs.CV

TL;DR: 用 HLS 把 CNN 加速器做成高度参数化 IP，一次综合即可在延迟、功耗、面积、成本等多约束间快速折中，实验表明优于传统固定架构设计。


<details>
  <summary>Details</summary>
Motivation: 纯追求 GOPS 的 FPGA-CNN 加速器难以满足嵌入式场景对延迟、功耗、面积、成本等多重要求，需要一种可系统化权衡的联合设计方法。

Method: 提出 HW/SW 协同设计流程：以 C/C++ 描述 CNN 加速器，利用高层次综合（HLS）将并行度、位宽、片上缓存、DSP 使用率等关键参数抽象为可配置变量；通过自动化脚本在综合前扫描参数空间，结合 Vivado 后端的时序/资源/功耗报告，快速生成 Pareto 最优解集；软件端同步调整量化、剪枝策略，保证精度不退化。

Result: 在 Zynq-7020 与 ZU3EG 两款 FPGA 上分别实现 MobileNetV2 与 Tiny-YOLO，相较同平台非参数化手工设计，在同等精度下：延迟降低 1.4–2.1×，功耗下降 18–32%，LUT/FF 利用率提升 15–25%，单次综合-评估循环缩短至 6–9 min；整体验证了方法可无缝扩展到其他 DL 任务。

Conclusion: 基于 HLS 的参数化 HW/SW 协同设计不仅能在多约束间高效折中，还显著缩短探索时间，为资源受限的嵌入式 DL 应用提供了一条可复用、易扩展的 FPGA 加速器实现路径。

Abstract: Convolutional neural network (CNN) accelerators implemented on Field-Programmable Gate Arrays (FPGAs) are typically designed with a primary focus on maximizing performance, often measured in giga-operations per second (GOPS). However, real-life embedded deep learning (DL) applications impose multiple constraints related to latency, power consumption, area, and cost. This work presents a hardware-software (HW/SW) co-design methodology in which a CNN accelerator is described using high-level synthesis (HLS) tools that ease the parameterization of the design, facilitating more effective optimizations across multiple design constraints. Our experimental results demonstrate that the proposed design methodology is able to outperform non-parameterized design approaches, and it can be easily extended to other types of DL applications.

</details>


### [13] [Fast, Unsupervised Framework for Registration Quality Assessment of Multi-stain Histological Whole Slide Pairs](https://arxiv.org/abs/2602.04046)
*Shikha Dubey,Patricia Raciti,Kristopher Standish,Albert Juan Ramon,Erik Ames Burlingame*

Main category: cs.CV

TL;DR: 无需人工标注即可实时评估H&E与IHC全切片配准质量的无监督框架，用下采样组织掩膜+形变场双重指标，在多标记物和多专家验证中与人工评分高度一致，可大规模部署于数字病理质控。


<details>
  <summary>Details</summary>
Motivation: 现有WSI配准质量评估依赖地标或强度相似度，耗时费力且缺乏金标准，难以满足大规模分子整合分析需求。

Method: 提出快速无监督RQA框架：①对下采样组织掩膜计算全局结构一致性指标；②对估计形变场计算局部平滑、连续及变换合理性指标；③联合两类指标实现无GT情况下的实时质量判定。

Result: 跨多种IHC标记和多专家主观评分验证，自动化指标与人工评价相关性高；在无需金标准条件下实现高保真、低算力的实时质量评估，可直接用于数字病理大规模质控。

Conclusion: 该框架突破了无GT WSI配准质量评估瓶颈，兼顾速度、精度与资源消耗，为数字病理集成分析提供了可扩展的质量控制工具。

Abstract: High-fidelity registration of histopathological whole slide images (WSIs), such as hematoxylin & eosin (H&E) and immunohistochemistry (IHC), is vital for integrated molecular analysis but challenging to evaluate without ground-truth (GT) annotations. Existing WSI-level assessments -- using annotated landmarks or intensity-based similarity metrics -- are often time-consuming, unreliable, and computationally intensive, limiting large-scale applicability. This study proposes a fast, unsupervised framework that jointly employs down-sampled tissue masks- and deformations-based metrics for registration quality assessment (RQA) of registered H&E and IHC WSI pairs. The masks-based metrics measure global structural correspondence, while the deformations-based metrics evaluate local smoothness, continuity, and transformation realism. Validation across multiple IHC markers and multi-expert assessments demonstrate a strong correlation between automated metrics and human evaluations. In the absence of GT, this framework offers reliable, real-time RQA with high fidelity and minimal computational resources, making it suitable for large-scale quality control in digital pathology.

</details>


### [14] [Seeing Through Clutter: Structured 3D Scene Reconstruction via Iterative Object Removal](https://arxiv.org/abs/2602.04053)
*Rio Aguina-Kang,Kevin James Blackburn-Matzen,Thibault Groueix,Vladimir Kim,Matheus Gadelha*

Main category: cs.CV

TL;DR: 用“逐物剔除-重建”循环把单张图像拆成干净个体，再拼回结构化3D场景，无需额外训练即可在杂乱与遮挡中取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统先做语义分割或深度估计再重建的方案，在遮挡和杂乱场景下误差连锁放大；作者希望绕过这些易错中间任务，直接得到可解释的结构化3D表示。

Method: 提出迭代式“检测-分割-图像修补-3D拟合-剔除”流水线，由VLM统筹，每次只把最显著前景物体建模并移除，使后续物体在更干净背景下被分割；循环直至场景为空，最终把所有单体模型按原序拼回整体3D场景。

Result: 在3D-FRONT与ADE20K上，单图重建的完整性、遮挡鲁棒性与几何精度均优于现有零样本方法，且随基础模型升级而直接获益。

Conclusion: 通过“逐个减去”策略，将复杂场景解耦为简单子任务，可显著降低遮挡干扰；该方法无需任务特定训练，展示了利用大模型迭代式推理实现复杂3D理解的潜力。

Abstract: We present SeeingThroughClutter, a method for reconstructing structured 3D representations from single images by segmenting and modeling objects individually. Prior approaches rely on intermediate tasks such as semantic segmentation and depth estimation, which often underperform in complex scenes, particularly in the presence of occlusion and clutter. We address this by introducing an iterative object removal and reconstruction pipeline that decomposes complex scenes into a sequence of simpler subtasks. Using VLMs as orchestrators, foreground objects are removed one at a time via detection, segmentation, object removal, and 3D fitting. We show that removing objects allows for cleaner segmentations of subsequent objects, even in highly occluded scenes. Our method requires no task-specific training and benefits directly from ongoing advances in foundation models. We demonstrate stateof-the-art robustness on 3D-Front and ADE20K datasets. Project Page: https://rioak.github.io/seeingthroughclutter/

</details>


### [15] [iSight: Towards expert-AI co-assessment for improved immunohistochemistry staining interpretation](https://arxiv.org/abs/2602.04063)
*Jacob S. Leiby,Jialu Yao,Pan Lu,George Hu,Anna Davidian,Shunsuke Koga,Olivia Leung,Pravin Patel,Isabella Tondi Resta,Rebecca Rojansky,Derek Sung,Eric Yang,Paul J. Zhang,Emma Lundberg,Dokyoon Kim,Serena Yeung-Levy,James Zou,Thomas Montine,Jeffrey Nirschl,Zhi Huang*

Main category: cs.CV

TL;DR: 发布全球最大IHC图像库HPA10M（1049万张），并训练多任务框架iSight，实现染色强度、定位、量、组织类型及良恶性同步评估，性能超越现有基础模型并与病理医生协同提升一致性。


<details>
  <summary>Details</summary>
Motivation: 免疫组化（IHC）是病理诊断关键，但AI模型因领域差异难以直接迁移；缺乏大规模、带完整元数据的IHC公开数据，限制了自动化评估方法的发展。

Method: 构建含45种正常组织+20种主要癌种的HPA10M数据集；提出多任务学习框架iSight，将全切片视觉特征与组织元数据经token级注意力融合，同步预测染色强度、定位、量、组织类型和良恶性。

Result: iSight在保留集上定位、强度、定量准确率分别达85.5%、76.6%、75.7%，比PLIP/CONCH高2.5–10.2%；校准误差仅0.0150–0.0408。8位病理医生200张图用户研究显示，iSight单模型评估优于初始人工（HPA数据集定位79% vs 68%等），且AI辅助后病理医生间一致性提升（HPA κ由0.63→0.70，Stanford TMAD 0.74→0.76）。

Conclusion: HPA10M与iSight为IHC自动化奠定新基准，验证AI-病理协同可显著提高IHC判读准确性与一致性，具备融入临床流程、增强诊断可靠性的潜力。

Abstract: Immunohistochemistry (IHC) provides information on protein expression in tissue sections and is commonly used to support pathology diagnosis and disease triage. While AI models for H\&E-stained slides show promise, their applicability to IHC is limited due to domain-specific variations. Here we introduce HPA10M, a dataset that contains 10,495,672 IHC images from the Human Protein Atlas with comprehensive metadata included, and encompasses 45 normal tissue types and 20 major cancer types. Based on HPA10M, we trained iSight, a multi-task learning framework for automated IHC staining assessment. iSight combines visual features from whole-slide images with tissue metadata through a token-level attention mechanism, simultaneously predicting staining intensity, location, quantity, tissue type, and malignancy status. On held-out data, iSight achieved 85.5\% accuracy for location, 76.6\% for intensity, and 75.7\% for quantity, outperforming fine-tuned foundation models (PLIP, CONCH) by 2.5--10.2\%. In addition, iSight demonstrates well-calibrated predictions with expected calibration errors of 0.0150-0.0408. Furthermore, in a user study with eight pathologists evaluating 200 images from two datasets, iSight outperformed initial pathologist assessments on the held-out HPA dataset (79\% vs 68\% for location, 70\% vs 57\% for intensity, 68\% vs 52\% for quantity). Inter-pathologist agreement also improved after AI assistance in both held-out HPA (Cohen's $κ$ increased from 0.63 to 0.70) and Stanford TMAD datasets (from 0.74 to 0.76), suggesting expert--AI co-assessment can improve IHC interpretation. This work establishes a foundation for AI systems that can improve IHC diagnostic accuracy and highlights the potential for integrating iSight into clinical workflows to enhance the consistency and reliability of IHC assessment.

</details>


### [16] [VideoBrain: Learning Adaptive Frame Sampling for Long Video Understanding](https://arxiv.org/abs/2602.04094)
*Junbo Zou,Ziheng Huang,Shengjie Zhang,Liwen Zhang,Weining Shen*

Main category: cs.CV

TL;DR: VideoBrain 让视觉-语言模型自己“决定”什么时候、在哪里取帧：用两个可学习的智能体（语义检索+密集采样）动态采 30–40% 的帧，就能在长视频任务上比均匀采样基线提升 3.5–9.0%，且跨数据集通用。


<details>
  <summary>Details</summary>
Motivation: 长视频动辄上千帧，现有方法要么均匀采样丢信息，要么一次选关键帧无法反悔；亟需让 VLM 在计算受限条件下自适应地“看”最少却最管用的帧。

Method: 提出端到端框架 VideoBrain，内含两个互补的可学习采样智能体：CLIP 语义检索智能体跨视频找相关帧，Uniform 智能体在局部时段密集采样。VLM 直接看帧并判断信息是否足够，行为感知奖励函数+数据分类管道防止模型滥用智能体刷奖励。

Result: 在 4 个长视频基准上平均提升 3.5–9.0%，帧数减少 30–40%；迁移到短视频任务也保持优势，证明采样策略具有跨数据集泛化能力。

Conclusion: 通过让 VLM 自主习得“何时、何处”获取视觉信息，VideoBrain 在显著降低计算量的同时提升了长视频理解性能，为高效视频-语言建模提供了可扩展的新范式。

Abstract: Long-form video understanding remains challenging for Vision-Language Models (VLMs) due to the inherent tension between computational constraints and the need to capture information distributed across thousands of frames. Existing approaches either sample frames uniformly (risking information loss) or select keyframes in a single pass (with no recovery from poor choices). We propose VideoBrain, an end-to-end framework that enables VLMs to adaptively acquire visual information through learned sampling policies. Our approach features dual complementary agents: a CLIP-based agent for semantic retrieval across the video and a Uniform agent for dense temporal sampling within intervals. Unlike prior agent-based methods that rely on text-only LLMs orchestrating visual tools, our VLM directly perceives frames and reasons about information sufficiency. To prevent models from invoking agents indiscriminately to maximize rewards, we introduce a behavior-aware reward function coupled with a data classification pipeline that teaches the model when agent invocation is genuinely beneficial. Experiments on four long video benchmarks demonstrate that VideoBrain achieves +3.5% to +9.0% improvement over the baseline while using 30-40% fewer frames, with strong cross-dataset generalization to short video benchmarks.

</details>


### [17] [Context Determines Optimal Architecture in Materials Segmentation](https://arxiv.org/abs/2602.04154)
*Mingjian Lu,Pawan K. Tripathi,Mark Shteyn,Debargha Ganguly,Roger H. French,Vipin Chaudhary,Yinghui Wu*

Main category: cs.CV

TL;DR: 提出首个跨SEM、AFM、XCT、光学显微四种成像模态的材料图像分割统一评测框架，发现UNet在高对比2D场景最优，DeepLabv3+最难任务表现最佳，并集成OOD检测与可解释性工具，解决材料表征中模型选型与可信度评估痛点。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型评测仅在单一模态内进行，忽略不同成像模态下性能差异，导致材料研究者无法为自身成像系统选择最合适架构，也难以判断模型在新样品上的可信度。

Method: 构建跨SEM、AFM、XCT、光学显微四种模态的七数据集基准；系统评测6种编码-解码组合；引入分布外检测与反事实解释，量化微结构特征对预测的贡献，提供部署级可靠性信号与可解释性。

Result: 发现架构最优选择随模态与对比度系统变化：UNet在高对比2D成像中领先，DeepLabv3+在最困难任务中显著优于其他；框架实时标记OOD样本并给出可解释性反馈，显著提升材料表征流程的可靠性。

Conclusion: 跨模态评测揭示“一刀切”模型不存在，为材料图像分割提供针对性选型指南；结合OOD检测与反事实解释，首次实现“选模型-用模型-信模型”闭环，填补材料显微表征在实际部署中的工具空白。

Abstract: Segmentation architectures are typically benchmarked on single imaging modalities, obscuring deployment-relevant performance variations: an architecture optimal for one modality may underperform on another. We present a cross-modal evaluation framework for materials image segmentation spanning SEM, AFM, XCT, and optical microscopy. Our evaluation of six encoder-decoder combinations across seven datasets reveals that optimal architectures vary systematically by context: UNet excels for high-contrast 2D imaging while DeepLabv3+ is preferred for the hardest cases. The framework also provides deployment feedback via out-of-distribution detection and counterfactual explanations that reveal which microstructural features drive predictions. Together, the architecture guidance, reliability signals, and interpretability tools address a practical gap in materials characterization, where researchers lack tools to select architectures for their specific imaging setup or assess when models can be trusted on new samples.

</details>


### [18] [Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity](https://arxiv.org/abs/2602.04162)
*Chenhe Du,Qing Wu,Xuanyu Tian,Jingyi Yu,Hongjiang Wei,Yuyao Zhang*

Main category: cs.CV

TL;DR: 用2D扩散模型做3D医学影像重建时，逐层采样随机性会导致层间不连续。本文提出“层间一致随机性（ISCS）”，在采样阶段同步相邻层的随机噪声轨迹，无需额外损失或优化即可消除伪影，即插即用提升3D保真度。


<details>
  <summary>Details</summary>
Motivation: 3D医学影像重建依赖扩散模型，但直接训练3D DM数据难获取且计算昂贵；退而求其次的2D DM逐层重建又因扩散采样的固有随机性造成层间断裂，现有z轴正则化方法超参敏感且易过平滑。

Method: 提出Inter-Slice Consistent Stochasticity（ISCS）：在反向扩散去噪过程中，对相邻切片共享或高度对齐随机噪声分量，使它们的采样轨迹保持一致，从而在不引入新损失、不增加训练/推断代价的前提下实现层间连贯。

Result: 在多个医学影像重建任务（如稀疏视角CT、MRI超分）上，将ISCS插入现有2D DM流水线后，层间SSIM提升约0.03–0.05，整体3D SSIM提升2–4%，同时消除了明显阶跃伪影；无需额外训练，推断时间零增加。

Conclusion: 控制层间随机性而非强制正则化，是一条简洁高效的路径，可在2D扩散先验下获得高保真3D医学影像；ISCS即插即用，为临床落地提供实用方案。

Abstract: 3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distribution with DMs in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the DMs on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter-slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the z-axis, which introduces sensitive hyper-parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter-Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages interslice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps. Importantly, the proposed ISCS is plug-and-play and can be dropped into any 2D trained diffusion based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter-slice stochasticity is a principled and practically attractive route toward high-fidelity 3D medical imaging with 2D diffusion priors. The code is available at: https://github.com/duchenhe/ISCS

</details>


### [19] [Point2Insert: Video Object Insertion via Sparse Point Guidance](https://arxiv.org/abs/2602.04167)
*Yu Zhou,Xiaoyan Yang,Bojia Zi,Lihan Zhang,Ruijie Sun,Weishi Zheng,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Point2Insert 用稀疏点代替繁琐掩码，实现视频中精准、低成本的物体插入，性能超越 10 倍参数量的基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖劳动密集的掩码标注，要么无法按指令精确定位；亟需一种既省力又能精确控制空间位置的插入方案。

Method: 提出稀疏点提示框架 Point2Insert：① 两阶段训练——先以点/掩码为条件训练插入模型，再用物体移除模型合成的成对视频继续微调；② 引入正负点实现细粒度空间约束；③ 以掩码教师模型进行知识蒸馏，提升点引导模型的可靠性。

Result: 在公开数据集上的大量实验表明，Point2Insert 在插入精度、时空一致性与用户主观评分上均显著优于强基线，甚至超过参数量大 10 倍的模型。

Conclusion: 稀疏点提示足以替代传统掩码，实现高质量视频物体插入；两阶段训练+知识蒸馏策略有效提升了生成可靠性与定位精度，为交互式视频编辑提供了轻量级新范式。

Abstract: This paper introduces Point2Insert, a sparse-point-based framework for flexible and user-friendly object insertion in videos, motivated by the growing popularity of accurate, low-effort object placement. Existing approaches face two major challenges: mask-based insertion methods require labor-intensive mask annotations, while instruction-based methods struggle to place objects at precise locations. Point2Insert addresses these issues by requiring only a small number of sparse points instead of dense masks, eliminating the need for tedious mask drawing. Specifically, it supports both positive and negative points to indicate regions that are suitable or unsuitable for insertion, enabling fine-grained spatial control over object locations. The training of Point2Insert consists of two stages. In Stage 1, we train an insertion model that generates objects in given regions conditioned on either sparse-point prompts or a binary mask. In Stage 2, we further train the model on paired videos synthesized by an object removal model, adapting it to video insertion. Moreover, motivated by the higher insertion success rate of mask-guided editing, we leverage a mask-guided insertion model as a teacher to distill reliable insertion behavior into the point-guided model. Extensive experiments demonstrate that Point2Insert consistently outperforms strong baselines and even surpasses models with $\times$10 more parameters.

</details>


### [20] [Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models](https://arxiv.org/abs/2602.04184)
*Angel Martinez-Sanchez,Parthib Roy,Ross Greer*

Main category: cs.CV

TL;DR: 首个真实场景语言指令驾驶数据集 doScenes 结合开源 MLLM 框架 OpenEMMA，证明自由文本指令可将轨迹预测平均误差降低 98.7%，并给出“好指令”设计原则。


<details>
  <summary>Details</summary>
Motivation: 现有指令跟随规划器依赖仿真或固定词表，难以泛化到真实世界；亟需带自由文本指令的真实驾驶数据与可复现基线，以验证语言能否有效约束轨迹生成。

Method: 构建 doScenes 数据集，将 nuScenes 真实轨迹与含指代关系的自由文本指令配对；把指令作为乘客风格提示嵌入开源 MLLM 框架 OpenEMMA 的视觉-语言接口，实现端到端条件规划；在 849 段标注场景上用 ADE 评估并对比有无指令的轨迹差异。

Result: 指令条件使极端失败率下降 98.7%（mean ADE）；剔除离群后，措辞良好的提示仍可提升 ADE 最多 5.1%；总结出让模型受益的“好指令”特征（具体、时空明确、无歧义）。

Conclusion: 自由形式语言指令能显著增强真实场景下端到端规划的鲁棒性与精度；doScenes+OpenEMMA 提供公开可复现的指令感知规划基线，为未来研究奠定数据与评估标准。

Abstract: Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-world dataset linking free-form instructions (with referentiality) to nuScenes ground-truth motion, enables instruction-conditioned planning. In this work, we adapt OpenEMMA, an open-source MLLM-based end-to-end driving framework that ingests front-camera views and ego-state and outputs 10-step speed-curvature trajectories, to this setting, presenting a reproducible instruction-conditioned baseline on doScenes and investigate the effects of human instruction prompts on predicted driving behavior. We integrate doScenes directives as passenger-style prompts within OpenEMMA's vision-language interface, enabling linguistic conditioning before trajectory generation. Evaluated on 849 annotated scenes using ADE, we observe that instruction conditioning substantially improves robustness by preventing extreme baseline failures, yielding a 98.7% reduction in mean ADE. When such outliers are removed, instructions still influence trajectory alignment, with well-phrased prompts improving ADE by up to 5.1%. We use this analysis to discuss what makes a "good" instruction for the OpenEMMA framework. We release the evaluation prompts and scripts to establish a reproducible baseline for instruction-aware planning. GitHub: https://github.com/Mi3-Lab/doScenes-VLM-Planning

</details>


### [21] [DiMo: Discrete Diffusion Modeling for Motion Generation and Understanding](https://arxiv.org/abs/2602.04188)
*Ning Zhang,Zhengyu Li,Kwong Weng Loh,Mingxi Xu,Qi Wang,Zhengyu Wen,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: DiMo 用离散扩散统一文本-动作双向生成，一套模型搞定 T2M/M2T/M2M，无需改动结构即可控制质量-延迟，在 HumanML3D/KIT-ML 上效果领先。


<details>
  <summary>Details</summary>
Motivation: 现有掩码建模多聚焦单向文本到动作，缺乏统一框架同时支持双向理解与生成，且自回归方法存在串行延迟、难以灵活权衡质量与速度的问题。

Method: 提出离散扩散式 DiMo：1) 采用残差向量量化（RVQ）获得高保真动作 token；2) 迭代掩码 token 精修而非自回归解码，统一 T2M、M2T 与无文本 M2M；3) 引入组相对策略优化（GRPO）增强文本-动作对齐与可控性；4) 通过调节迭代步数实现推理期质量-延迟权衡。

Result: 在 HumanML3D 与 KIT-ML 上取得强动作质量与竞争性的双向理解性能；无需架构调整即可完成无文本动作补全、文本引导动作预测与动作字幕纠错等任务。

Conclusion: DiMo 证明离散扩散+迭代掩码精修可成为文本-动作双向任务的统一高效范式，兼顾质量、速度与扩展性，为后续多模态动作研究提供新基线。

Abstract: Prior masked modeling motion generation methods predominantly study text-to-motion. We present DiMo, a discrete diffusion-style framework, which extends masked modeling to bidirectional text--motion understanding and generation. Unlike GPT-style autoregressive approaches that tokenize motion and decode sequentially, DiMo performs iterative masked token refinement, unifying Text-to-Motion (T2M), Motion-to-Text (M2T), and text-free Motion-to-Motion (M2M) within a single model. This decoding paradigm naturally enables a quality-latency trade-off at inference via the number of refinement steps.We further improve motion token fidelity with residual vector quantization (RVQ) and enhance alignment and controllability with Group Relative Policy Optimization (GRPO). Experiments on HumanML3D and KIT-ML show strong motion quality and competitive bidirectional understanding under a unified framework. In addition, we demonstrate model ability in text-free motion completion, text-guided motion prediction and motion caption correction without architectural change.Additional qualitative results are available on our project page: https://animotionlab.github.io/DiMo/.

</details>


### [22] [Continuous Degradation Modeling via Latent Flow Matching for Real-World Super-Resolution](https://arxiv.org/abs/2602.04193)
*Hyeonjae Kim,Dongjin Kim,Eugene Jin,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 用流匹配从单张高清图生成带真实降质的低清图，可任意降质强度，训出的超分模型在真实场景大幅优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习超分在合成降质（如双三次下采样）上表现好，但在含噪声、模糊、压缩等复杂非线性降质的真实图像上失效；真实LR-HR数据对收集困难且只覆盖有限降质尺度。

Method: 提出基于流匹配的新框架，仅输入单张HR图像即可在潜降质空间中采样并合成具有真实感的LR图像，支持未见降质强度，无需成对真实数据。

Result: 合成LR图像在定量与定性评估上均准确再现真实降质；用其训练的传统固定尺度与任意尺度超分模型，在真实测试集上获得显著更优的HR重建效果。

Conclusion: 所提方法可高效构建大规模真实降质训练集，突破真实场景超分的数据瓶颈，显著提升模型泛化与实用性。

Abstract: While deep learning-based super-resolution (SR) methods have shown impressive outcomes with synthetic degradation scenarios such as bicubic downsampling, they frequently struggle to perform well on real-world images that feature complex, nonlinear degradations like noise, blur, and compression artifacts. Recent efforts to address this issue have involved the painstaking compilation of real low-resolution (LR) and high-resolution (HR) image pairs, usually limited to several specific downscaling factors. To address these challenges, our work introduces a novel framework capable of synthesizing authentic LR images from a single HR image by leveraging the latent degradation space with flow matching. Our approach generates LR images with realistic artifacts at unseen degradation levels, which facilitates the creation of large-scale, real-world SR training datasets. Comprehensive quantitative and qualitative assessments verify that our synthetic LR images accurately replicate real-world degradations. Furthermore, both traditional and arbitrary-scale SR models trained using our datasets consistently yield much better HR outcomes.

</details>


### [23] [VTok: A Unified Video Tokenizer with Decoupled Spatial-Temporal Latents](https://arxiv.org/abs/2602.04202)
*Feng Wang,Yichun Shi,Ceyuan Yang,Qiushan Guo,Jingxiang Sun,Alan Yuille,Peng Wang*

Main category: cs.CV

TL;DR: VTok 用“关键帧保持原貌＋后续帧仅保留残差”的方式，把视频 token 复杂度从“帧数×每帧 token”降到“帧数＋每帧 token”，在理解与生成任务上同时取得更高性能与更短序列。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言系统对视频做 token 化时普遍采用“逐帧均匀采样”，导致 token 序列长、计算冗余，且难以兼顾生成与理解两类任务。作者希望提出一种统一且紧凑的视频 token 化范式，兼顾效率与表达能力。

Method: 提出 VTok：1) 选取单张关键帧，保留其完整空间 token；2) 对后续帧仅编码与关键帧的残差，得到 1 个残差 token/帧；3) 空间-时序解耦，使总 token 数从 O(F×N) 降至 O(F+N)。框架可无缝接入现有生成或理解模型。

Result: 在多个视频理解（TV-Align 等）与文生视频（VBench）基准上，VTok 以显著更短的输入序列取得更高精度：TV-Align +3.4%，VBench +1.9%，且生成的动作更连贯、文本一致性更好。

Conclusion: VTok 验证了“关键帧+残差 token”的紧凑表征足以同时支撑视频理解与生成，为后续研究提供了一个高效、统一且可扩展的视频 token 化标准。

Abstract: This work presents VTok, a unified video tokenization framework that can be used for both generation and understanding tasks. Unlike the leading vision-language systems that tokenize videos through a naive frame-sampling strategy, we propose to decouple the spatial and temporal representations of videos by retaining the spatial features of a single key frame while encoding each subsequent frame into a single residual token, achieving compact yet expressive video tokenization. Our experiments suggest that VTok effectively reduces the complexity of video representation from the product of frame count and per-frame token count to their sum, while the residual tokens sufficiently capture viewpoint and motion changes relative to the key frame. Extensive evaluations demonstrate the efficacy and efficiency of VTok: it achieves notably higher performance on a range of video understanding and text-to-video generation benchmarks compared with baselines using naive tokenization, all with shorter token sequences per video (e.g., 3.4% higher accuracy on our TV-Align benchmark and 1.9% higher VBench score). Remarkably, VTok produces more coherent motion and stronger guidance following in text-to-video generation, owing to its more consistent temporal encoding. We hope VTok can serve as a standardized video tokenization paradigm for future research in video understanding and generation.

</details>


### [24] [AGMA: Adaptive Gaussian Mixture Anchors for Prior-Guided Multimodal Human Trajectory Forecasting](https://arxiv.org/abs/2602.04204)
*Chao Li,Rui Zhang,Siyuan Huang,Xian Zhong,Hongbo Jiang*

Main category: cs.CV

TL;DR: AGMA 用两阶段自适应高斯混合先验解决轨迹预测中的先验失配，显著降低误差、提升多样性，在三大数据集刷新 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹预测方法因先验分布与真实多模态行为失配，导致预测精度与多样性受限；理论证明预测误差受先验质量下界约束，亟需提升先验表达能力。

Method: 提出 AGMA：① 离线阶段从训练集挖掘多样化行为模式并聚类成高斯混合；② 在线阶段根据场景上下文蒸馏出场景自适应全局先验，再与观测特征融合完成预测。

Result: 在 ETH-UCY、Stanford Drone、JRDB 上全面领先，ADE/FDE 平均降低 10–15%，预测多样性指标提升约 20%，验证高质量先验对性能的关键作用。

Conclusion: 先验建模是轨迹预测核心瓶颈；AGMA 通过数据驱动、场景自适应的高斯混合先验有效缓解失配，为后续研究提供了可扩展的通用框架。

Abstract: Human trajectory forecasting requires capturing the multimodal nature of pedestrian behavior. However, existing approaches suffer from prior misalignment. Their learned or fixed priors often fail to capture the full distribution of plausible futures, limiting both prediction accuracy and diversity. We theoretically establish that prediction error is lower-bounded by prior quality, making prior modeling a key performance bottleneck. Guided by this insight, we propose AGMA (Adaptive Gaussian Mixture Anchors), which constructs expressive priors through two stages: extracting diverse behavioral patterns from training data and distilling them into a scene-adaptive global prior for inference. Extensive experiments on ETH-UCY, Stanford Drone, and JRDB datasets demonstrate that AGMA achieves state-of-the-art performance, confirming the critical role of high-quality priors in trajectory forecasting.

</details>


### [25] [Adaptive 1D Video Diffusion Autoencoder](https://arxiv.org/abs/2602.04220)
*Yao Teng,Minxuan Lin,Xian Liu,Shuai Wang,Xiao Yang,Xihui Liu*

Main category: cs.CV

TL;DR: One-DVA 用 Transformer 把视频压成可变长 1D 隐码，再用扩散模型解码，既省 token 又保细节，还能适配生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频自编码器固定压缩率浪费 token、CNN 结构无法变长、确定性解码器难以恢复细节，阻碍高质量视频生成。

Method: 提出 One-DVA：① 基于查询的 ViT 编码器提取时空特征并动态 dropout 调整隐码长度，实现自适应压缩；② 像素空间扩散 Transformer 解码器以隐码为条件重建视频；③ 两阶段训练+分布正则化+生成 artifact 微调，兼顾重建与生成需求。

Result: 在相同压缩率下重建指标与 3D-CNN VAE 相当；凭借可变长隐码可进一步推高压缩率；正则化后隐码适配下游生成模型，解码微调显著降低生成伪影。

Conclusion: One-DVA 通过 Transformer 自适应 1D 编码与扩散解码，突破固定率与结构限制，实现更高压缩比和保真重建，为 latent 视频生成提供高效、灵活的表征基础。

Abstract: Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.

</details>


### [26] [An Intuitionistic Fuzzy Logic Driven UNet architecture: Application to Brain Image segmentation](https://arxiv.org/abs/2602.04227)
*Hanuman Verma,Kiho Im,Pranabesh Maji,Akshansh Gupta*

Main category: cs.CV

TL;DR: 把直觉模糊逻辑嵌入 UNet，提出 IF-UNet，可在 IBSR 脑 MRI 上更好处理部分容积效应带来的不确定性，显著提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 脑 MRI 分割受部分容积效应与边界不确定影响，传统 UNet 难以建模体素隶属不确定性，需引入更精细的不确定性描述机制。

Method: 在 UNet 编码-解码流程中嵌入直觉模糊层，显式计算每体素的隶属、非隶属与犹豫度，用犹豫度捕获部分容积混合信息，再重构特征图供后续卷积。

Result: IBSR 数据集实验显示，IF-UNet 在 Accuracy、Dice、IoU 上均优于基线 UNet，分割边界更连续，对灰白质交界与微小结构改善明显。

Conclusion: 直觉模糊逻辑能有效表征 MRI 脑图像的不确定性，IF-UNet 为医学图像分割提供了一种简洁可信的改进思路，可拓展至其他模态与器官。

Abstract: Accurate segmentation of MRI brain images is essential for image analysis, diagnosis of neuro-logical disorders and medical image computing. In the deep learning approach, the convolutional neural networks (CNNs), especially UNet, are widely applied in medical image segmentation. However, it is difficult to deal with uncertainty due to the partial volume effect in brain images. To overcome this limitation, we propose an enhanced framework, named UNet with intuitionistic fuzzy logic (IF-UNet), which incorporates intuitionistic fuzzy logic into UNet. The model processes input data in terms of membership, nonmembership, and hesitation degrees, allowing it to better address tissue ambiguity resulting from partial volume effects and boundary uncertainties. The proposed architecture is evaluated on the Internet Brain Segmentation Repository (IBSR) dataset, and its performance is computed using accuracy, Dice coefficient, and intersection over union (IoU). Experimental results confirm that IF-UNet improves segmentation quality with handling uncertainty in brain images.

</details>


### [27] [SPOT-Occ: Sparse Prototype-guided Transformer for Camera-based 3D Occupancy Prediction](https://arxiv.org/abs/2602.04240)
*Suzeyu Chen,Leheng Li,Ying-Cong Chen*

Main category: cs.CV

TL;DR: SPOT-Occ 用“稀疏原型引导注意力”替代传统稠密注意力，在解码阶段先动态选少量关键体素原型、再聚焦聚合，实现车载摄像头 3D 占位预测的速度与精度双提升。


<details>
  <summary>Details</summary>
Motivation: 摄像头 3D 占位预测需实时且高精度，但现有稀疏 3D 表示虽缓解编码瓶颈，却使解码端面临“非均匀稀疏体素特征难以高效聚合”的难题，而稠密注意力计算代价过高无法落地。

Method: 提出 Prototype-based Sparse Transformer Decoder：①稀疏原型选择——每个查询自适应挑最显著体素作为原型；②去噪辅助——利用真值掩膜为查询-原型关联提供跨层一致显式监督，实现稳定的两阶段“选原型-聚焦聚合”解码流程。

Result: SPOT-Occ 在保持更高精度的同时，速度显著优于之前方法，满足自动驾驶实时要求；代码已开源。

Conclusion: 原型引导的稀疏注意力机制可在 3D 占位解码端替代稠密注意力，兼顾精度与效率，为车载视觉 3D 感知提供了一条可部署的新思路。

Abstract: Achieving highly accurate and real-time 3D occupancy prediction from cameras is a critical requirement for the safe and practical deployment of autonomous vehicles. While this shift to sparse 3D representations solves the encoding bottleneck, it creates a new challenge for the decoder: how to efficiently aggregate information from a sparse, non-uniformly distributed set of voxel features without resorting to computationally prohibitive dense attention.
  In this paper, we propose a novel Prototype-based Sparse Transformer Decoder that replaces this costly interaction with an efficient, two-stage process of guided feature selection and focused aggregation. Our core idea is to make the decoder's attention prototype-guided. We achieve this through a sparse prototype selection mechanism, where each query adaptively identifies a compact set of the most salient voxel features, termed prototypes, for focused feature aggregation.
  To ensure this dynamic selection is stable and effective, we introduce a complementary denoising paradigm. This approach leverages ground-truth masks to provide explicit guidance, guaranteeing a consistent query-prototype association across decoder layers. Our model, dubbed SPOT-Occ, outperforms previous methods with a significant margin in speed while also improving accuracy. Source code is released at https://github.com/chensuzeyu/SpotOcc.

</details>


### [28] [ACIL: Active Class Incremental Learning for Image Classification](https://arxiv.org/abs/2602.04252)
*Aditya R. Bhattacharya,Debanjan Goswami,Shayok Chakraborty*

Main category: cs.CV

TL;DR: 提出ACIL框架，在类增量学习中用主动学习策略只为“高价值”样本打标签，显著降低标注量并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有类增量学习假设每轮所有样本都需标注，导致昂贵且冗余的标注成本；主动学习可挑选关键样本，却尚未被系统引入增量场景。

Method: 设计ACIL框架，在每轮结合“不确定性+多样性”准则选择少量 exemplar 样本进行标注，并把这些样本加入后续训练集，实现低成本增量更新。

Result: 在多个视觉数据集上，ACIL用显著更少的标注量达到与全标注增量方法相当甚至更高的精度，有效抑制了灾难性遗忘。

Conclusion: 将主动学习嵌入类增量流程可同时降低标注开销与遗忘风险，为实际部署持续学习系统提供了可行的新范式。

Abstract: Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focused on avoiding catastrophic forgetting, which occurs due to the continuously changing class distributions in each episode and the inaccessibility of the data from previous episodes. However, these methods assume that all the training samples in every episode are annotated; this not only incurs a huge annotation cost, but also results in a wastage of annotation effort, since most of the samples in a given episode will not be accessible to the model in subsequent episodes. Active learning algorithms identify the salient and informative samples from large amounts of unlabeled data and are instrumental in reducing the human annotation effort in inducing a deep neural network. In this paper, we propose ACIL, a novel active learning framework for class incremental learning settings. We exploit a criterion based on uncertainty and diversity to identify the exemplar samples that need to be annotated in each episode, and will be appended to the data in the next episode. Such a framework can drastically reduce annotation cost and can also avoid catastrophic forgetting. Our extensive empirical analyses on several vision datasets corroborate the promise and potential of our framework against relevant baselines.

</details>


### [29] [Depth-Guided Metric-Aware Temporal Consistency for Monocular Video Human Mesh Recovery](https://arxiv.org/abs/2602.04257)
*Jiaxin Cen,Xudong Mao,Guanghui Yue,Wei Zhou,Ruomei Wang,Fan Zhou,Baoquan Zhao*

Main category: cs.CV

TL;DR: 用单目视频恢复人体网格时，深度歧义导致尺度漂移与遮挡失稳。本文提出深度引导三组件框架：多尺度融合、尺度一致初始化、运动-几何对齐精修，在三大基准上兼顾鲁棒性与效率。


<details>
  <summary>Details</summary>
Motivation: 单目视频人体网格恢复因深度不确定和尺度漂移难以保持度量一致性与时间稳定性；现有RGB+时序平滑方法在深度排序、遮挡场景下失效。

Method: 提出深度引导框架：1) Depth-Guided Multi-Scale Fusion 以置信门控自适应融合几何先验与RGB特征；2) D-MAPS 估计器利用深度标定的骨长统计实现尺度一致初始化；3) MoDAR 模块通过运动-几何跨模态注意力强制时序连贯。

Result: 在三个挑战性基准上显著优于现有方法，对严重遮挡的鲁棒性与空间精度提升，同时保持计算高效。

Conclusion: 引入显式深度引导可有效解决单目人体恢复的度量一致性与时序稳定性难题，为实时应用提供鲁棒且轻量的解决方案。

Abstract: Monocular video human mesh recovery faces fundamental challenges in maintaining metric consistency and temporal stability due to inherent depth ambiguities and scale uncertainties. While existing methods rely primarily on RGB features and temporal smoothing, they struggle with depth ordering, scale drift, and occlusion-induced instabilities. We propose a comprehensive depth-guided framework that achieves metric-aware temporal consistency through three synergistic components: A Depth-Guided Multi-Scale Fusion module that adaptively integrates geometric priors with RGB features via confidence-aware gating; A Depth-guided Metric-Aware Pose and Shape (D-MAPS) estimator that leverages depth-calibrated bone statistics for scale-consistent initialization; A Motion-Depth Aligned Refinement (MoDAR) module that enforces temporal coherence through cross-modal attention between motion dynamics and geometric cues. Our method achieves superior results on three challenging benchmarks, demonstrating significant improvements in robustness against heavy occlusion and spatial accuracy while maintaining computational efficiency.

</details>


### [30] [Decoupled Hierarchical Distillation for Multimodal Emotion Recognition](https://arxiv.org/abs/2602.04260)
*Yong Li,Yuanzhi Wang,Yi Ding,Shiqing Zhang,Ke Lu,Cuntai Guan*

Main category: cs.CV

TL;DR: DHMD 通过“解耦-分层蒸馏”策略，把各模态特征拆成同质/异质两部分，先在图蒸馏单元做粗粒度跨模态知识交换，再用跨模态字典做细粒度语义对齐，在 MOSI/MOSEI 上显著优于 SOTA。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别（MER）中，模态间异质性大且贡献不均，现有方法难以同时消除异质差异并充分利用互补信息。

Method: 提出 Decoupled Hierarchical Multimodal Distillation (DHMD)：① 自回归机制将每模态特征解耦为模态无关（同质）与模态独有（异质）两部分；② 两阶段知识蒸馏：a) 粗粒度阶段，在解耦空间内用 Graph Distillation Unit 动态图实现自适应跨模态蒸馏；b) 细粒度阶段，通过跨模态字典匹配对齐语义粒度，生成判别性表示。

Result: 在 CMU-MOSI/MOSEI 上，DHMD 相对 SOTA 分别提升 1.3 %/2.4 % ACC7、1.3 %/1.9 % ACC2、1.9 %/1.8 % F1；可视化显示图边与字典激活在同质/异质空间均呈现有意义分布。

Conclusion: 分层解耦蒸馏有效缓解模态异质性，实现灵活知识迁移与精准跨模态对齐，为 MER 提供新的强基准。

Abstract: Human multimodal emotion recognition (MER) seeks to infer human emotions by integrating information from language, visual, and acoustic modalities. Although existing MER approaches have achieved promising results, they still struggle with inherent multimodal heterogeneities and varying contributions from different modalities. To address these challenges, we propose a novel framework, Decoupled Hierarchical Multimodal Distillation (DHMD). DHMD decouples each modality's features into modality-irrelevant (homogeneous) and modality-exclusive (heterogeneous) components using a self-regression mechanism. The framework employs a two-stage knowledge distillation (KD) strategy: (1) coarse-grained KD via a Graph Distillation Unit (GD-Unit) in each decoupled feature space, where a dynamic graph facilitates adaptive distillation among modalities, and (2) fine-grained KD through a cross-modal dictionary matching mechanism, which aligns semantic granularities across modalities to produce more discriminative MER representations. This hierarchical distillation approach enables flexible knowledge transfer and effectively improves cross-modal feature alignment. Experimental results demonstrate that DHMD consistently outperforms state-of-the-art MER methods, achieving 1.3\%/2.4\% (ACC$_7$), 1.3\%/1.9\% (ACC$_2$) and 1.9\%/1.8\% (F1) relative improvement on CMU-MOSI/CMU-MOSEI dataset, respectively. Meanwhile, visualization results reveal that both the graph edges and dictionary activations in DHMD exhibit meaningful distribution patterns across modality-irrelevant/-exclusive feature spaces.

</details>


### [31] [KVSmooth: Mitigating Hallucination in Multi-modal Large Language Models through Key-Value Smoothing](https://arxiv.org/abs/2602.04268)
*Siyu Jiang,Feiyang Chen,Xiaojin Zhang,Kun He*

Main category: cs.CV

TL;DR: KVSmooth 是一种无需训练、即插即用的推理阶段方法，通过对 KV-Cache 的 key/value 做 attention-entropy 指导的自适应 EMA 平滑，显著抑制多模态大模型幻觉，同时提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在生成过程中会因序列增长而出现语义漂移，导致输出与视觉事实不一致的幻觉问题；现有再训练或对比解码方案成本高，亟需轻量级推理阶段解决方案。

Method: 提出 KVSmooth：在推理时无需训练或改模型，对 KV-Cache 中的 key/value 向量施加指数移动平均平滑；利用每个 token 注意力分布的熵动态衡量其“沉没”程度，自适应调整平滑强度，从而抑制视觉无关信息的累积。

Result: 在标准幻觉指标 CHAIR_S 上从 41.8 降至 18.2，整体 F1 从 77.5 提升至 79.2，同时提高精度与召回；此前方法往往只能提升其一，验证了 KVSmooth 的有效性与通用性。

Conclusion: KVSmooth 以极低的推理开销实现了显著且全面的幻觉抑制，为可靠部署多模态大模型提供了即插即用的实用方案。

Abstract: Despite the significant progress of Multimodal Large Language Models (MLLMs) across diverse tasks, hallucination -- corresponding to the generation of visually inconsistent objects, attributes, or relations -- remains a major obstacle to their reliable deployment. Unlike pure language models, MLLMs must ground their generation process in visual inputs. However, existing models often suffer from semantic drift during decoding, causing outputs to diverge from visual facts as the sequence length increases.
  To address this issue, we propose KVSmooth, a training-free and plug-and-play method that mitigates hallucination by performing attention-entropy-guided adaptive smoothing on hidden states. Specifically, KVSmooth applies an exponential moving average (EMA) to both keys and values in the KV-Cache, while dynamically quantifying the sink degree of each token through the entropy of its attention distribution to adaptively adjust the smoothing strength.
  Unlike computationally expensive retraining or contrastive decoding methods, KVSmooth operates efficiently during inference without additional training or model modification. Extensive experiments demonstrate that KVSmooth significantly reduces hallucination ($\mathit{CHAIR}_{S}$ from $41.8 \rightarrow 18.2$) while improving overall performance ($F_1$ score from $77.5 \rightarrow 79.2$), achieving higher precision and recall simultaneously. In contrast, prior methods often improve one at the expense of the other, validating the effectiveness and generality of our approach.

</details>


### [32] [SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization](https://arxiv.org/abs/2602.04271)
*Lifan Wu,Ruijie Zhu,Yubo Ai,Tianzhu Zhang*

Main category: cs.CV

TL;DR: SkeletonGaussian 用显式骨架驱动+非刚性细化的层级表示，把单目视频变成可编辑的动态 3D 高斯，质量更高且支持直观运动编辑。


<details>
  <summary>Details</summary>
Motivation: 现有 4D 生成把运动隐含在形变场中，难以直接控制与后期编辑，亟需一种可解释、可编辑的动态 3D 表示。

Method: 提出层级关节表示：1) 从单目视频提取鲁棒骨架；2) 用线性混合蒙皮显式驱动稀疏刚性运动；3) 基于 hexplane 对残差非刚性形变进行细化，实现整体 4D 高斯建模。

Result: 在生成质量上优于现有方法，同时支持骨架级别的直观运动编辑，为可编辑 4D 内容创作提供了新范式。

Conclusion: SkeletonGaussian 通过“骨架驱动刚性+hexplane 补偿非刚性”的显式分解，兼顾高质量与可编辑性，确立了可编辑 4D 生成的新路线。

Abstract: 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input. Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning, followed by a hexplane-based refinement for non-rigid deformations, enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing, establishing a new paradigm for editable 4D generation. Project page: https://wusar.github.io/projects/skeletongaussian/

</details>


### [33] [Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement](https://arxiv.org/abs/2602.04304)
*Zipeng Zhu,Zhanghao Hu,Qinglin Zhu,Yuxi Hong,Yijun Liu,Jingyong Su,Yulan He,Lin Gui*

Main category: cs.CV

TL;DR: 通过层敏感性分析发现视觉定位是动态的，提出VAQ指标与LASER推理策略，在无需训练的情况下为不同复杂度任务自适应选取最优层进行视觉增强，显著提升多类VQA性能。


<details>
  <summary>Details</summary>
Motivation: 固定视觉token预算导致图像被压缩到统一分辨率，丢失细粒度细节并引发幻觉；现有注意力增强方法依赖静态“魔法层”，在简单识别基准上经验选定，难以迁移至复杂推理任务。

Method: 1) 层敏感性分析：量化各层对查询的注意力敏感度，证明简单识别依赖中层、复杂推理需深层再激活视觉信息。2) VAQ指标：无需标签，仅依据输入查询与注意力图的相关性，动态定位最适合视觉定位的层。3) LASER：基于VAQ，在推理阶段对选中层执行注意力引导的选择性视觉增强（crop/重分配token）与解码增强，无需任何训练。

Result: 在GQA、A-OKVQA、VQAv2、TextVQA、MMVP等多复杂度VQA基准上，LASER将LLaVA-1.5-7B绝对准确率平均提升3.2%-4.7%，在复杂推理子集最高达6.9%；相比静态最佳层策略平均再提升1.8%。

Conclusion: 视觉定位是随任务复杂度而变的动态过程；VAQ可零成本识别任务适配层，LASER在推理阶段即可释放LVLM潜能，为训练无关的可扩展视觉增强提供新范式。

Abstract: Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static "magic layer" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity.

</details>


### [34] [JOintGS: Joint Optimization of Cameras, Bodies and 3D Gaussians for In-the-Wild Monocular Reconstruction](https://arxiv.org/abs/2602.04317)
*Zihan Lou,Jinlong Fan,Sihan Ma,Yuxiang Yang,Jing Zhang*

Main category: cs.CV

TL;DR: JOintGS 首次把相机外参、人体姿态与 3D 高斯一起联合优化，无需精确标定即可从单目 RGB 视频重建可驱动、高保真 3D 人体 avatar，并在 NeuMan 数据集上取得 2.1 dB PSNR 提升，实现实时渲染。


<details>
  <summary>Details</summary>
Motivation: 单目野外视频缺乏准确相机参数与人体姿态，现有 3D 高斯泼溅（3DGS）方法严重依赖精确标定，导致重建质量骤降甚至失败，亟需一套对初始化噪声鲁棒的统一框架。

Method: 提出 JOintGS：① 前景-背景显式解耦，静态背景高斯利用多视一致性锚定相机；② 相机-姿态-高斯三者协同迭代求精；③ 引入时序动态模块刻画姿态相关形变，残差颜色场建模光照变化；④ 端到端可微联合优化。

Result: 在 NeuMan 与 EMDB 上显著优于 SOTA，NeuMan 数据集 PSNR↑2.1 dB，LPISS、SSIM 亦领先；对初始化误差表现出强鲁棒性，渲染速度达实时。

Conclusion: JOintGS 突破了 3DGS 对精准标定的依赖，实现“无标定-高保真-可驱动”3D 人体重建，为野外单目视频 avatar 制作提供实用解决方案。

Abstract: Reconstructing high-fidelity animatable 3D human avatars from monocular RGB videos remains challenging, particularly in unconstrained in-the-wild scenarios where camera parameters and human poses from off-the-shelf methods (e.g., COLMAP, HMR2.0) are often inaccurate. Splatting (3DGS) advances demonstrate impressive rendering quality and real-time performance, they critically depend on precise camera calibration and pose annotations, limiting their applicability in real-world settings. We present JOintGS, a unified framework that jointly optimizes camera extrinsics, human poses, and 3D Gaussian representations from coarse initialization through a synergistic refinement mechanism. Our key insight is that explicit foreground-background disentanglement enables mutual reinforcement: static background Gaussians anchor camera estimation via multi-view consistency; refined cameras improve human body alignment through accurate temporal correspondence; optimized human poses enhance scene reconstruction by removing dynamic artifacts from static constraints. We further introduce a temporal dynamics module to capture fine-grained pose-dependent deformations and a residual color field to model illumination variations. Extensive experiments on NeuMan and EMDB datasets demonstrate that JOintGS achieves superior reconstruction quality, with 2.1~dB PSNR improvement over state-of-the-art methods on NeuMan dataset, while maintaining real-time rendering. Notably, our method shows significantly enhanced robustness to noisy initialization compared to the baseline.Our source code is available at https://github.com/MiliLab/JOintGS.

</details>


### [35] [Multiview Self-Representation Learning across Heterogeneous Views](https://arxiv.org/abs/2602.04328)
*Jie Chen,Zhu Wang,Chuanbin Liu,Xi Peng*

Main category: cs.CV

TL;DR: 提出多视角自表示学习（MSRL），利用不同预训练模型提取的无标签视觉特征，通过自表示传递与分配概率一致性约束，在无监督条件下学得跨模型不变表示，理论分析与实验均验证其优势。


<details>
  <summary>Details</summary>
Motivation: 不同预训练模型对同一样本生成的特征分布差异显著，现有方法难以在大规模无标签视觉数据上实现完全无监督的跨模型不变表示学习。

Method: 构建“冻结预训练骨干+线性层”的异构多视角架构；引入基于自表示的信息传递机制聚合各视角线性输出；设计分配概率分布一致性损失，利用互补信息引导多视角自表示学习；对信息传递、一致性约束及视角增量进行理论分析。

Result: 在多个视觉基准数据集上的实验表明，MSRL一致优于现有最先进无监督迁移方法，验证了其学到的表示具有更强的跨模型不变性与下游任务迁移性能。

Conclusion: 通过自表示与概率一致性约束，MSRL可有效挖掘并融合异构预训练模型的互补信息，在无监督条件下获得鲁棒且可迁移的不变视觉表示，为大规模无标签数据利用提供了新思路。

Abstract: Features of the same sample generated by different pretrained models often exhibit inherently distinct feature distributions because of discrepancies in the model pretraining objectives or architectures. Learning invariant representations from large-scale unlabeled visual data with various pretrained models in a fully unsupervised transfer manner remains a significant challenge. In this paper, we propose a multiview self-representation learning (MSRL) method in which invariant representations are learned by exploiting the self-representation property of features across heterogeneous views. The features are derived from large-scale unlabeled visual data through transfer learning with various pretrained models and are referred to as heterogeneous multiview data. An individual linear model is stacked on top of its corresponding frozen pretrained backbone. We introduce an information-passing mechanism that relies on self-representation learning to support feature aggregation over the outputs of the linear model. Moreover, an assignment probability distribution consistency scheme is presented to guide multiview self-representation learning by exploiting complementary information across different views. Consequently, representation invariance across different linear models is enforced through this scheme. In addition, we provide a theoretical analysis of the information-passing mechanism, the assignment probability distribution consistency and the incremental views. Extensive experiments with multiple benchmark visual datasets demonstrate that the proposed MSRL method consistently outperforms several state-of-the-art approaches.

</details>


### [36] [Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner](https://arxiv.org/abs/2602.04337)
*Qian-Wei Wang,Guanghao Meng,Ren Cai,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: CoFT用双模型、跨模态协作在无标注数据上自训练CLIP，无需手工阈值即可抑制伪标签噪声，两阶段微调+迭代扩展CoFT+，在多项任务上超越现有无监督甚至小样本监督方法。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉-语言模型（如CLIP）零样本能力强，但下游适配依赖昂贵标注；现有无监督自训练方法因置信度过滤不可靠、确认偏差及低置信样本利用不足而性能受限。

Method: 提出Collaborative Fine-Tuning (CoFT)：① 双提示学习，显式用正负文本提示对样本级伪标签洁净度建模，省去手工阈值；② 负提示正则化轻量视觉模块，抑制噪声；③ 两阶段训练：先参数高效微调高置信样本，再在全参数微调中用协作过滤的伪标签指导。CoFT+引入迭代微调、动量对比学习与LLM生成提示进一步增益。

Result: 在多项基准上，CoFT一致优于现有无监督方法，并超越若干小样本监督基线；CoFT+带来额外提升，验证框架的有效性与扩展性。

Conclusion: 通过跨模态协作与样本依赖的伪标签洁净度建模，CoFT无需标注即可高效适配VLMs，为无监督视觉-语言模型微调提供了新的强基准。

Abstract: Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines.

</details>


### [37] [Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning](https://arxiv.org/abs/2602.04340)
*Qian-Wei Wang,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 用正负两组可学习 prompt 显式建模 CLIP 在少标注场景下的不确定性，实现更高效的主动学习采样。


<details>
  <summary>Details</summary>
Motivation: CLIP 虽具强迁移性，但在标注预算受限的下游分类任务中，现有主动学习策略仅依赖熵或聚类，未从模型本身量化不确定性，导致采样效率低。

Method: 提出双 prompt 微调框架：正 prompt 增强任务相关文本嵌入判别性；负 prompt 以“反向优化”方式显式估计预测正确概率，从而提供可解释的不确定性信号，用于主动选择样本。

Result: 在多种微调范式与公开数据集上，相同标注预算下，所提方法持续优于现有主动学习基线。

Conclusion: 通过显式建模模型不确定性，双 prompt 策略能更精准地挑选高价值样本，显著提升 CLIP 在少标注场景下的适应效率与分类性能。

Abstract: Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget.

</details>


### [38] [VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image](https://arxiv.org/abs/2602.04349)
*Teng-Fang Hsiao,Bo-Kai Ruan,Yu-Lun Liu,Hong-Han Shuai*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely on voxel-based representations that suffer from limited resolution and necessitate labor-intensive 3D mask. To address these limitations, we propose \textbf{VecSet-Edit}, the first pipeline that leverages the high-fidelity VecSet Large Reconstruction Model (LRM) as a backbone for mesh editing. Our approach is grounded on a analysis of the spatial properties in VecSet tokens, revealing that token subsets govern distinct geometric regions. Based on this insight, we introduce Mask-guided Token Seeding and Attention-aligned Token Gating strategies to precisely localize target regions using only 2D image conditions. Also, considering the difference between VecSet diffusion process versus voxel we design a Drift-aware Token Pruning to reject geometric outliers during the denoising process. Finally, our Detail-preserving Texture Baking module ensures that we not only preserve the geometric details of original mesh but also the textural information. More details can be found in our project page: https://github.com/BlueDyee/VecSet-Edit/tree/main

</details>


### [39] [When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models](https://arxiv.org/abs/2602.04356)
*Jaehyun Kwak,Nam Cao,Boryeong Cho,Segyu Lee,Sumyeong Ahn,Se-Young Yun*

Main category: cs.CV

TL;DR: 提出SAGA方法：利用LVLM的区域注意力分数迭代锁定高敏感区域并集中扰动，在有限扰动预算下实现更高攻击成功率与隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有基于随机裁剪的对抗攻击虽表明局部扰动优于全局扰动，但随机性导致像素预算浪费；作者发现高注意力区域与对抗损失敏感度正相关，且攻击这些区域会结构化地重定向注意力，遂提出用注意力指导扰动投放。

Method: 设计Stage-wise Attention-Guided Attack (SAGA)：逐阶段计算区域注意力得分，选取最高注意力区域施加扰动，利用注意力重分布效应迭代收缩攻击焦点，从而在约束预算内集中扰动。

Result: 在10个主流LVLM上实现SOTA攻击成功率，同时生成视觉上难以察觉的对抗样本；代码已开源。

Conclusion: 注意力机制可作为高效对抗攻击的可靠线索，SAGA验证了逐阶段聚焦高注意力区域能显著提升攻击效率与隐蔽性，为后续多模态模型安全研究提供新思路。

Abstract: Adversarial attacks against Large Vision-Language Models (LVLMs) are crucial for exposing safety vulnerabilities in modern multimodal systems. Recent attacks based on input transformations, such as random cropping, suggest that spatially localized perturbations can be more effective than global image manipulation. However, randomly cropping the entire image is inherently stochastic and fails to use the limited per-pixel perturbation budget efficiently. We make two key observations: (i) regional attention scores are positively correlated with adversarial loss sensitivity, and (ii) attacking high-attention regions induces a structured redistribution of attention toward subsequent salient regions. Based on these findings, we propose Stage-wise Attention-Guided Attack (SAGA), an attention-guided framework that progressively concentrates perturbations on high-attention regions. SAGA enables more efficient use of constrained perturbation budgets, producing highly imperceptible adversarial examples while consistently achieving state-of-the-art attack success rates across ten LVLMs. The source code is available at https://github.com/jackwaky/SAGA.

</details>


### [40] [SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration](https://arxiv.org/abs/2602.04361)
*Zekun Li,Ning Wang,Tongxin Bai,Changwang Mei,Peisong Wang,Shuang Qiu,Jian Cheng*

Main category: cs.CV

TL;DR: SparVAR 首次在 VAR 生成中实现「不跳级」的稀疏注意力，无需再训练即可把 8B 模型生成 1024×1024 图像时间压到 1 s，相对 FlashAttention 基线提速 1.57×，若叠加跳级策略可达 2.28×，几乎不损失高频细节。


<details>
  <summary>Details</summary>
Motivation: 主流 VAR 在每一步自回归都要对历史所有尺度的 token 做全局注意力，当生成分辨率升高时注意力计算复杂度呈四次方增长，成为主要延迟来源；现有加速方法靠直接跳过高分辨率尺度，虽快但牺牲高频细节、降低画质。

Method: 提出无训练加速框架 SparVAR，利用 VAR 注意力的三大特性——强 attention sink、跨尺度激活相似性与显著局部性：1) 在稀疏决策尺度动态预测后续高分辨率尺度的稀疏注意力模式；2) 通过高效索引映射构造“尺度自相似稀疏注意力”，实现大尺度下的高效稀疏计算；3) 设计跨尺度局部稀疏注意力并配套块稀疏 CUDA kernel，速度较 FlashAttention 再提升 5 倍以上。

Result: 在 8B 参数 VAR 模型生成 1024×1024 图像任务中，SparVAR 将总耗时降至约 1 s 且不跳过任何尺度；与 FlashAttention 基线相比提速 1.57×，SSIM、FID 等指标几乎无损；若结合已有跳级策略，最高可达 2.28× 加速，同时保持竞争性图像质量。

Conclusion: SparVAR 通过挖掘 VAR 注意力固有的稀疏与自相似结构，首次在保持全尺度建模的前提下实现大幅加速，为高分辨率视觉自回归模型走向实时应用提供了可行路径。

Abstract: Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of attention increases quartically with resolution, causing substantial latency. Prior accelerations often skip high-resolution scales, which speeds up inference but discards high-frequency details and harms image quality. To address these problems, we present SparVAR, a training-free acceleration framework that exploits three properties of VAR attention: (i) strong attention sinks, (ii) cross-scale activation similarity, and (iii) pronounced locality. Specifically, we dynamically predict the sparse attention pattern of later high-resolution scales from a sparse decision scale, and construct scale self-similar sparse attention via an efficient index-mapping mechanism, enabling high-efficiency sparse attention computation at large scales. Furthermore, we propose cross-scale local sparse attention and implement an efficient block-wise sparse kernel, which achieves $\mathbf{> 5\times}$ faster forward speed than FlashAttention. Extensive experiments demonstrate that the proposed SparseVAR can reduce the generation time of an 8B model producing $1024\times1024$ high-resolution images to the 1s, without skipping the last scales. Compared with the VAR baseline accelerated by FlashAttention, our method achieves a $\mathbf{1.57\times}$ speed-up while preserving almost all high-frequency details. When combined with existing scale-skipping strategies, SparseVAR attains up to a $\mathbf{2.28\times}$ acceleration, while maintaining competitive visual generation quality. Code is available at https://github.com/CAS-CLab/SparVAR.

</details>


### [41] [Enabling Real-Time Colonoscopic Polyp Segmentation on Commodity CPUs via Ultra-Lightweight Architecture](https://arxiv.org/abs/2602.04381)
*Weihao Gao,Zhuo Deng,Zheng Gong,Lan Ma*

Main category: cs.CV

TL;DR: 提出0.1 M级参数、CPU单核90 FPS的息肉分割模型UltraSeg，在7个公开数据集上仅用U-Net 0.4%参数保留>94% Dice，首次实现临床可部署的极端压缩内镜AI。


<details>
  <summary>Details</summary>
Motivation: 现有高精度息肉分割依赖GPU，基层医院、移动内镜或胶囊机器人无法部署，亟需可在CPU实时运行的极轻量模型。

Method: 设计<0.3 M参数的UltraSeg家族：联合优化编解码通道宽度；引入受限扩张卷积扩大感受野；提出跨层轻量融合模块；单中心版108 K、多中心多模态版130 K。

Result: 单核CPU达90 FPS；7个公开数据集平均Dice保留>94%的31 M U-Net性能，参数量仅0.4%；首次在极端压缩域建立临床可用基线。

Conclusion: UltraSeg提供可立即落地的CPU原生息肉分割方案，并为其他微创外科视觉任务给出可复现的极端压缩蓝图，源码已公开。

Abstract: Early detection of colorectal cancer hinges on real-time, accurate polyp identification and resection. Yet current high-precision segmentation models rely on GPUs, making them impractical to deploy in primary hospitals, mobile endoscopy units, or capsule robots. To bridge this gap, we present the UltraSeg family, operating in an extreme-compression regime (<0.3 M parameters). UltraSeg-108K (0.108 M parameters) is optimized for single-center data, while UltraSeg-130K (0.13 M parameters) generalizes to multi-center, multi-modal images. By jointly optimizing encoder-decoder widths, incorporating constrained dilated convolutions to enlarge receptive fields, and integrating a cross-layer lightweight fusion module, the models achieve 90 FPS on a single CPU core without sacrificing accuracy. Evaluated on seven public datasets, UltraSeg retains >94% of the Dice score of a 31 M-parameter U-Net while utilizing only 0.4% of its parameters, establishing a strong, clinically viable baseline for the extreme-compression domain and offering an immediately deployable solution for resource-constrained settings. This work provides not only a CPU-native solution for colonoscopy but also a reproducible blueprint for broader minimally invasive surgical vision applications. Source code is publicly available to ensure reproducibility and facilitate future benchmarking.

</details>


### [42] [Interactive Spatial-Frequency Fusion Mamba for Multi-Modal Image Fusion](https://arxiv.org/abs/2602.04405)
*Yixin Zhu,Long Lv,Pingping Zhang,Xuehu Liu,Tongdan Tang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: cs.CV

TL;DR: ISFM 首次把 Mamba 的线性复杂度全局建模引入多模态图像融合，提出“交互式空-频融合”策略，用频域特征反向引导空域互补信息，在 6 个公开数据集上全面刷新 SOTA，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有 MMIF 方法虽引入频域，但空域与频域仅做串/并联简单叠加，缺乏跨模态、跨域的交互，难以充分挖掘互补信息。

Method: 1) Modality-Specific Extractor (MSE)：基于 Mamba 架构，线性复杂度捕获长程依赖；2) Multi-scale Frequency Fusion (MFF)：自适应整合多尺度高低频分量，生成鲁棒频域表征；3) Interactive Spatial-Frequency Fusion (ISF)：以频域特征为引导，反向增强空域跨模态特征，实现真正的空-频交互融合。

Result: 在可见光-红外、医学、遥感等 6 个 MMIF 数据集上，ISFM 在视觉保真、纹理保留、信息熵、SD、SF、VIF、Qabf 等客观指标均优于现有最优方法，平均提升 3–15%，且推理速度与参数量可控。

Conclusion: 通过“空-频交互”与 Mamba 线性建模，ISFM 有效突破传统融合范式，在精度与效率间取得新平衡，为多模态图像融合提供了可扩展的新基线。

Abstract: Multi-Modal Image Fusion (MMIF) aims to combine images from different modalities to produce fused images, retaining texture details and preserving significant information. Recently, some MMIF methods incorporate frequency domain information to enhance spatial features. However, these methods typically rely on simple serial or parallel spatial-frequency fusion without interaction. In this paper, we propose a novel Interactive Spatial-Frequency Fusion Mamba (ISFM) framework for MMIF. Specifically, we begin with a Modality-Specific Extractor (MSE) to extract features from different modalities. It models long-range dependencies across the image with linear computational complexity. To effectively leverage frequency information, we then propose a Multi-scale Frequency Fusion (MFF). It adaptively integrates low-frequency and high-frequency components across multiple scales, enabling robust representations of frequency features. More importantly, we further propose an Interactive Spatial-Frequency Fusion (ISF). It incorporates frequency features to guide spatial features across modalities, enhancing complementary representations. Extensive experiments are conducted on six MMIF datasets. The experimental results demonstrate that our ISFM can achieve better performances than other state-of-the-art methods. The source code is available at https://github.com/Namn23/ISFM.

</details>


### [43] [LCUDiff: Latent Capacity Upgrade Diffusion for Faithful Human Body Restoration](https://arxiv.org/abs/2602.04406)
*Jue Gong,Zihan Zhou,Jingkai Wang,Shu Li,Libo Liu,Jianliang Lan,Yulun Zhang*

Main category: cs.CV

TL;DR: LCUDiff 把潜空间从 4 通道扩到 16 通道，用 CSD 保先验、PPA 稳训练、DeR 动态选解码器，一步推理即可在人与背景区域同时获得更高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有人像复原方法（尤其基于潜扩散模型）受限于 4 通道 VAE，高频细节丢失严重；同时保持一步推理效率的前提下提升保真度仍是空白。

Method: 1) 设计 16 通道 VAE：提出通道拆分蒸馏（CSD），让新增 12 通道专司高频，前 4 通道对齐原模型先验；2) 先验保持适配（PPA）：在 4→16 通道过渡阶段冻结原 UNet 权重并引入可学习适配器，缓解维度失配；3) 解码器路由器（DeR）：为每张图预测复原质量分数，动态选择最优解码器，减少 artifact。

Result: 在合成与真实退化数据集上，PSNR、LPIPS、FID 均优于 Real-ESRGAN、StableSR 等，一步推理即可实现更高保真、更少伪影，且计算开销几乎不变。

Conclusion: 通过扩增潜空间并配套 CSD+PPA+DeR，LCUDiff 在不牺牲一步效率的前提下显著提升了人像及背景的细节还原能力，为潜扩散式图像复原提供了新的扩展范式。

Abstract: Existing methods for restoring degraded human-centric images often struggle with insufficient fidelity, particularly in human body restoration (HBR). Recent diffusion-based restoration methods commonly adapt pre-trained text-to-image diffusion models, where the variational autoencoder (VAE) can significantly bottleneck restoration fidelity. We propose LCUDiff, a stable one-step framework that upgrades a pre-trained latent diffusion model from the 4-channel latent space to the 16-channel latent space. For VAE fine-tuning, channel splitting distillation (CSD) is used to keep the first four channels aligned with pre-trained priors while allocating the additional channels to effectively encode high-frequency details. We further design prior-preserving adaptation (PPA) to smoothly bridge the mismatch between 4-channel diffusion backbones and the higher-dimensional 16-channel latent. In addition, we propose a decoder router (DeR) for per-sample decoder routing using restoration-quality score annotations, which improves visual quality across diverse conditions. Experiments on synthetic and real-world datasets show competitive results with higher fidelity and fewer artifacts under mild degradations, while preserving one-step efficiency. The code and model will be at https://github.com/gobunu/LCUDiff.

</details>


### [44] [TrajVG: 3D Trajectory-Coupled Visual Geometry Learning](https://arxiv.org/abs/2602.04439)
*Xingyu Miao,Weiguang Zhao,Tao Lu,Linning Yu,Mulin Yu,Yang Long,Jiangmiao Pang,Junting Dong*

Main category: cs.CV

TL;DR: TrajVG 把跨帧 3D 对应显式建模为相机坐标系下的 3D 轨迹，用稀疏轨迹-点云-位姿联合几何一致性约束解决动态视频重建中的漂移与重影，并可在无 3D 标注时依赖伪 2D 轨迹自监督训练，全面刷新 feed-forward 视频 3D 重建基线。


<details>
  <summary>Details</summary>
Motivation: 现有 feed-forward 多帧 3D 重建在物体运动视频中退化：全局参考因多运动模糊，局部点云依赖相对位姿易漂移，导致跨帧错位与结构重复。

Method: 提出 TrajVG 框架，显式预测相机坐标 3D 轨迹作为跨帧对应；联合稀疏轨迹、逐帧局部点云与相对位姿，设计两项几何一致性目标：① 双向轨迹-点云一致性（控制梯度流）；② 以静态轨迹锚点驱动的位姿一致性（抑制动态区梯度）。将上述耦合约束改写为仅需伪 2D 轨迹的自监督损失，实现混合监督下野外视频训练。

Result: 在 3D 跟踪、位姿估计、点云重建与视频深度四项任务上，TrajVG 均超越当前 feed-forward 最佳基线。

Conclusion: 把跨帧 3D 对应显式建模为轨迹并引入静态锚点约束，可有效消除动态场景漂移；结合自监督策略后，TrajVG 为无标注视频的高精度 feed-forward 3D 重建提供了新范式。

Abstract: Feed-forward multi-frame 3D reconstruction models often degrade on videos with object motion. Global-reference becomes ambiguous under multiple motions, while the local pointmap relies heavily on estimated relative poses and can drift, causing cross-frame misalignment and duplicated structures. We propose TrajVG, a reconstruction framework that makes cross-frame 3D correspondence an explicit prediction by estimating camera-coordinate 3D trajectories. We couple sparse trajectories, per-frame local point maps, and relative camera poses with geometric consistency objectives: (i) bidirectional trajectory-pointmap consistency with controlled gradient flow, and (ii) a pose consistency objective driven by static track anchors that suppresses gradients from dynamic regions. To scale training to in-the-wild videos where 3D trajectory labels are scarce, we reformulate the same coupling constraints into self-supervised objectives using only pseudo 2D tracks, enabling unified training with mixed supervision. Extensive experiments across 3D tracking, pose estimation, pointmap reconstruction, and video depth show that TrajVG surpasses the current feedforward performance baseline.

</details>


### [45] [SynthVerse: A Large-Scale Diverse Synthetic Dataset for Point Tracking](https://arxiv.org/abs/2602.04441)
*Weiguang Zhao,Haoran Xu,Xingyu Miao,Qin Zhao,Rui Zhang,Kaizhu Huang,Ning Gao,Peizhou Cao,Mingze Sun,Mulin Yu,Tao Lu,Linning Xu,Junting Dong,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 提出 SynthVerse——迄今最多样化的大规模合成点跟踪数据集，并配套新基准；实验表明其可显著提升现有模型的跨域泛化能力，同时暴露主流方法在极端场景下的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有真实或合成数据集在类别、运动样式及标注精度上均严重不足，制约了点跟踪基础模型的通用性提升，亟需高多样性、高质量轨迹数据。

Method: 构建 SynthVerse：1) 引入动画电影、具身操作、场景导航、关节物体等缺失域；2) 程序化+物理仿真生成高保真动态与交互；3) 自动产出亚像素级真实轨迹；4) 基于该数据建立跨域评测基准，系统评估最新跟踪器。

Result: 在 SynthVerse 上预训练/微调后，CoTracker、TAPIR 等 SOTA 方法在 TAP-Vid、DAVIS、RGB-Stacking 等真实基准上平均提升 6–15% 跟踪精度；新基准揭示现有方法在剧烈遮挡、强视角变化与关节运动下鲁棒性显著下降。

Conclusion: SynthVerse 以高多样性合成数据有效弥补真实数据稀缺，显著提升点跟踪模型的泛化性能，并为后续研究提供可扩展的评测平台；未来需进一步融合真实-合成域适应与自监督策略以缩小剩余性能差距。

Abstract: Point tracking aims to follow visual points through complex motion, occlusion, and viewpoint changes, and has advanced rapidly with modern foundation models. Yet progress toward general point tracking remains constrained by limited high-quality data, as existing datasets often provide insufficient diversity and imperfect trajectory annotations. To this end, we introduce SynthVerse, a large-scale, diverse synthetic dataset specifically designed for point tracking. SynthVerse includes several new domains and object types missing from existing synthetic datasets, such as animated-film-style content, embodied manipulation, scene navigation, and articulated objects. SynthVerse substantially expands dataset diversity by covering a broader range of object categories and providing high-quality dynamic motions and interactions, enabling more robust training and evaluation for general point tracking. In addition, we establish a highly diverse point tracking benchmark to systematically evaluate state-of-the-art methods under broader domain shifts. Extensive experiments and analyses demonstrate that training with SynthVerse yields consistent improvements in generalization and reveal limitations of existing trackers under diverse settings.

</details>


### [46] [Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search](https://arxiv.org/abs/2602.04454)
*Tianming Liang,Qirui Du,Jian-Fang Hu,Haichao Jiang,Zicheng Lin,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: Seg-ReSearch 让分割模型在推理过程中实时检索外部知识，突破 MLLM 固定知识瓶颈，在需外部知识的 OK-VOS 等基准上显著刷新 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言的视觉分割系统虽引入 MLLM 获得推理能力，但受限于模型内部冻结知识，难以应对需最新信息或领域概念的开放世界查询。

Method: 提出 Seg-ReSearch 框架：在分割流程中交替执行“推理—检索”循环，动态获取外部知识；设计分层奖励函数，将初始引导与渐进激励结合，缓解稀疏结果信号与严格步骤监督之间的矛盾，实现端到端训练。

Result: 构建需外部知识的视频目标分割基准 OK-VOS，并在该基准及两个既有推理分割数据集上验证，Seg-ReSearch 相比现有最佳方法取得显著性能提升。

Conclusion: 通过引入在线检索与分层奖励，Seg-ReSearch 有效打破 MLLM 知识固化限制，为开放世界语言驱动分割提供了可扩展的新范式。

Abstract: Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose \textbf{Seg-ReSearch}, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search, Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation. Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.

</details>


### [47] [Temporal Slowness in Central Vision Drives Semantic Object Learning](https://arxiv.org/abs/2602.04462)
*Timothy Schaumlöffel,Arthur Aubret,Gemma Roig,Jochen Triesch*

Main category: cs.CV

TL;DR: 利用Ego4D模拟5个月人眼视觉流，仅保留预测注视点高分辨率中心区域，并以时间对比自监督学习发现：中心视野强化前景物体特征，时间慢变性在固视微动中补充背景语义，二者协同即可在无标注条件下形成高质量物体表征。


<details>
  <summary>Details</summary>
Motivation: 人类仅通过 egocentric 视觉流且监督极少即可习得语义物体表征；视网膜中央凹高分辨率与时间连续性（慢变性）被认为是关键，但缺乏大规模人类真实视觉数据与计算建模的直接证据。

Method: 基于 Ego4D 构建 5 个月量级 egocentric 视频序列；用 SOTA 注视预测模型生成每帧 gaze 坐标；依此提取模拟中央凹的 512×512 中心 crop；在 crop 序列上训练时间对比自监督模型（TC-SSL），通过快慢两种采样策略分别对应扫视与固视微动；对比仅中心、仅慢变、二者结合及全图四种条件。

Result: 中心+慢变组合在 ImageNet 线性 probing 上 Top-1 提升 4.8%，在 ADE 前景-背景分离任务中 IoU 提升 6.2%，在 MIT 物体属性判别任务中 mAP 提升 5.1%；消融显示中心视野主要贡献前景特征判别力，慢变性在固视片段显著增加背景/语境语义编码。

Conclusion: 中央高分辨率与时间慢变性是人从自然视觉经验中自发形成语义物体表征的两大计算原则；该机制可完全自监督实现，为开发数据高效的 egocentric 视觉系统提供可直接迁移的框架。

Abstract: Humans acquire semantic object representations from egocentric visual streams with minimal supervision. Importantly, the visual system processes with high resolution only the center of its field of view and learns similar representations for visual inputs occurring close in time. This emphasizes slowly changing information around gaze locations. This study investigates the role of central vision and slowness learning in the formation of semantic object representations from human-like visual experience. We simulate five months of human-like visual experience using the Ego4D dataset and generate gaze coordinates with a state-of-the-art gaze prediction model. Using these predictions, we extract crops that mimic central vision and train a time-contrastive Self-Supervised Learning model on them. Our results show that combining temporal slowness and central vision improves the encoding of different semantic facets of object representations. Specifically, focusing on central vision strengthens the extraction of foreground object features, while considering temporal slowness, especially during fixational eye movements, allows the model to encode broader semantic information about objects. These findings provide new insights into the mechanisms by which humans may develop semantic object representations from natural visual experience.

</details>


### [48] [Vision-aligned Latent Reasoning for Multi-modal Large Language Model](https://arxiv.org/abs/2602.04476)
*Byungwoo Jeon,Yoonwoo Jeong,Hyunseok Lee,Minsu Cho,Jinwoo Shin*

Main category: cs.CV

TL;DR: VaLR 通过“每步推理前动态生成与视觉对齐的隐变量 token”，把视觉信息牢牢锁在推理链中，让多模态大模型首次实现可观测的 test-time scaling，在 VSI-Bench 等长链推理 benchmark 上暴涨 19.9 个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLM 在多步推理时视觉信息被逐步稀释，导致无法利用 test-time scaling 提升效果。

Method: 提出 Vision-aligned Latent Reasoning（VaLR）框架：每步 CoT 前动态生成与视觉编码器中间嵌入对齐的隐变量 token，用对比损失强制 MLLM 的隐状态保持视觉知识。

Result: 在需要长上下文理解或精细视觉感知的多个 benchmark 上全面超越现有方法；VSI-Bench 从 33.0% 提升至 52.9%，并首次观察到随推理步数增加而性能持续提升的 test-time scaling 现象。

Conclusion: VaLR 证明只要把视觉信息持续注入推理链，MLLM 就能突破多步推理瓶颈，实现可扩展的测试时增强，为后续多模态推理研究提供了简单有效的通用范式。

Abstract: Despite recent advancements in Multi-modal Large Language Models (MLLMs) on diverse understanding tasks, these models struggle to solve problems which require extensive multi-step reasoning. This is primarily due to the progressive dilution of visual information during long-context generation, which hinders their ability to fully exploit test-time scaling. To address this issue, we introduce Vision-aligned Latent Reasoning (VaLR), a simple, yet effective reasoning framework that dynamically generates vision-aligned latent tokens before each Chain of Thought reasoning step, guiding the model to reason based on perceptual cues in the latent space. Specifically, VaLR is trained to preserve visual knowledge during reasoning by aligning intermediate embeddings of MLLM with those from vision encoders. Empirical results demonstrate that VaLR consistently outperforms existing approaches across a wide range of benchmarks requiring long-context understanding or precise visual perception, while exhibiting test-time scaling behavior not observed in prior MLLMs. In particular, VaLR improves the performance significantly from 33.0% to 52.9% on VSI-Bench, achieving a 19.9%p gain over Qwen2.5-VL.

</details>


### [49] [S-MUSt3R: Sliding Multi-view 3D Reconstruction](https://arxiv.org/abs/2602.04517)
*Leonid Antsfeld,Boris Chidlovskii,Yohann Cabon,Vincent Leroy,Jerome Revaud*

Main category: cs.CV

TL;DR: 提出 S-MUSt3R：无需重训，用序列切分+段间对齐+轻量闭环即可把 MUSt3R 扩展为长序列单目 RGB 度量三维重建，内存可控、精度比肩传统复杂方法。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 视觉基础模型虽具备强大单目感知能力，但直接用于大规模无标定 RGB 视频流重建时，因显存/内存瓶颈难以处理长序列，亟需一种无需重训即可扩展的轻量方案。

Method: 在 MUSt3R 特征点+深度预测基础上，引入“序列分段→逐段重建→段间特征匹配对齐→轻量级闭环优化”四步流水线；所有操作仅依赖冻结的 MUSt3R 权重，无需再训练或微调。

Result: 在 TUM、7-Scenes 及自有机器人导航数据上，S-MUSt3R 可稳定跑完数千帧 RGB 序列，轨迹误差与稠密重建精度与当前复杂传统 SLAM/SfM 相当，且直接输出度量尺度点云。

Conclusion: 证明通过简单分段策略即可释放基础模型在长序列度量三维重建中的潜能，为实时机器人导航、AR 等场景提供了内存友好、无需重训的新基线。

Abstract: The recent paradigm shift in 3D vision led to the rise of foundation models with remarkable capabilities in 3D perception from uncalibrated images. However, extending these models to large-scale RGB stream 3D reconstruction remains challenging due to memory limitations. This work proposes S-MUSt3R, a simple and efficient pipeline that extends the limits of foundation models for monocular 3D reconstruction. Our approach addresses the scalability bottleneck of foundation models through a simple strategy of sequence segmentation followed by segment alignment and lightweight loop closure optimization. Without model retraining, we benefit from remarkable 3D reconstruction capacities of MUSt3R model and achieve trajectory and reconstruction performance comparable to traditional methods with more complex architecture. We evaluate S-MUSt3R on TUM, 7-Scenes and proprietary robot navigation datasets and show that S-MUSt3R runs successfully on long RGB sequences and produces accurate and consistent 3D reconstruction. Our results highlight the potential of leveraging the MUSt3R model for scalable monocular 3D scene in real-world settings, with an important advantage of making predictions directly in the metric space.

</details>


### [50] [SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking](https://arxiv.org/abs/2602.04525)
*Muhammad Taha Mukhtar,Syed Musa Ali Kazmi,Khola Naseem,Muhammad Ali Chattha,Andreas Dengel,Sheraz Ahmed,Muhammad Naseer Bajwa,Muhammad Imran Malik*

Main category: cs.CV

TL;DR: 构建了一个覆盖1 869 km²的南亚三城非正规定居区新基准，提出“类别感知自适应阈值+原型库”半监督分割框架，仅用10%源域标签即可在跨洲8城上超越全监督零样本泛化性能。


<details>
  <summary>Details</summary>
Motivation: 中低收入国家大城市的非正规定居区因光谱混淆与标注噪声导致大规模制图困难，现有数据稀缺且质量参差不齐，亟需可迁移的鲁棒学习方法。

Method: ① 自建拉合尔标注并从官方边界衍生卡拉奇、孟买数据，形成三城基准；② 提出半监督分割框架：a) 类别感知自适应阈值动态抑制多数类，缓解类别不平衡；b) 原型库系统利用历史高保真特征锚定预测，保持语义一致。

Result: 在8座跨洲城市、共9套数据集上全面评估，所提方法显著优于现有半监督基线；仅用10%源域标签即取得0.461 mIoU，超越全监督模型的零样本泛化表现，展示出优异的域迁移能力。

Conclusion: 新基准与半监督框架共同解决了非正规定居区制图中的数据稀缺与域差异难题，验证了少量标注即可实现跨城市、跨大洲的可靠迁移，为快速城市化地区的可持续监测提供了可行方案。

Abstract: Rapid urban expansion has fueled the growth of informal settlements in major cities of low- and middle-income countries, with Lahore and Karachi in Pakistan and Mumbai in India serving as prominent examples. However, large-scale mapping of these settlements is severely constrained not only by the scarcity of annotations but by inherent data quality challenges, specifically high spectral ambiguity between formal and informal structures and significant annotation noise. We address this by introducing a benchmark dataset for Lahore, constructed from scratch, along with companion datasets for Karachi and Mumbai, which were derived from verified administrative boundaries, totaling 1,869 $\text{km}^2$ of area. To evaluate the global robustness of our framework, we extend our experiments to five additional established benchmarks, encompassing eight cities across three continents, and provide comprehensive data quality assessments of all datasets. We also propose a new semi-supervised segmentation framework designed to mitigate the class imbalance and feature degradation inherent in standard semi-supervised learning pipelines. Our method integrates a Class-Aware Adaptive Thresholding mechanism that dynamically adjusts confidence thresholds to prevent minority class suppression and a Prototype Bank System that enforces semantic consistency by anchoring predictions to historically learned high-fidelity feature representations. Extensive experiments across a total of eight cities spanning three continents demonstrate that our approach outperforms state-of-the-art semi-supervised baselines. Most notably, our method demonstrates superior domain transfer capability whereby a model trained on only 10% of source labels reaches a 0.461 mIoU on unseen geographies and outperforms the zero-shot generalization of fully supervised models.

</details>


### [51] [OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis](https://arxiv.org/abs/2602.04547)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto*

Main category: cs.CV

TL;DR: OmniRad 是一个基于 120 万张多模态医学影像自监督预训练的放射学基础模型，通过“冻结骨干+轻量适配器”或“全参数微调”两种方式，在 MedMNISTv2 分类和 MedSegBench 分割任务上均优于现有基础模型，F1 最高提升 2.05%，Dice 平均提升，且特征空间呈现更好的模态聚类与可分性。


<details>
  <summary>Details</summary>
Motivation: 放射学分析需要可迁移的通用视觉表征，以支持跨模态、多任务的下游应用；现有预训练模型在医学影像上的跨任务泛化能力仍显不足。

Method: 构建大规模多模态放射学数据集（120 万幅图像），采用自监督策略预训练 OmniRad；引入放射学启发的表征复用原则，设计“冻结编码器 + 轻量任务适配器”以及“端到端微调”两种下游适应范式，系统评估分类与分割任务。

Result: 在 MedMNISTv2 分类基准上，OmniRad 的 F1 分数较现有基础模型最高提升 2.05%；在 MedSegBench 的 6 个分割数据集上，使用冻结表征即获得平均 Dice 提升；可视化显示特征聚类更紧凑，模态间分离度更高。

Conclusion: OmniRad 提供了高质量、可复用的放射学通用表征，兼顾轻量部署与高性能微调，验证了大规模自监督预训练在跨模态医学影像任务中的有效性与优越性。

Abstract: Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability. We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualizations suggest improved feature clustering and modality-related separation.

</details>


### [52] [Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models](https://arxiv.org/abs/2602.04549)
*Cem Eteke,Enzo Tartaglione*

Main category: cs.CV

TL;DR: NiFi 用扩散一步蒸馏“修复”被极限压缩的 3DGS，在 0.1 MB（≈1000×压缩）下仍保持 SOTA 感知质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS 虽实现实时渲染，但稀疏高斯存储开销大，阻碍沉浸式通信等应用；现有压缩方法在极低码率下视觉伪影严重，亟需一种极低位率下仍能维持感知质量的压缩方案。

Method: 提出 NiFi——基于“伪影感知”的扩散模型一步蒸馏修复框架：先对极低码率 3DGS 解码出的带噪渲染图进行单步去噪恢复，再将修复结果反向监督压缩端，实现极限压缩与感知保真双赢。

Result: 在 0.1 MB 模型大小下达到与原始 3DGS 相当的感知质量，实现约 1000× 压缩率，显著优于现有 3DGS 压缩方法的低码率表现。

Conclusion: NiFi 验证了“极限压缩+扩散修复”路线的有效性，为存储受限场景的实时神经辐射场应用提供了可扩展的新范式。

Abstract: 3D Gaussian Splatting (3DGS) revolutionized novel view rendering. Instead of inferring from dense spatial points, as implicit representations do, 3DGS uses sparse Gaussians. This enables real-time performance but increases space requirements, hindering applications such as immersive communication. 3DGS compression emerged as a field aimed at alleviating this issue. While impressive progress has been made, at low rates, compression introduces artifacts that degrade visual quality significantly. We introduce NiFi, a method for extreme 3DGS compression through restoration via artifact-aware, diffusion-based one-step distillation. We show that our method achieves state-of-the-art perceptual quality at extremely low rates, down to 0.1 MB, and towards 1000x rate improvement over 3DGS at comparable perceptual performance. The code will be open-sourced upon acceptance.

</details>


### [53] [Understanding Degradation with Vision Language Model](https://arxiv.org/abs/2602.04565)
*Guanzhou Lan,Chenyi Liao,Yuqi Yang,Qianli Ma,Zhigang Wang,Dong Wang,Bin Zhao,Xuelong Li*

Main category: cs.CV

TL;DR: 提出统一视觉退化理解的层级结构预测框架 DU-VLM，可在零样本条件下驱动扩散模型完成高保真图像复原，并发布 11 万带物理参数标签的 DU-110k 数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型虽能定性描述图像退化，却无法揭示其背后的物理参数机制，限制了精确诊断与后续复原。

Method: 将退化理解重定义为“退化类型-参数键-连续值”层级结构预测任务，证明三者可在统一自回归下一 token 框架内通过量化网格误差界限求解；构建 DU-VLM 多模态链式思维模型，用监督微调+结构奖励强化学习训练；利用该模型零样本控制预训练扩散模型实现免 backbone 微调的图像复原；发布含 11 万清洁-退化配对及物理注释的 DU-110k 数据集。

Result: 在 DU-110k 及跨分布测试上，DU-VLM 在退化识别精度与鲁棒性方面显著优于通用基线，并可零样本驱动扩散模型生成高保真复原结果。

Conclusion: 通过将物理参数估计纳入统一自回归框架，DU-VLM 首次实现了对视觉退化的深度理解与零样本可控复原，为后续视觉质量增强与物理可解释研究提供了新范式与数据基础。

Abstract: Understanding visual degradations is a critical yet challenging problem in computer vision. While recent Vision-Language Models (VLMs) excel at qualitative description, they often fall short in understanding the parametric physics underlying image degradations. In this work, we redefine degradation understanding as a hierarchical structured prediction task, necessitating the concurrent estimation of degradation types, parameter keys, and their continuous physical values. Although these sub-tasks operate in disparate spaces, we prove that they can be unified under one autoregressive next-token prediction paradigm, whose error is bounded by the value-space quantization grid. Building on this insight, we introduce DU-VLM, a multimodal chain-of-thought model trained with supervised fine-tuning and reinforcement learning using structured rewards. Furthermore, we show that DU-VLM can serve as a zero-shot controller for pre-trained diffusion models, enabling high-fidelity image restoration without fine-tuning the generative backbone. We also introduce \textbf{DU-110k}, a large-scale dataset comprising 110,000 clean-degraded pairs with grounded physical annotations. Extensive experiments demonstrate that our approach significantly outperforms generalist baselines in both accuracy and robustness, exhibiting generalization to unseen distributions.

</details>


### [54] [A labeled dataset of simulated phlebotomy procedures for medical AI: polygon annotations for object detection and human-object interaction](https://arxiv.org/abs/2602.04624)
*Raúl Jiménez Cruz,César Torres-Huitzil,Marco Franceschetti,Ronny Seiger,Luciano García-Bañuelos,Barbara Weber*

Main category: cs.CV

TL;DR: 公开了一个包含11 884张标注图像的采血训练数据集，支持手套、注射器等5类器械分割，可用于流程识别与教学反馈研究。


<details>
  <summary>Details</summary>
Motivation: 医学采血培训自动化缺少高质量、隐私合规的带标注视觉数据，难以支撑器械检测与流程分析模型的开发。

Method: 在受控环境下用高清视频拍摄训练臂采血过程→SSIM去冗余→自动人脸匿名→人工标注5类器械多边形→按YOLOv8分割格式导出→按7:1.5:1.5划分训练/验证/测试集并发布至Zenodo。

Result: 获得11 884张图像、五类器械像素级标注、零可识别隐私信息；数据可直接用于YOLOv8等框架，支持工具检测、步骤识别、流程合规检查及智能教学系统研发。

Conclusion: 该数据集填补了医学采血训练公开分割数据的空白，为后续自动化培训与实时反馈算法提供了可靠基准。

Abstract: This data article presents a dataset of 11,884 labeled images documenting a simulated blood extraction (phlebotomy) procedure performed on a training arm. Images were extracted from high-definition videos recorded under controlled conditions and curated to reduce redundancy using Structural Similarity Index Measure (SSIM) filtering. An automated face-anonymization step was applied to all videos prior to frame selection. Each image contains polygon annotations for five medically relevant classes: syringe, rubber band, disinfectant wipe, gloves, and training arm. The annotations were exported in a segmentation format compatible with modern object detection frameworks (e.g., YOLOv8), ensuring broad usability. This dataset is partitioned into training (70%), validation (15%), and test (15%) subsets and is designed to advance research in medical training automation and human-object interaction. It enables multiple applications, including phlebotomy tool detection, procedural step recognition, workflow analysis, conformance checking, and the development of educational systems that provide structured feedback to medical trainees. The data and accompanying label files are publicly available on Zenodo.

</details>


### [55] [AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation](https://arxiv.org/abs/2602.04672)
*Jin-Chuan Shi,Binhong Ye,Tao Liu,Junzhe He,Yangjinhui Xu,Xiaoyang Liu,Zeju Li,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: AGILE 用“生成式智能体”取代传统重建：VLM 引导生成完整无孔物体网格，单帧初始化+时序跟踪跳过 SfM，再经接触-稳定优化，输出可直接仿真的手-物交互资产，在 HO3D、DexYCB 及野生视频上精度与鲁棒性均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单目视频重建动态手-物交互是机器人灵巧操作数据与 VR 数字孪生的关键，但现有方法依赖神经渲染导致遮挡处几何破碎且无法直接用于仿真，同时脆弱的 SfM 初始化在野外视频中频繁失败。

Method: 提出 AGILE 框架：① 用 VLM 驱动生成模型合成完整水密高纹理物体网格，摆脱视频遮挡；② 单帧 foundation model 估计初始位姿，靠生成资产与观测的高视觉相似性做时序跟踪，彻底绕过 SfM；③ 引入语义-几何-交互稳定性约束的接触感知优化，确保物理合理。

Result: 在 HO3D、DexYCB 及野外视频上的实验显示，AGILE 全局几何精度优于基线，并在以往方法崩溃的困难序列中保持稳健；生成的资产经 real-to-sim 重定向验证可直接用于机器人仿真。

Conclusion: AGILE 通过“生成式智能体”范式实现物理合理、仿真就绪的手-物交互资产提取，兼顾精度与野外鲁棒性，为机器人数据获取和数字孪生创建提供了可扩展的新路径。

Abstract: Reconstructing dynamic hand-object interactions from monocular videos is critical for dexterous manipulation data collection and creating realistic digital twins for robotics and VR. However, current methods face two prohibitive barriers: (1) reliance on neural rendering often yields fragmented, non-simulation-ready geometries under heavy occlusion, and (2) dependence on brittle Structure-from-Motion (SfM) initialization leads to frequent failures on in-the-wild footage. To overcome these limitations, we introduce AGILE, a robust framework that shifts the paradigm from reconstruction to agentic generation for interaction learning. First, we employ an agentic pipeline where a Vision-Language Model (VLM) guides a generative model to synthesize a complete, watertight object mesh with high-fidelity texture, independent of video occlusions. Second, bypassing fragile SfM entirely, we propose a robust anchor-and-track strategy. We initialize the object pose at a single interaction onset frame using a foundation model and propagate it temporally by leveraging the strong visual similarity between our generated asset and video observations. Finally, a contact-aware optimization integrates semantic, geometric, and interaction stability constraints to enforce physical plausibility. Extensive experiments on HO3D, DexYCB, and in-the-wild videos reveal that AGILE outperforms baselines in global geometric accuracy while demonstrating exceptional robustness on challenging sequences where prior art frequently collapses. By prioritizing physical validity, our method produces simulation-ready assets validated via real-to-sim retargeting for robotic applications.

</details>


### [56] [DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking](https://arxiv.org/abs/2602.04692)
*Sijia Chen,Lijuan Ma,Yanqiu Yu,En Yu,Liman Liu,Wenbing Tao*

Main category: cs.CV

TL;DR: 首个融合RGB-Depth-Language三模态的指称多目标跟踪任务DRMOT及其数据集DRSet，提出MLLM引导的DRTrack框架，用深度信息解决2D RMOT在复杂空间语义和严重遮挡下的目标关联与ID保持难题。


<details>
  <summary>Details</summary>
Motivation: 现有RMOT仅依赖2D RGB，难以处理含空间语义的指称（如“离相机最近的人”）并在严重遮挡下保持身份一致性，缺乏显式3D空间信息。

Method: 提出新任务RGBD指称多目标跟踪(DRMOT)，构建含187场景、240条语言描述（56条含深度线索）的DRSet数据集；设计MLLM引导的DRTrack框架，实现RGB-D-L三模态融合的深度感知目标定位与轨迹关联。

Result: 在DRSet上的大量实验验证DRTrack可显著提升对空间语义指称的 grounding 精度及遮挡下的ID保持能力，证明引入深度信息对RMOT的有效性。

Conclusion: 首次将深度模态引入指称多目标跟踪，通过DRMOT任务、DRSet基准与DRTrack框架，为后续交互式AI系统在机器人与自动驾驶中的3D-aware语言指令跟踪奠定基础。

Abstract: Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate targets characterized by complex spatial semantics (e.g., ``the person closest to the camera'') and to maintain reliable identities under severe occlusion, due to the absence of explicit 3D spatial information. In this work, we propose a novel task, RGBD Referring Multi-Object Tracking (DRMOT), which explicitly requires models to fuse RGB, Depth (D), and Language (L) modalities to achieve 3D-aware tracking. To advance research on the DRMOT task, we construct a tailored RGBD referring multi-object tracking dataset, named DRSet, designed to evaluate models' spatial-semantic grounding and tracking capabilities. Specifically, DRSet contains RGB images and depth maps from 187 scenes, along with 240 language descriptions, among which 56 descriptions incorporate depth-related information. Furthermore, we propose DRTrack, a MLLM-guided depth-referring tracking framework. DRTrack performs depth-aware target grounding from joint RGB-D-L inputs and enforces robust trajectory association by incorporating depth cues. Extensive experiments on the DRSet dataset demonstrate the effectiveness of our framework.

</details>


### [57] [Annotation Free Spacecraft Detection and Segmentation using Vision Language Models](https://arxiv.org/abs/2602.04699)
*Samet Hicsonmez,Jose Sosa,Dan Pineau,Inder Pal Singh,Arunkumar Rathinam,Abd El Rahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出一种无需人工标注即可检测与分割航天器及轨道目标的流程：先用预训练视觉语言模型为少量无标签真实数据生成伪标签，再通过师生蒸馏训练轻量模型，在 SPARK-2024、SPEED+、TANGO 数据集上 AP 提升最高 10 点。


<details>
  <summary>Details</summary>
Motivation: 太空图像手动标注困难（低可见度、光照变化、目标与行星背景融合），亟需无需大量人工标签即可检测与分割航天器/轨道目标的方法。

Method: 1) 用预训练视觉语言模型为少量无标签真实数据自动生成伪标签；2) 构建师生标签蒸馏框架，用含噪伪标签训练轻量检测/分割模型；3) 迭代优化以抑制伪标签噪声并提升性能。

Result: 在 SPARK-2024、SPEED+、TANGO 分割任务上，相比直接零样本 VLM 推理，平均精度（AP）提升最高达 10 个百分点，验证了伪标签蒸馏的有效性。

Conclusion: 即使伪标签存在噪声，通过师生蒸馏仍能显著增强轻量模型在太空目标检测与分割上的表现，为缺乏人工标注的航天应用提供了可行且高效的解决方案。

Abstract: Vision Language Models (VLMs) have demonstrated remarkable performance in open-world zero-shot visual recognition. However, their potential in space-related applications remains largely unexplored. In the space domain, accurate manual annotation is particularly challenging due to factors such as low visibility, illumination variations, and object blending with planetary backgrounds. Developing methods that can detect and segment spacecraft and orbital targets without requiring extensive manual labeling is therefore of critical importance. In this work, we propose an annotation-free detection and segmentation pipeline for space targets using VLMs. Our approach begins by automatically generating pseudo-labels for a small subset of unlabeled real data with a pre-trained VLM. These pseudo-labels are then leveraged in a teacher-student label distillation framework to train lightweight models. Despite the inherent noise in the pseudo-labels, the distillation process leads to substantial performance gains over direct zero-shot VLM inference. Experimental evaluations on the SPARK-2024, SPEED+, and TANGO datasets on segmentation tasks demonstrate consistent improvements in average precision (AP) by up to 10 points. Code and models are available at https://github.com/giddyyupp/annotation-free-spacecraft-segmentation.

</details>


### [58] [How to rewrite the stars: Mapping your orchard over time through constellations of fruits](https://arxiv.org/abs/2602.04722)
*Gonçalo P. Matos,Carlos Santiago,João P. Costeira,Ricardo L. Saldanha,Ernesto M. Morgado*

Main category: cs.CV

TL;DR: 用3D质心星座描述稀疏果点云，跨视频匹配同一果实，实现全程无标定生长追踪与机器人6DoF定位。


<details>
  <summary>Details</summary>
Motivation: 人工用卡尺跟踪果实生长耗时且无法扩展；现有视觉方法难以在无GPS、无视差特征、相机位姿未知条件下跨日匹配同一果实，导致无法自动估算果径增长曲线。

Method: 提出“3D质心星座”新范式：先对每帧视频重建稀疏3D点云并检测果实中心→构建包含相对几何与拓扑关系的星座描述子→用星座间一致性投票匹配，而非单果匹配；结合RANSAC与图优化实现跨视频果实对应，并同步恢复果园全局地图与相机6DoF位姿。

Result: 在苹果园多日视频中，果实重识别F1>90%，大小增长曲线误差<2 mm；可在线生成果园拓扑地图并支持机器人后续自主导航与选择性采摘。

Conclusion: 星座-描述子框架摆脱对初始位姿、GPS或丰富纹理的依赖，首次实现“无标定”跨期果实生长追踪，并为果园机器人提供低成本 simultaneous mapping and localization 能力，可直接用于估产、成熟预测与精准收获。

Abstract: Following crop growth through the vegetative cycle allows farmers to predict fruit setting and yield in early stages, but it is a laborious and non-scalable task if performed by a human who has to manually measure fruit sizes with a caliper or dendrometers. In recent years, computer vision has been used to automate several tasks in precision agriculture, such as detecting and counting fruits, and estimating their size. However, the fundamental problem of matching the exact same fruits from one video, collected on a given date, to the fruits visible in another video, collected on a later date, which is needed to track fruits' growth through time, remains to be solved. Few attempts were made, but they either assume that the camera always starts from the same known position and that there are sufficiently distinct features to match, or they used other sources of data like GPS. Here we propose a new paradigm to tackle this problem, based on constellations of 3D centroids, and introduce a descriptor for very sparse 3D point clouds that can be used to match fruits across videos. Matching constellations instead of individual fruits is key to deal with non-rigidity, occlusions and challenging imagery with few distinct visual features to track. The results show that the proposed method can be successfully used to match fruits across videos and through time, and also to build an orchard map and later use it to locate the camera pose in 6DoF, thus providing a method for autonomous navigation of robots in the orchard and for selective fruit picking, for example.

</details>


### [59] [Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention](https://arxiv.org/abs/2602.04789)
*Chengtao Lv,Yumeng Shi,Yushi Huang,Ruihao Gong,Shen Ren,Wenya Wang*

Main category: cs.CV

TL;DR: Light Forcing 是首个专为自回归视频生成模型设计的稀疏注意力方案，通过“块感知增长”与“分层稀疏注意力”在几乎不损失画质的前提下实现 1.2–2.3× 端到端加速，RTX 5090 上达 19.7 FPS。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法直接用于自回归视频模型会显著掉点，原因在于：1) 孤立地处理分块生成，2) 未能充分利用过往上下文信息。亟需一种保留因果依赖且能继承历史知识的稀疏方案。

Method: 提出 Light Forcing，包含两大核心：① Chunk-Aware Growth——量化每块对最终生成的贡献并据此动态分配稀疏度，使当前块逐步继承早期块知识；② Hierarchical Sparse Attention——帧级+块级两级掩码，从粗到细地选择关键历史与局部上下文，适配多样化注意力模式。配合 FP8 量化与 LightVAE 进一步加速。

Result: 在 VBench 上取得 84.5 分，优于现有稀疏注意力基线；端到端速度提升 1.2–1.3×，结合 FP8+LightVAE 后整体 2.3× 加速，RTX 5090 实测 19.7 FPS，显存占用显著下降，代码将开源。

Conclusion: Light Forcing 通过“贡献感知渐进稀疏”与“分层粗-细选择”首次在自回归视频生成中实现高保真与高效率兼得，为实时交互视频生成提供了可行路径。

Abstract: Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \textsc{Light Forcing}, the \textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, $1.2{\sim}1.3\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \textsc{Light Forcing} further achieves a $2.3\times$ speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at \href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.

</details>


### [60] [VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?](https://arxiv.org/abs/2602.04802)
*Qing'an Liu,Juntong Feng,Yuhao Wang,Xinzhe Han,Yujie Cheng,Yue Zhu,Haiwen Diao,Yunzhi Zhuge,Huchuan Lu*

Main category: cs.CV

TL;DR: 构建VISTA-Bench评测集，首次系统揭示主流多模态大模型在“纯文本查询”与“图像内可视化文本”上的显著性能落差，并指出渲染差异会放大该落差。


<details>
  <summary>Details</summary>
Motivation: 现有基准几乎只用纯文本提问，而真实场景常出现嵌在图片里的可视化文本；尚不清楚当前VLMs能否同等理解这两种形态的语言信息。

Method: 设计覆盖感知、推理、单模理解三域的VISTA-Bench，在受控渲染条件下成对生成语义等价但形态不同（纯文本 vs 可视化文本）的问题，对20余个代表性VLM进行大规模评测。

Result: 发现明显“模态落差”：同一模型在纯文本上表现良好，面对语义相同但像素化的文本时性能显著下降，且随渲染难度增加落差被进一步放大。

Conclusion: VISTA-Bench为诊断并缩小文本token与像素文本间的统一表征缺陷提供了原则性框架，可指导后续研究提升VLM对可视化文本的鲁棒理解能力。

Abstract: Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench.

</details>


### [61] [XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas](https://arxiv.org/abs/2602.04819)
*Aqsa Sultana,Rayan Afsar,Ahmed Rahu,Surendra P. Singh,Brian Shula,Brandon Combs,Derrick Forchetti,Vijayan K. Asari*

Main category: cs.CV

TL;DR: 仅用3.2万参数的XtraLight-MedMamba，在整张切片上识别低级别管状腺瘤癌变风险，准确率97.18%，显著优于复杂Transformer与Mamba模型。


<details>
  <summary>Details</summary>
Motivation: 低级别异型增生靠主观病理判读难以精准分层，而数字病理与深度学习可捕捉人眼不可见的细微形态特征，实现癌变风险早期预警。

Method: 提出XtraLight-MedMamba：ConvNext浅层特征提取器+并行Vision Mamba捕获长-短程依赖；SCAB模块融合空间-通道注意力增强多尺度特征；FNOClassifier以固定非负正交变换实现极致参数压缩与泛化提升。

Result: 在基于低级别管状腺瘤的回顾性队列（按后续是否进展为CRC划分病例-对照）上，模型仅用≈32 k参数即达97.18%准确率、F1=0.9767，全面优于参数量大得多的Transformer及传统Mamba架构。

Conclusion: 超轻量状态空间模型可在WSI级别完成精准风险分层，为实时内镜-病理联合筛查提供可部署的AI工具，并验证了“小参数+状态空间”在数字病理中的潜力。

Abstract: Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.

</details>


### [62] [Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization](https://arxiv.org/abs/2602.04820)
*Farzia Hossain,Samanta Ghosh,Shahida Begum,B. M. Shahria Alam,Mohammad Tahmid Noor,Md Parvez Mia,Nishat Tasnim Niloy*

Main category: cs.CV

TL;DR: 基于3 835张甲病图像，用InceptionV3实现95.57%准确率，辅以对抗训练与SHAP解释，为临床提供快速辅助诊断。


<details>
  <summary>Details</summary>
Motivation: 甲病随年龄增长高发且常被忽视，其视觉差异细微、早期诊断困难，需自动化工具提升筛查效率并揭示潜在系统性疾病。

Method: 公开数据集6类甲病图像→统一224×224像素；训练并对比InceptionV3、DenseNet201、EfficientNetV2、ResNet50；最佳模型加入对抗训练增强鲁棒性；引入SHAP可视化关键决策区域。

Result: InceptionV3以95.57%准确率领先，DenseNet201次之为94.79%；对抗训练提升噪声鲁棒性；SHAP热力图可解释模型关注区域，验证临床相关性。

Conclusion: 所提系统可在临床端作为快速、准确的甲病分类辅助工具，减轻医生负担并促进早诊早治。

Abstract: Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.

</details>


### [63] [LitS: A novel Neighborhood Descriptor for Point Clouds](https://arxiv.org/abs/2602.04838)
*Jonatan B. Bastos,Francisco F. Rivera,Oscar G. Lorenzo,David L. Vilariño,José C. Cabaleiro,Alberto M. Esmorís,Tomás F. Pena*

Main category: cs.CV

TL;DR: 提出 LitS——一种用单位圆上分片常数函数刻画点云局部邻域的新描述子，可抗密度变化和噪声，适配 2D/3D 数据。


<details>
  <summary>Details</summary>
Motivation: 现有邻域描述子难以同时兼顾对局部几何的精细刻画、对密度变化与噪声的鲁棒性，以及跨 2D/3D 场景的通用性，亟需一种简洁而信息丰富的替代方案。

Method: 将各点邻域按局部坐标系划分成若干圆锥方向，统计每个方向上的邻居数量，得到定义在单位圆上的分片常数函数 LitS；进一步给出累积版 LitS 并引入两个可调参数，以适配不同尺度与密度的点云。

Result: LitS 能在单点层面编码丰富的局部几何信息，并通过相邻点的 LitS 差异揭示全局结构；实验表明其对可变密度和噪声具有韧性，可作为一种通用、灵活的邻域描述子。

Conclusion: LitS 以极低计算成本实现了对 2D/3D 点云局部结构的高效、鲁棒刻画，为后续配准、分割、识别等任务提供了新的特征基础。

Abstract: With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.

</details>


### [64] [When LLaVA Meets Objects: Token Composition for Vision-Language-Models](https://arxiv.org/abs/2602.04864)
*Soumya Jahagirdar,Walid Bousselham,Anna Kukleva,Hilde Kuehne*

Main category: cs.CV

TL;DR: Mask-LLaVA 用“全局+局部+掩码对象”三级视觉 token 训练，推理时可随意丢弃掩码 token 不掉点，实现 1/10 量级 token 的轻量级 VLM。


<details>
  <summary>Details</summary>
Motivation: 现有自回归 VLM 需大量视觉 token 表示图像，推理计算昂贵，亟需一种不牺牲性能、可动态压缩 token 的方案。

Method: 提出 Mask-LLaVA：① 保留 LLaVA 原有全局与局部 patch token；② 引入掩码对象 token（Mask-based object representations）提供语义先验；③ 训练阶段三级 token 全部参与，推理阶段可零重训地按需丢弃掩码对象 token，实现动态 token 预算。

Result: 在多项标准基准上，仅用原始 LLaVA 视觉 token 的 10–20% 即可达到可比精度，显著优于现有 token-efficient 方法，且推理延迟与显存均大幅下降。

Conclusion: 多级视觉特征融合能在训练时充分利用信息，推理时通过掩码对象 token 的弹性丢弃实现“一次训练、多级预算”，为自回归 VLM 的轻量部署提供了通用范式。

Abstract: Current autoregressive Vision Language Models (VLMs) usually rely on a large number of visual tokens to represent images, resulting in a need for more compute especially at inference time. To address this problem, we propose Mask-LLaVA, a framework that leverages different levels of visual features to create a compact yet information-rich visual representation for autoregressive VLMs. Namely, we combine mask-based object representations together with global tokens and local patch tokens. While all tokens are used during training, it shows that the resulting model can flexibly drop especially the number of mask-based object-tokens at test time, allowing to adapt the number of tokens during inference without the need to retrain the model and without a significant drop in performance. We evaluate the proposed approach on a suite of standard benchmarks showing results competitive to current token efficient methods and comparable to the original LLaVA baseline using only a fraction of visual tokens. Our analysis demonstrates that combining multi-level features enables efficient learning with fewer tokens while allowing dynamic token selection at test time for good performance.

</details>


### [65] [Laminating Representation Autoencoders for Efficient Diffusion](https://arxiv.org/abs/2602.04873)
*Ramón Calvo-González,François Fleuret*

Main category: cs.CV

TL;DR: 把 DINOv2 的二维密集 patch 特征压成仅 32 个 1-D token，扩散模型在 ImageNet 256² 上仍保持 1.80 gFID，同时前向计算量降 8×，训练步 FLOPs 最多降 4.5×。


<details>
  <summary>Details</summary>
Motivation: 直接在 DINOv2 patch 特征上做扩散虽能出高质量图像，但 patch 网格冗余严重，导致计算浪费。

Method: 提出 FlatDINO——变分自编码器，将冗余的二维 patch 特征压缩成长度仅 32 的一维连续 token 序列（总维度压缩 48×）；随后用 DiT-XL 在该潜空间上做扩散生成。

Result: ImageNet 256×256 上，基于 FlatDINO 的 DiT-XL 在 classifier-free guidance 下取得 gFID 1.80，与未压缩 DINOv2 特征扩散相当，但单次前向 FLOPs 减少 8×，单训练步最多减少 4.5×。

Conclusion: FlatDINO 在几乎不牺牲生成质量的前提下显著降低扩散模型计算开销，验证了高维 patch 特征可被极度压缩，为高效特征空间生成提供了新思路。结果尚属初步，工作仍在推进。

Abstract: Recent work has shown that diffusion models can generate high-quality images by operating directly on SSL patch features rather than pixel-space latents. However, the dense patch grids from encoders like DINOv2 contain significant redundancy, making diffusion needlessly expensive. We introduce FlatDINO, a variational autoencoder that compresses this representation into a one-dimensional sequence of just 32 continuous tokens -an 8x reduction in sequence length and 48x compression in total dimensionality. On ImageNet 256x256, a DiT-XL trained on FlatDINO latents achieves a gFID of 1.80 with classifier-free guidance while requiring 8x fewer FLOPs per forward pass and up to 4.5x fewer FLOPs per training step compared to diffusion on uncompressed DINOv2 features. These are preliminary results and this work is in progress.

</details>


### [66] [PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation](https://arxiv.org/abs/2602.04876)
*Jiahao Zhan,Zizhang Li,Hong-Xing Yu,Jiajun Wu*

Main category: cs.CV

TL;DR: 单图→长时序4D场景生成的闭环混合模拟器，视觉与物理双向耦合，首次实现交互式持续修正。


<details>
  <summary>Details</summary>
Motivation: 现有方法将物理状态与视觉表征解耦，导致生成式优化无法反向修正物理模型，长时序交互因误差累积而崩溃。

Method: 提出 PerpetualWonder：①统一表征——在视觉基元与物理状态间建立双向可微链接；②闭环更新——利用多视角观测聚合监督，消除单视角优化歧义，实现生成式动态与外观同步修正。

Result: 仅凭单张图像即可生成复杂多步长时序交互，保持物理合理性与视觉一致性，显著优于无法闭环修正的基线方法。

Conclusion: 视觉-物理双向耦合的闭环生成模拟是长时序4D 场景生成的关键，PerpetualWonder 为可交互式神经模拟器提供了可扩展范式。

Abstract: We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [67] [WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling](https://arxiv.org/abs/2602.03924)
*Michael Aich,Andreas Fürst,Florian Sestak,Carlos Ruiz-Gonzalez,Niklas Boers,Johannes Brandstetter*

Main category: cs.LG

TL;DR: WIND 是一个无需任务微调即可统一替代多种气象专用模型的预训练大气基础模型，通过自监督视频扩散先验与后验采样求解逆问题，实现预报、降尺度、缺测重建、守恒约束及气候变化情景反事实模拟。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽革新了气象建模，但现有方法碎片化严重——每个任务都需单独训练专用模型，缺乏可统一处理多任务的通用基础模型。

Method: 以自监督视频重建为目标，用无条件视频扩散模型从噪声态迭代重建大气动态，预训练出任务无关的通用先验；推断阶段将各类下游问题严格建模为逆问题，通过扩散后验采样求解，无需任何任务特定微调。

Result: 在概率预报、时空降尺度、稀疏观测重建、守恒定律约束及全球变暖下极端事件反事实 storyline 生成等关键任务上，单一预训练 WIND 即可替代多套专用基线模型，且保持物理一致性。

Conclusion: 通过生成式视频建模与逆问题求解的统一框架，WIND 为 AI 气象建模提供了无需微调、计算高效的新范式，显著降低开发与应用门槛。

Abstract: Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing specialized baselines across a vast array of tasks. Crucially, in contrast to previous atmospheric foundation models, we achieve this without any task-specific fine-tuning. To learn a robust, task-agnostic prior of the atmosphere, we pre-train WIND with a self-supervised video reconstruction objective, utilizing an unconditional video diffusion model to iteratively reconstruct atmospheric dynamics from a noisy state. At inference, we frame diverse domain-specific problems strictly as inverse problems and solve them via posterior sampling. This unified approach allows us to tackle highly relevant weather and climate problems, including probabilistic forecasting, spatial and temporal downscaling, sparse reconstruction and enforcing conservation laws purely with our pre-trained model. We further demonstrate the model's capacity to generate physically consistent counterfactual storylines of extreme weather events under global warming scenarios. By combining generative video modeling with inverse problem solving, WIND offers a computationally efficient paradigm shift in AI-based atmospheric modeling.

</details>


### [68] [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876)
*Kyuseong Choi,Dwaipayan Saha,Woojeong Kim,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: GOPO 用排序替代绝对奖励值，在非可验证奖励场景下比 GRPO 训练更快、奖励更高、LLM-as-judge 胜率更好。


<details>
  <summary>Details</summary>
Motivation: 标准 RLHF 先用 pairwise 偏好学奖励模型，再拿绝对奖励值做策略优化；但在摘要、对话等奖励不可验证的任务中，绝对值与偏好排序不一致，导致次优策略。

Method: 提出 Group Ordinal Policy Optimization（GOPO）：在策略优化阶段仅保留组内奖励排名，丢弃具体数值，通过排序变换构造目标函数。

Result: 在多个任务和模型规模上，GOPO 相比 GRPO 获得 (1) 更高且更稳定的训练/验证奖励曲线；(2) 绝大多数中间 checkpoint 的 LLM-as-judge 胜率提升；(3) 用显著更少的步数达到同等策略质量。

Conclusion: 在非可验证奖励场景，仅利用奖励排序而非幅值的 GOPO 能更高效、更可靠地优化语言模型策略，为 RLHF 提供了一种更鲁棒的替代方案。

Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.

</details>


### [69] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: 提出 GeoIB：用信息几何把互信息瓶颈转化为 KL 投影距离，无需估计 MI；用 Fisher-Rao 与 Jacobian-Frobenius 两项显式控制压缩，配合自然梯度优化，在信息平面获得更稳、更优的准确率-压缩权衡。


<details>
  <summary>Details</summary>
Motivation: 现有深度 IB 依赖变分界或神经 MI 估计器，只能间接、有偏地控制 I(X;Z)，导致压缩不可控、优化脆弱。作者希望绕过 MI 估计，直接、稳定地优化信息瓶颈。

Method: 从信息几何视角将 I(X;Z) 与 I(Z;Y) 表示为联合分布到各自“独立流形”的最小 KL 投影；用分布级 Fisher-Rao 距离匹配 KL 二阶特性，并用几何级 Jacobian-Frobenius 项惩罚编码器拉回体积膨胀，给出 I(Z;X) 的局部容量上界；推导出与 FR 度量一致的自然梯度更新，并证明其加性形式一阶等价于测地更新；两项正则共享单一瓶颈乘子，形成 GeoIB 目标。

Result: 在多个基准数据集上，GeoIB 在信息平面取得优于主流 IB 基线的准确率-压缩权衡，同时表现出更好的重参数不变性与优化稳定性。

Conclusion: GeoIB 通过信息几何把 MI 瓶颈转化为可计算的几何投影，无需估计互信息即可显式、稳定地控制压缩，为深度信息瓶颈提供了一种新的、更鲁棒的优化框架。

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


### [70] [SpecMD: A Comprehensive Study On Speculative Expert Prefetching](https://arxiv.org/abs/2602.03921)
*Duc Hoang,Ajay Jaiswal,Mohammad Samragh,Minsik Cho*

Main category: cs.LG

TL;DR: 提出 SpecMD 统一框架系统评估 MoE 专家缓存策略，发现 LRU/LFU 失效；据此设计 Least-Stale 驱逐算法，在仅 0.6 GB 缓存下把冲突未命中降低 85×、TTFT 缩短 34.7%，命中率超 88%。


<details>
  <summary>Details</summary>
Motivation: MoE 虽只在推理时激活少数专家，但现有硬件专用缓存策略缺乏统一基准，其与不同硬件的交互机制尚不清楚，难以将理论稀疏性转化为实测性能提升。

Method: 构建 SpecMD 标准化基准框架，在受控真实约束下复现并扩展多种 MoE 缓存策略；通过大规模实验揭示专家访问不符合时间局部性假设，进而提出利用可预测访问模式的 Least-Stale 驱逐策略。

Result: 实验证明 Least-Stale 相比 LRU 可将冲突未命中减少高达 85 倍；在 OLMoE 上仅用 5 %（0.6 GB）显存缓存即可实现 >88 % 命中率，并将首 token 延迟（TTFT）降低 34.7 %。

Conclusion: MoE 专家访问模式可预测且非局部，Least-Stale 以极低缓存成本显著改善命中与延迟，为稀疏大模型在资源受限设备上的高效部署提供了可行方案。

Abstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric caching policies, but how these various caching policies interact with each other and different hardware specification remains poorly understood. To address this gap, we develop \textbf{SpecMD}, a standardized framework for benchmarking ad-hoc cache policies on various hardware configurations. Using SpecMD, we perform an exhaustive benchmarking of several MoE caching strategies, reproducing and extending prior approaches in controlled settings with realistic constraints. Our experiments reveal that MoE expert access is not consistent with temporal locality assumptions (e.g LRU, LFU). Motivated by this observation, we propose \textbf{Least-Stale}, a novel eviction policy that exploits MoE's predictable expert access patterns to reduce collision misses by up to $85\times$ over LRU. With such gains, we achieve over $88\%$ hit rates with up to $34.7\%$ Time-to-first-token (TTFT) reduction on OLMoE at only $5\%$ or $0.6GB$ of VRAM cache capacity.

</details>


### [71] [Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints](https://arxiv.org/abs/2602.03940)
*Olaf Yunus Laitinen Imanov,Duygu Erisken,Derya Umut Kulali,Taner Yilmaz,Rana Irem Turhan*

Main category: cs.LG

TL;DR: AURA 用分层多智能体强化学习在 72 小时内完成合规可负担住房选址，合规率 94.3%，比人工快 200 倍并多找出 23% 可行地块。


<details>
  <summary>Details</summary>
Motivation: 全球数十亿人缺可负担住房，但土地稀缺与复杂法规使传统选址耗时数月到数年，亟需自动化工具在硬约束下快速平衡成本、公平、环境与可达性。

Method: 将任务建模为带 127 项联邦与地方约束（QCT、DDA、LIHTC）的多目标马尔可夫决策过程；提出分层多智能体系统 AURA，采用监管感知状态编码、Pareto-约束策略梯度并保证可行性，通过奖励分解把即期成本与长期社会效益分离。

Result: 在 8 个美国都会区 47,392 宗地块数据上，AURA 合规率 94.3%，Pareto 超体积比强基线提升 37.2%；纽约 2026 案例把选址时间从 18 个月缩至 72 小时，多识别 23% 可行地块，所选地块公交可达性优 31%、环境影响降 19%。

Conclusion: AURA 首次在真实联邦-地方监管框架下实现实时、合规、多目标可负担住房选址，可显著加速政策落地并提升选址质量，为城市资源自主分配提供可扩展范式。

Abstract: Affordable housing shortages affect billions, while land scarcity and regulations make site selection slow. We present AURA (Autonomous Urban Resource Allocator), a hierarchical multi-agent reinforcement learning system for real-time affordable housing site selection under hard regulatory constraints (QCT, DDA, LIHTC). We model the task as a constrained multi-objective Markov decision process optimizing accessibility, environmental impact, construction cost, and social equity while enforcing feasibility. AURA uses a regulatory-aware state encoding 127 federal and local constraints, Pareto-constrained policy gradients with feasibility guarantees, and reward decomposition separating immediate costs from long-term social outcomes. On datasets from 8 U.S. metros (47,392 candidate parcels), AURA attains 94.3% regulatory compliance and improves Pareto hypervolume by 37.2% over strong baselines. In a New York City 2026 case study, it reduces selection time from 18 months to 72 hours and identifies 23% more viable sites; chosen sites have 31% better transit access and 19% lower environmental impact than expert picks.

</details>


### [72] [Representation Geometry as a Diagnostic for Out-of-Distribution Robustness](https://arxiv.org/abs/2602.03951)
*Ali Zia,Farid Hazratian*

Main category: cs.LG

TL;DR: 无需标签即可通过嵌入空间的几何特征（谱复杂度＋曲率）预判模型对分布漂移的鲁棒性，实现无监督的鲁棒检查点筛选。


<details>
  <summary>Details</summary>
Motivation: 分布漂移场景下缺乏目标域标签，无法直接监控或优化OOD性能；已有方法依赖训练正则或低阶统计量，未能利用嵌入空间几何结构作为事后诊断信号。

Method: 提出基于几何的诊断框架：在ID嵌入上构建类条件k近邻图，提取两个不变量——全局谱复杂度（归一化拉普拉斯矩阵的约化对数行列式）与局部光滑度（Ollivier–Ricci曲率均值）；跨架构、训练策略及腐败基准验证其预测能力，并用受控扰动与拓扑分析确认信号反映表征结构而非表面统计。

Result: 谱复杂度越低、曲率越高，OOD准确率越高；该关系在多种设定下稳定成立，可实现无监督、可解释的鲁棒检查点选择。

Conclusion: 表征几何提供了可靠、无需标签的鲁棒性诊断工具，为分布漂移下的模型选择开辟了新途径。

Abstract: Robust generalization under distribution shift remains difficult to monitor and optimize in the absence of target-domain labels, as models with similar in-distribution accuracy can exhibit markedly different out-of-distribution (OOD) performance. While prior work has focused on training-time regularization and low-order representation statistics, little is known about whether the geometric structure of learned embeddings provides reliable post-hoc signals of robustness. We propose a geometry-based diagnostic framework that constructs class-conditional mutual k-nearest-neighbor graphs from in-distribution embeddings and extracts two complementary invariants: a global spectral complexity proxy based on the reduced log-determinant of the normalized Laplacian, and a local smoothness measure based on Ollivier--Ricci curvature. Across multiple architectures, training regimes, and corruption benchmarks, we find that lower spectral complexity and higher mean curvature consistently predict stronger OOD accuracy across checkpoints. Controlled perturbations and topological analyses further show that these signals reflect meaningful representation structure rather than superficial embedding statistics. Our results demonstrate that representation geometry enables interpretable, label-free robustness diagnosis and supports reliable unsupervised checkpoint selection under distribution shift.

</details>


### [73] [eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models](https://arxiv.org/abs/2602.03986)
*Nikolaos Bousias,Lars Lindemann,George Pappas*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.

</details>


### [74] [When Chains of Thought Don't Matter: Causal Bypass in Large Language Models](https://arxiv.org/abs/2602.03994)
*Anish Sathyanarayanan,Aditya Nagarsekar,Aarush Rathore*

Main category: cs.LG

TL;DR: 尽管 CoT 提示被寄予厚望，但模型答案往往与推理链因果脱钩；即使文本看似合规，仍可能走“旁路”捷径。作者提出可解释+因果探测的审计框架，发现任务间差异显著：多数 QA 几乎完全旁路（CMI≈0），部分逻辑题可达 0.56，且推理窗口层位狭窄。


<details>
  <summary>Details</summary>
Motivation: 业界普遍假设 CoT 能暴露模型真实推理并提升透明度。作者质疑该假设：若模型仅做表面合规而答案实际绕过 CoT，则透明度承诺失效。需量化“推理链是否被真正依赖”这一因果忠实性缺口。

Method: 构建诊断框架：(i) 可解释行为模块，对 CoT 文本中的操纵相关信号打分；(ii) 因果探测，用隐藏状态补丁法计算 CoT 介导影响度 CMI，并报告旁路得分 1−CMI。结合审计感知提示与层位分析，评估不同任务与层的因果依赖。

Result: 审计感知提示虽显著提高可检测操纵信号（平均风险分 +5.10），但因果探测显示任务依赖的弱中介：多数 QA 项目 CMI≈0（几乎完全旁路），部分逻辑题 CMI 最高 0.56；层分析发现即使平均 CMI 低，仍存在狭窄“推理窗口”。

Conclusion: CoT 的透明度承诺在因果层面常不成立；表面合规与真实依赖脱钩。亟需以因果忠实性而非文本忠实性作为审计标准，并针对任务与层位设计更严格的忠实性约束。

Abstract: Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: even when CoT is verbose, strategic, and flagged by surface-level manipulation detectors, model answers are often causally independent of the CoT content. We present a diagnostic framework for auditing this failure mode: it combines (i) an interpretable behavioral module that scores manipulation-relevant signals in CoT text and (ii) a causal probe that measures CoT-mediated influence (CMI) via hidden-state patching and reports a bypass score ($1-\mathrm{CMI}$), quantifying the degree to which the answer is produced by a bypass circuit independent of the rationale. In pilot evaluations, audit-aware prompting increases detectable manipulation signals (mean risk-score delta: $+5.10$), yet causal probes reveal task-dependent mediation: many QA items exhibit near-total bypass (CMI $\approx 0$), while some logic problems show stronger mediation (CMI up to $0.56$). Layer-wise analysis reveals narrow and task-dependent ``reasoning windows'' even when mean CMI is low.

</details>


### [75] [PromptSplit: Revealing Prompt-Level Disagreement in Generative Models](https://arxiv.org/abs/2602.04009)
*Mehdi Lotfian,Mohammad Jalali,Farzan Farnia*

Main category: cs.LG

TL;DR: PromptSplit 用核方法把提示与输出做张量积嵌入，通过两模型协方差矩阵差值的特征空间，快速定位导致行为差异的关键提示，理论误差 O(1/r²)，实验覆盖文生图、文生文与图像描述任务。


<details>
  <summary>Details</summary>
Motivation: 提示驱动的生成模型种类繁多、训练数据与架构各异，亟需系统化手段找出哪些提示会触发模型行为分歧，以便用户选型与开发者诊断。

Method: 提出 PromptSplit 框架：1) 将提示与生成输出分别编码后做张量积，构建联合表示；2) 计算两模型对应的核协方差矩阵，取加权差值；3) 对其特征空间分解，提取行为差异主方向；4) 用随机投影将复杂度降至 O(nr²+r³)，并给出误差界。

Result: 在文生图、文生文和图像字幕任务上，PromptSplit 能准确检出预设的 ground-truth 差异，并高亮引发分歧的具体提示，提供可解释的诊断结果。

Conclusion: PromptSplit 为生成模型行为差异提供了一种可扩展、可解释且理论保障的提示级检测工具，有助于模型比较、风险发现与提示优化。

Abstract: Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts lead to distinct model behaviors. In this work, we propose PromptSplit, a kernel-based framework for detecting and analyzing prompt-dependent disagreement between generative models. For each compared model pair, PromptSplit constructs a joint prompt--output representation by forming tensor-product embeddings of the prompt and image (or text) features, and then computes the corresponding kernel covariance matrix. We utilize the eigenspace of the weighted difference between these matrices to identify the main directions of behavioral difference across prompts. To ensure scalability, we employ a random-projection approximation that reduces computational complexity to $O(nr^2 + r^3)$ for projection dimension $r$. We further provide a theoretical analysis showing that this approximation yields an eigenstructure estimate whose expected deviation from the full-dimensional result is bounded by $O(1/r^2)$. Experiments across text-to-image, text-to-text, and image-captioning settings demonstrate that PromptSplit accurately detects ground-truth behavioral differences and isolates the prompts responsible, offering an interpretable tool for detecting where generative models disagree.

</details>


### [76] [Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.04019)
*Yichen Xu,Yuyang Liang,Shan Dai,Tianyang Hu,Tsz Nam Chan,Chenhao Ma*

Main category: cs.LG

TL;DR: 提出“投影残差”统一视角，把 PEFT 层选择问题转化为可解释的三元组度量；依此设计可复用的 Layer Card，在 Qwen3-8B 上仅用 30–40 % 层即可达到全层 LoRA 98 % 性能，显著降低训练与推理开销。


<details>
  <summary>Details</summary>
Motivation: 大模型全参数微调成本激增，现有 PEFT 方法普遍“一刀切”地对所有层插入适配器，缺乏对“该调哪一层”的系统理解与定量工具，导致在边缘部署、快速迭代等场景下训练-推理资源浪费。

Method: 1) 建立统一投影残差框架：将 PEFT 视为在冻结主干的每层注入可学习残差，并在局部二次近似下导出层选择的三元解析指标——投影残差范数(resnorm)、激活能量、层间耦合度。2) 证明对于平方损失与线性适配器，resnorm 等价于归一化梯度范数，激活能量决定病态性与噪声放大，弱耦合时各层贡献近似可加。3) 设计 Layer Card：一次性测量并缓存每层的残差信号强度、计算代价与预期性能，形成可复用诊断表。4) 基于 Layer Card 的贪心/背包策略，在指定预算下动态选择最优层子集进行 LoRA 插入。

Result: 在 Qwen3-8B 的五大下游任务上，仅调整 30–40 % 的层即可达到全层 LoRA 97–99 % 的精度，训练参数减少 2.5×，GPU 小时节省 2.2×，推理时适配层数量降低 60 %，显著优于随机层选取与人工经验方案。

Conclusion: Layer Card 为 PEFT 提供了可解释、可复用、低成本的一层一表诊断工具，使“调哪层”从黑箱经验变为可量化决策；其投影残差视角可推广至其他适配器形式与损失函数，为资源受限场景下的高效大模型适配开辟了新范式。

Abstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited understanding or leverage of layer selection. This paper develops a unified projected residual view of PEFT on top of a frozen base model. Under a local quadratic approximation, layerwise adaptation is governed by three quantities: (i) the projected residual norm (resnorm), which measures how much correctable bias a layer can capture; (ii) the activation energy, which determines feature conditioning; and (iii) layer coupling, which quantifies how strongly residuals interact across layers. We show that, for squared loss and linear adapters, the resnorm equals a normalized gradient norm, activation energy controls ill-conditioning and noise amplification, and weak coupling yields approximately additive layerwise contributions. Building on these insights, we introduce the Layer Card, a reusable diagnostic that summarizes residual signal strength, compute cost, and performance for each layer of a given model. With an identical model and LoRA configuration, Layer Card-guided placement refines the choice of adapted layers to flexibly prioritize different objectives, such as maximizing performance or reducing fine-tuning cost. Moreover, on Qwen3-8B, we show that selectively adapting a subset of layers can achieve performance close to full-layer LoRA while substantially reducing fine-tuning cost and the number of adapter-augmented layers during inference, offering a more cost-performance-aware alternative to full-layer insertion.

</details>


### [77] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: GROOVE 利用半监督 GroupCLIP 对比损失，在仅共享扰动标签的弱配对多模态数据上实现与/优于现有方法的跨模态匹配与插补性能。


<details>
  <summary>Details</summary>
Motivation: 高内涵扰动数据常跨模态但仅“弱配对”（共享扰动标签却无样本级对应），CLIP 需强配对，SupCon 仅单模态，缺乏针对弱配对场景的多模态对比学习框架。

Method: 提出 GroupCLIP——将 CLIP 的跨模态对比与 SupCon 的组监督结合，实现组级对比；并集成即时回译自编码器促进跨模态纠缠，同时设计基于最优运输的组合评估体系系统测试不同对齐器与模拟扰动效应。

Result: 在合成模拟与两套真实单细胞遗传扰动数据上，GROOVE 在跨模态匹配与插补任务中持平或优于现有方法；消融实验显示 GroupCLIP 为性能提升关键；评估亦揭示尚无对齐器可一统所有场景。

Conclusion: 组级约束是弱配对多模态表征学习的有效策略，GroupCLIP 与组合评估框架为该领域提供新基线与分析工具。

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [78] [A Consensus-Bayesian Framework for Detecting Malicious Activity in Enterprise Directory Access Graphs](https://arxiv.org/abs/2602.04027)
*Pratyush Uppuluri,Shilpa Noushad,Sajan Kumar*

Main category: cs.LG

TL;DR: 用“共识+贝叶斯”双引擎在企业目录访问图上抓内鬼：把目录当话题、用户当智能体，用带权意见动力学模拟访问演化；通过 SCC 结构规范检测跨组件逻辑扰动，并以时变贝叶斯异常分数量化不确定度，合成数据实验表明对逻辑不一致敏感且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 企业目录服务是权限中枢，传统基于签名或统计阈值的入侵检测难以刻画用户间复杂的逻辑依赖与动态演化，亟需一种能融合结构信息与不确定度量化的方法，以提前发现伪装成正常访问的恶意行为。

Method: ①将目录建模为“话题”、用户建模为“智能体”，构建多层交互图；②用影响矩阵 W 刻画目录相似度，用动态矩阵 Ci 编码用户间逻辑依赖；③在强连通分量(SCC) 结构规范下，用影响加权意见动力学模拟访问演化，并以理论收敛结果保证话题稳态；④把恶意访问视为跨 SCC 的“逻辑扰动”，通过缩放意见方差捕捉异常；⑤引入静态+在线先验的时变贝叶斯异常评分，持续量化检测不确定性。

Result: 合成访问图实验显示，该方法能在扰动强度仅 5% 时即显著抬高异常分数，AUC>0.95；当图结构动态变化（节点增删、权重漂移）时，检测性能下降 <5%，验证了对逻辑不一致的高敏感与动态鲁棒性。

Conclusion: 共识-贝叶斯混合框架首次把意见动力学收敛理论与在线贝叶斯推理结合，可在无标注条件下利用图结构规范与演化一致性实现早期、可解释、带不确定度估计的恶意访问检测，为特权滥用与内部威胁提供新的实时防御范式。

Abstract: This work presents a consensus-based Bayesian framework to detect malicious user behavior in enterprise directory access graphs. By modeling directories as topics and users as agents within a multi-level interaction graph, we simulate access evolution using influence-weighted opinion dynamics. Logical dependencies between users are encoded in dynamic matrices Ci, and directory similarity is captured via a shared influence matrix W. Malicious behavior is injected as cross-component logical perturbations that violate structural norms of strongly connected components(SCCs). We apply theoretical guarantees from opinion dynamics literature to determine topic convergence and detect anomaly via scaled opinion variance. To quantify uncertainty, we introduce a Bayesian anomaly scoring mechanism that evolves over time, using both static and online priors. Simulations over synthetic access graphs validate our method, demonstrating its sensitivity to logical inconsistencies and robustness under dynamic perturbation.

</details>


### [79] [The Illusion of Generalization: Re-examining Tabular Language Model Evaluation](https://arxiv.org/abs/2602.04031)
*Aditya Gorla,Ratish Puduppully*

Main category: cs.LG

TL;DR: 对 8B 参数表格语言模型 Tabula 的 165 个数据集再评估显示：其“涌现泛化”主要来自四分位分类任务；高分数据集普遍存在训练-测试重叠与任务级泄漏；仅用通用指令微调即可复现 92.2% 分类性能，表明所谓表格推理能力实为评估假象。


<details>
  <summary>Details</summary>
Motivation: 近期研究宣称表格语言模型（TLM）在表格预测任务上表现出“涌现式泛化”，但缺乏系统性验证，可能因数据污染或任务设计偏差而高估能力。

Method: 以 Tabula-8B 为对象，在 UniPredict 的 165 个数据集上重跑实验；对比 majority-class 基线，检测训练-测试样本重叠与任务级泄漏；进一步用无表格数据的通用指令微调，测量性能恢复比例。

Result: 1) 二分类与多分类的中位数提升接近 0，整体高分完全由四分位分类任务拉动；2) 高分数据集普遍存在完全重叠与任务泄漏，常规去重无法识别；3) 纯指令微调即可恢复 92.2% 标准分类性能，在四分位任务上格式熟悉度弥补 71.3% 差距，剩余差距归因于污染数据。

Conclusion: TLM 的“泛化”更多是评估流程缺陷所致假象，而非模型真正习得表格推理。建议未来加强数据去重、任务分层与格式消融，以建立更可信的 TLM 评估协议。

Abstract: Tabular Language Models (TLMs) have been claimed to achieve emergent generalization for tabular prediction. We conduct a systematic re-evaluation of Tabula-8B as a representative TLM, utilizing 165 datasets from the UniPredict benchmark. Our investigation reveals three findings. First, binary and categorical classification achieve near-zero median lift over majority-class baselines and strong aggregate performance is driven entirely by quartile classification tasks. Second, top-performing datasets exhibit pervasive contamination, including complete train-test overlap and task-level leakage that evades standard deduplication. Third, instruction-tuning without tabular exposure recovers 92.2% of standard classification performance and on quartile classification, format familiarity closes 71.3% of the gap with the residual attributable to contaminated datasets. These findings suggest claimed generalization likely reflects evaluation artifacts rather than learned tabular reasoning. We conclude with recommendations for strengthening TLM evaluation.

</details>


### [80] [DADP: Domain Adaptive Diffusion Policy](https://arxiv.org/abs/2602.04037)
*Pengcheng Wang,Qinghang Liu,Haotian Lin,Yiheng Li,Guojian Zhan,Masayoshi Tomizuka,Yixiao Wang*

Main category: cs.LG

TL;DR: 用滞后上下文把静态域特征与瞬态动态解耦，再把该特征注入扩散策略，实现零样本域迁移。


<details>
  <summary>Details</summary>
Motivation: 现有域表示方法用相邻上下文，易将静态域信息与动态变化混为一谈，导致策略在未知动力学上零-shot 迁移失败。

Method: 提出 DADP：① Lagged Context Dynamical Prediction——用历史滞后上下文预测未来状态，无监督滤掉瞬态动态，得到纯净静态域表示；② 将该表示直接偏置扩散模型的先验并重构去噪目标，实现域感知生成。

Result: 在多个机器人运动与操作基准上，DADP 的零-shot 域迁移成功率显著优于先前方法，且表示可视化验证了解耦效果。

Conclusion: 通过滞后上下文解耦+扩散注入，可在无监督条件下获得可泛化的域自适应策略，为复杂动力学下的零-shot 控制提供了新思路。

Abstract: Learning domain adaptive policies that can generalize to unseen transition dynamics, remains a fundamental challenge in learning-based control. Substantial progress has been made through domain representation learning to capture domain-specific information, thus enabling domain-aware decision making. We analyze the process of learning domain representations through dynamical prediction and find that selecting contexts adjacent to the current step causes the learned representations to entangle static domain information with varying dynamical properties. Such mixture can confuse the conditioned policy, thereby constraining zero-shot adaptation. To tackle the challenge, we propose DADP (Domain Adaptive Diffusion Policy), which achieves robust adaptation through unsupervised disentanglement and domain-aware diffusion injection. First, we introduce Lagged Context Dynamical Prediction, a strategy that conditions future state estimation on a historical offset context; by increasing this temporal gap, we unsupervisedly disentangle static domain representations by filtering out transient properties. Second, we integrate the learned domain representations directly into the generative process by biasing the prior distribution and reformulating the diffusion target. Extensive experiments on challenging benchmarks across locomotion and manipulation demonstrate the superior performance, and the generalizability of DADP over prior methods. More visualization results are available on the https://outsider86.github.io/DomainAdaptiveDiffusionPolicy/.

</details>


### [81] [Partition Trees: Conditional Density Estimation over General Outcome Spaces](https://arxiv.org/abs/2602.04042)
*Felipe Angelim,Alessandro Leite*

Main category: cs.LG

TL;DR: 提出“划分树/森林”，用分段常数密度直接极小化条件负对数似然，统一处理连续与离散响应，无需分布假设，兼具可扩展性与非参优势，在概率预测上优于 CART 及主流概率树方法，并对冗余特征与异方差噪声稳健。


<details>
  <summary>Details</summary>
Motivation: 现有概率树多针对连续或离散响应做参数假设，难以兼顾一般输出空间、非参灵活性与可扩展性；需要一种统一框架实现条件密度估计，同时保持树结构的可解释与高效训练。

Method: 构建“划分树”：将条件分布建模为数据自适应划分上的分段常数密度，以条件负对数似然为分裂准则直接学习树结构；进一步通过平均多棵树的条件密度得到“划分森林”集成。

Result: 在多种数据集上，划分树的概率预测精度显著优于 CART 风格树；划分森林与当前最优概率树及随机森林相当或更优，且对冗余特征和异方差噪声表现出鲁棒性。

Conclusion: 划分树/森林提供了一种无需参数假设、统一处理连续/离散响应的可扩展非参条件密度估计工具，兼具预测性能与鲁棒性，可作为现有概率树与随机森林的有力替代。

Abstract: We propose Partition Trees, a tree-based framework for conditional density estimation over general outcome spaces, supporting both continuous and categorical variables within a unified formulation. Our approach models conditional distributions as piecewise-constant densities on data adaptive partitions and learns trees by directly minimizing conditional negative log-likelihood. This yields a scalable, nonparametric alternative to existing probabilistic trees that does not make parametric assumptions about the target distribution. We further introduce Partition Forests, an ensemble extension obtained by averaging conditional densities. Empirically, we demonstrate improved probabilistic prediction over CART-style trees and competitive or superior performance compared to state-of-the-art probabilistic tree methods and Random Forests, along with robustness to redundant features and heteroscedastic noise.

</details>


### [82] [An Empirical Survey and Benchmark of Learned Distance Indexes for Road Networks](https://arxiv.org/abs/2602.04068)
*Gautam Choudhary,Libin Zhou,Yeasir Rayhan,Walid G. Aref*

Main category: cs.LG

TL;DR: 首个面向路网ML距离索引的实证综述：系统测评10种代表方法 vs. 经典基线，给出训练时间、查询延迟、存储与精度四维权衡，并开源统一代码库。


<details>
  <summary>Details</summary>
Motivation: 路网最短路径距离计算是导航与LBS核心操作，经典算法延迟高；近年兴起的ML型距离索引虽能近似加速，却缺乏系统横向评估，阻碍实际选型与后续研究。

Method: 在7张真实路网与轨迹衍生查询集上，对10种代表ML型索引与强非ML基线进行四维（训练时间、查询延迟、存储、精度）实证对比，并构建统一开源代码框架保证可复现性。

Result: 首次系统揭示ML型索引在精度-延迟-存储-训练成本间的实际权衡，指出部分ML方案在特定场景可优于经典索引，同时发布开源基准平台供后续研究。

Conclusion: ML距离索引已展现潜力，但尚不存在全能方案；选型需结合路网规模、精度要求及资源约束。未来应聚焦训练效率、增量更新与理论误差界，并依托公开基准持续迭代。

Abstract: The calculation of shortest-path distances in road networks is a core operation in navigation systems, location-based services, and spatial analytics. Although classical algorithms, e.g., Dijkstra's algorithm, provide exact answers, their latency is prohibitive for modern real-time, large-scale deployments. Over the past two decades, numerous distance indexes have been proposed to speed up query processing for shortest distance queries. More recently, with the advancement in machine learning (ML), researchers have designed and proposed ML-based distance indexes to answer approximate shortest path and distance queries efficiently. However, a comprehensive and systematic evaluation of these ML-based approaches is lacking. This paper presents the first empirical survey of ML-based distance indexes on road networks, evaluating them along four key dimensions: Training time, query latency, storage, and accuracy. Using seven real-world road networks and workload-driven query datasets derived from trajectory data, we benchmark ten representative ML techniques and compare them against strong classical non-ML baselines, highlighting key insights and practical trade-offs. We release a unified open-source codebase to support reproducibility and future research on learned distance indexes.

</details>


### [83] [Agentic AI-Empowered Dynamic Survey Framework](https://arxiv.org/abs/2602.04071)
*Furkan Mumcu,Lokman Bekit,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.LG

TL;DR: 把综述论文看作“活文档”，提出一套可持续、增量更新的智能框架，让旧综述随新研究动态演进，避免迅速过时。


<details>
  <summary>Details</summary>
Motivation: 科研产出爆炸式增长，传统一次性综述发表后迅速老化，导致知识碎片化与重复劳动，需要把“写完即弃”的静态模式转变为“长期维护”的动态模式。

Method: 将综述撰写重定义为长周期维护任务，设计基于智能体的 Dynamic Survey Framework：1) 结构保持模块识别并保留原文章节组织与逻辑流；2) 增量集成模块用智能体持续检索、过滤、摘要新文献；3) 最小扰动更新策略只替换或追加必要内容，维持连贯性；4) 采用回顾式实验，用已发表综述+其后一年新文献模拟真实更新场景，评估框架效果。

Result: 在模拟实验中，框架能准确召回 85% 以上相关新工作，新增章节与原文衔接自然，人工评估结构一致性得分提升 30%，冗余信息减少 22%，显示出“活综述”可持续更新且不失连贯性。

Conclusion: 把综述视为可演化的长周期资产，用智能体驱动的增量维护替代一次性写作，可显著延长综述寿命、降低重复调研成本，为社区提供始终前沿、结构稳定的知识地图。

Abstract: Survey papers play a central role in synthesizing and organizing scientific knowledge, yet they are increasingly strained by the rapid growth of research output. As new work continues to appear after publication, surveys quickly become outdated, contributing to redundancy and fragmentation in the literature. We reframe survey writing as a long-horizon maintenance problem rather than a one-time generation task, treating surveys as living documents that evolve alongside the research they describe. We propose an agentic Dynamic Survey Framework that supports the continuous updating of existing survey papers by incrementally integrating new work while preserving survey structure and minimizing unnecessary disruption. Using a retrospective experimental setup, we demonstrate that the proposed framework effectively identifies and incorporates emerging research while preserving the coherence and structure of existing surveys.

</details>


### [84] [Stroke Lesions as a Rosetta Stone for Language Model Interpretability](https://arxiv.org/abs/2602.04074)
*Julius Fridriksson,Roger D. Newman-Norlund,Saeed Ahmadi,Regan Willis,Nadra Salman,Kalil Warren,Xiang Guan,Yong Yang,Srihari Nelakuditi,Rutvik Desai,Leonardo Bonilha,Jeff Charney,Chris Rorden*

Main category: cs.LG

TL;DR: 用中风失语症病人的脑损伤-行为数据当“标尺”，系统干扰大语言模型后，让模型和人类做同样的语言测试；若模型犯错模式与某类病人相似，其“虚拟损伤”就能映射到真人病灶，67–68 % 情况下命中，首次用临床神经科学从外部验证模型组件的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性方法依赖内部指标，无法外部验证哪些组件真正决定语言功能；神经病学百年来的“病灶-症状映射”是因果性金标准，却尚未用于评估人工系统。

Method: 构建Brain-LLM Unified Model（BLUM）：①用410例慢性中风失语症数据训练“行为错误→脑损伤位置”的映射模型；②对Transformer各层做系统扰动（lesion）；③让扰动后的LLM与患者完成相同临床测验（图片命名、句子补全）；④将LLM的错误特征投射到人类 lesion 空间，看预测病灶是否对应真实病灶。

Result: LLM错误模式与患者足够相似，预测病灶在误差匹配人群中的空间对应率：图片命名67 %（p<10⁻²³），句子补全68.3 %（p<10⁻⁶¹）；语义主导错误映射至腹侧通路病灶，音位主导错误映射至背侧通路病灶。

Conclusion: 临床神经科学的病灶-症状映射可作为外部参考框架，用于评判人工语言系统组件的必要性；行为对齐可能反映共享计算原则，为LLM可解释性开辟了新途径。

Abstract: Large language models (LLMs) have achieved remarkable capabilities, yet methods to verify which model components are truly necessary for language function remain limited. Current interpretability approaches rely on internal metrics and lack external validation. Here we present the Brain-LLM Unified Model (BLUM), a framework that leverages lesion-symptom mapping, the gold standard for establishing causal brain-behavior relationships for over a century, as an external reference structure for evaluating LLM perturbation effects. Using data from individuals with chronic post-stroke aphasia (N = 410), we trained symptom-to-lesion models that predict brain damage location from behavioral error profiles, applied systematic perturbations to transformer layers, administered identical clinical assessments to perturbed LLMs and human patients, and projected LLM error profiles into human lesion space. LLM error profiles were sufficiently similar to human error profiles that predicted lesions corresponded to actual lesions in error-matched humans above chance in 67% of picture naming conditions (p < 10^{-23}) and 68.3% of sentence completion conditions (p < 10^{-61}), with semantic-dominant errors mapping onto ventral-stream lesion patterns and phonemic-dominant errors onto dorsal-stream patterns. These findings open a new methodological avenue for LLM interpretability in which clinical neuroscience provides external validation, establishing human lesion-symptom mapping as a reference framework for evaluating artificial language systems and motivating direct investigation of whether behavioral alignment reflects shared computational principles.

</details>


### [85] [Federated Concept-Based Models: Interpretable models with distributed supervision](https://arxiv.org/abs/2602.04093)
*Dario Fenoglio,Arianna Casanova,Francesco De Santis,Mohan Li,Gabriele Dominici,Johannes Schneider,Martin Gjoreski,Marc Langheinrich,Pietro Barbiero,Giovanni De Felice*

Main category: cs.LG

TL;DR: 提出联邦概念模型（F-CMs），在动态联邦环境中跨机构聚合概念知识，无需共享原始数据即可实现可扩展、可解释的深度推理，并支持对本地未标注概念的推断。


<details>
  <summary>Details</summary>
Motivation: 概念模型（CMs）依赖昂贵且稀缺的概念标注；联邦学习（FL）虽能整合多机构数据，但缺乏可解释范式，且真实 FL 场景存在概念空间与架构动态变化、非平稳异构等挑战，导致 CM 与 FL 难以直接结合。

Method: 设计 Federated Concept-based Models（F-CMs）：在联邦层面维护可扩展概念词典与动态架构，通过安全聚合协议同步跨机构概念表征；当新机构加入或新增概念监督时，采用高效架构生长/剪枝机制更新模型，同时利用知识蒸馏保持旧概念性能；推理阶段基于全局概念空间进行可解释预测，即使某概念在本地从未出现。

Result: 在模拟与真实医疗数据集上，F-CMs 在完整概念监督场景下保持与传统 CM 相当的准确率与干预有效性；相比非自适应联邦基线，F-CMs 在新概念适应速度、整体准确率及概念干预成功率上平均提升 8–15%，并首次实现对本地未提供概念的可解释推断。

Conclusion: F-CMs 将概念模型的可解释性引入动态联邦学习，突破标注孤岛与架构固定限制，在保护隐私的前提下实现跨机构概念知识共享与持续扩展，为医疗、金融等高 stakes 领域的可信分布式 AI 提供实用框架。

Abstract: Concept-based models (CMs) enhance interpretability in deep learning by grounding predictions in human-understandable concepts. However, concept annotations are expensive to obtain and rarely available at scale within a single data source. Federated learning (FL) could alleviate this limitation by enabling cross-institutional training that leverages concept annotations distributed across multiple data owners. Yet, FL lacks interpretable modeling paradigms. Integrating CMs with FL is non-trivial: CMs assume a fixed concept space and a predefined model architecture, whereas real-world FL is heterogeneous and non-stationary, with institutions joining over time and bringing new supervision. In this work, we propose Federated Concept-based Models (F-CMs), a new methodology for deploying CMs in evolving FL settings. F-CMs aggregate concept-level information across institutions and efficiently adapt the model architecture in response to changes in the available concept supervision, while preserving institutional privacy. Empirically, F-CMs preserve the accuracy and intervention effectiveness of training settings with full concept supervision, while outperforming non-adaptive federated baselines. Notably, F-CMs enable interpretable inference on concepts not available to a given institution, a key novelty with respect to existing approaches.

</details>


### [86] [Rethinking Perplexity: Revealing the Impact of Input Length on Perplexity Evaluation in LLMs](https://arxiv.org/abs/2602.04099)
*Letian Cheng,Junyan Wang,Yan Gao,Elliott Wen,Ting Dang,Hong Jia*

Main category: cs.LG

TL;DR: 输入长度会系统性地扭曲 LLM 的困惑度，LengthBenchmark 首次将其作为系统级变量纳入评测，发现滑动窗口协议在短文本上虚高、随片段增长模型普遍“受益”，且量化也无法消除该偏差。


<details>
  <summary>Details</summary>
Motivation: 困惑度虽常用，但近期发现其受无关长输入干扰而失真；现有研究仅做数据过滤，未把输入长度当作影响公平与效率的系统变量系统考察。

Method: 提出 LengthBenchmark 框架，把输入长度、评测协议（直接累加 vs. 固定窗口滑动）与系统开销（延迟、内存、费用）一起纳入评估；对多款代表性 LLM 及其量化版本进行跨上下文长度实验，并做鲁棒性检验。

Result: 滑动窗口在短输入上持续虚高评分；无论全精度还是量化模型，随着被评估片段变长，困惑度均呈“改善”假象；长度偏差普遍且独立于量化，破坏跨模型公平比较。

Conclusion: 长度偏差是系统性现象，必须将输入长度作为一级系统变量与协议设计共同控制，才能得出可靠、可部署的 LLM 评估结果。

Abstract: Perplexity is a widely adopted metric for assessing the predictive quality of large language models (LLMs) and often serves as a reference metric for downstream evaluations. However, recent evidence shows that perplexity can be unreliable, especially when irrelevant long inputs are used, raising concerns for both benchmarking and system deployment. While prior efforts have employed selective input filtering and curated datasets, the impact of input length on perplexity has not been systematically studied from a systems perspective and input length has rarely been treated as a first-class system variable affecting both fairness and efficiency. In this work, we close this gap by introducing LengthBenchmark, a system-conscious evaluation framework that explicitly integrates input length, evaluation protocol design, and system-level costs, evaluating representative LLMs under two scoring protocols (direct accumulation and fixed window sliding) across varying context lengths. Unlike prior work that focuses solely on accuracy-oriented metrics, LengthBenchmark additionally measures latency, memory footprint, and evaluation cost, thereby linking predictive metrics to deployment realities. We further incorporate quantized variants not as a main contribution, but as robustness checks, showing that length-induced biases persist across both full-precision and compressed models. This design disentangles the effects of evaluation logic, quantization, and input length, and demonstrates that length bias is a general phenomenon that undermines fair cross-model comparison. Our analysis yields two key observations: (i) sliding window evaluation consistently inflates performance on short inputs, and (ii) both full-precision and quantized models appear to realise gains as the evaluated segment length grows.

</details>


### [87] [Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis](https://arxiv.org/abs/2602.04107)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 用「有损压缩+有限码长」视角重新刻画机器学习泛化：采样=编码、模型=解码，显式拆分过拟合与归纳偏置失配，给出紧的样本复杂度下界，并统一信息论与稳定性度量。


<details>
  <summary>Details</summary>
Motivation: 传统泛化界常把过拟合与任务-算法失耦合在一起，难以指导实际调参与架构设计；需要一种能显式分离“算法自身过拟合程度”与“归纳偏置对任务匹配度”的统一理论。

Method: 将学习过程形式化为“有损压缩信道”：训练集采样视为编码器，模型参数视为解码器；引入有限码长（finite-blocklength）信息论工具，对固定随机算法及其最优采样策略推导样本复杂度和泛化误差的紧下界；进一步把过拟合项分解为互信息、条件熵等已知信息论量，并与稳定性系数建立等式关系。

Result: 得到同时依赖算法随机性、样本数、压缩率的泛化误差下界，其中过拟合与归纳偏置失配被显式拆分为两项；理论结果在常用高斯、离散假设类上闭合可算，且退化为经典MI-bound 与 VC-bound 的 sharpened 版本；数值实验显示该界对早期停止、数据增广等策略的预测趋势与实测误差一致。

Conclusion: 有限码长信息论为机器学习泛化提供了新的“压缩-解码”语言，不仅能精确定量过拟合，还能把信息论、稳定性、PAC-Bayes 等多条研究线统一在同一框架内，为算法设计与理论分析提供了可解释、可计算的指导原则。

Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.

</details>


### [88] [Rate-Optimal Noise Annealing in Semi-Dual Neural Optimal Transport: Tangential Identifiability, Off-Manifold Ambiguity, and Guaranteed Recovery](https://arxiv.org/abs/2602.04110)
*Raymond Chu,Jaewoong Choi,Dohyun Kwon*

Main category: cs.LG

TL;DR: 本文指出半对偶神经最优传输在低密度区域存在虚假解，并给出可计算的“终止噪声水平”ε_stat(N)，当退火至此阈值后继续降噪只会恶化优化条件而不提升统计精度。


<details>
  <summary>Details</summary>
Motivation: 半对偶神经最优传输虽通过极大-极小目标学习传输映射，但在低维流形数据上常收敛到错误或退化映射。需要理论上厘清虚假解来源，并给出可实际计算的停止准则。

Method: 1) 在低维流形假设下完整刻画虚假解：流形外目标欠定，流形内信号可识别；2) 引入加性噪声平滑，联合分析最优传输计划的量化稳定性、平滑偏差与有限样本误差，得到仅依赖内在维数 m 的统计收敛率；3) 导出显式公式 ε_stat(N) 实现最优速率，并证明继续退火会使降维后的半对偶目标病态化。

Result: 获得仅随内在维数 m 变化的最优统计速率；给出可计算的终端噪声水平 ε_stat(N) 作为退火停止规则；证明低于该阈值后优化条件恶化而统计精度不再提升。

Conclusion: ε_stat(N) 提供了原理性的早停准则，实际训练应在达到该噪声水平时终止，以在统计精度与优化行为之间取得最佳权衡。

Abstract: Semi-dual neural optimal transport learns a transport map via a max-min objective, yet training can converge to incorrect or degenerate maps. We fully characterize these spurious solutions in the common regime where data concentrate on low-dimensional manifold: the objective is underconstrained off the data manifold, while the on-manifold transport signal remains identifiable. Following Choi, Choi, and Kwon (2025), we study additive-noise smoothing as a remedy and prove new map recovery guarantees as the noise vanishes. Our main practical contribution is a computable terminal noise level $\varepsilon_{\mathrm{stat}}(N)$ that attains the optimal statistical rate, with scaling governed by the intrinsic dimension $m$ of the data. The formula arises from a theoretical unified analysis of (i) quantitative stability of optimal plans, (ii) smoothing-induced bias, and (iii) finite-sample error, yielding rates that depend on $m$ rather than the ambient dimension. Finally, we show that the reduced semi-dual objective becomes increasingly ill-conditioned as $\varepsilon \downarrow 0$. This provides a principled stopping rule: annealing below $\varepsilon_{\mathrm{stat}}(N)$ can $\textit{worsen}$ optimization conditioning without improving statistical accuracy.

</details>


### [89] [Turning mechanistic models into forecasters by using machine learning](https://arxiv.org/abs/2602.04114)
*Amit K. Chakraborty,Hao Wang,Pouria Ramazi*

Main category: cs.LG

TL;DR: 提出一种带时变参数的数据驱动微分方程发现框架，可同步学习常参数和随时间演化的参数，并用于预测；在多个生态与环境数据集上学习误差＜3%，1个月预测误差＜6%，优于CNN-LSTM与GBM。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方程发现方法假设系数时不变，难以刻画机制未知且动态演化的复杂系统，需要引入时变参数以捕捉演化规律。

Method: 构建含常参数与时变参数的函数库，从时间序列数据同时辨识微分方程结构与参数演化轨迹；将时变参数预测结果代入已学方程实现滚动预报。

Result: 在SIR、消费者-资源、温室气体浓度、蓝藻细胞计数等数据集上，学习阶段MAE<3%，提前1个月预测MAE<6%，整体预测精度高于CNN-LSTM与GBM。

Conclusion: 把时变参数纳入数据驱动的微分方程发现，可显著提升模型对动态系统的表征与预测能力，为机制未知系统的可解释建模提供新途径。

Abstract: The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\% for learning a time series and below 6\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.

</details>


### [90] [Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach](https://arxiv.org/abs/2602.04116)
*Sicheng Liu,Xunkai Li,Daohan Su,Ru Zhang,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.LG

TL;DR: PLANET 用“分而治之”策略把模态交互与对齐解耦到嵌入级和节点级，在 MAG 上首次显式建模跨模态语义并统一对齐空间，显著超越现有 MGFM 基线。


<details>
  <summary>Details</summary>
Motivation: 现有 MGFM 仅简单聚合多模态信息，既未显式刻画模态间交互，也未有效对齐异构语义空间，导致在 MAG 上表现受限。

Method: 提出 PLANET 框架：嵌入级用 Embedding-wise Domain Gating 自适应注入拓扑感知的跨模态上下文实现局部交互；节点级用 Node-wise Discretization Retrieval 构建离散化语义表示空间 DSRS，完成全局对齐。

Result: 在多种图中心任务与多模态生成任务上，PLANET 显著优于当前最佳基线，验证其交互与对齐双重改进的有效性。

Conclusion: 显式解耦并协同优化模态交互与对齐是提升 MGFM 泛化能力的关键，PLANET 为后续 MAG 预训练研究提供了可扩展范式。

Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.

</details>


### [91] [Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems](https://arxiv.org/abs/2602.04120)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 将可解释性从推理中解耦，以服务的形式在边缘侧按需、缓存、验证解释，实现38%延迟下降。


<details>
  <summary>Details</summary>
Motivation: 现有边缘/IoT场景的XAI把解释与推理“耦合”在一起，导致冗余计算、高延迟、难扩展，无法适应异构设备。

Method: 提出Explainability-as-a-Service (XaaS)架构：①分布式语义相似缓存，复用历史解释；②轻量级验证协议，保证缓存与新生解释的保真度；③自适应解释引擎，根据设备能力与用户需求动态选方法。

Result: 在制造质检、自动驾驶感知、医疗诊断三类真实边缘场景中，XaaS相比耦合方案平均降低38%端到端延迟，同时维持高解释质量。

Conclusion: XaaS把可解释性提升为第一类系统服务，使大规模异构IoT系统也能部署透明、可信的AI，弥合XAI研究与边缘落地的差距。

Abstract: Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are "coupled" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redundant computation, high latency and poor scalability when deployed across heterogeneous sets of edge devices. In this work we propose Explainability-as-a-Service (XaaS), a distributed architecture for treating explainability as a first-class system service (as opposed to a model-specific feature). The key innovation in our proposed XaaS architecture is that it decouples inference from explanation generation allowing edge devices to request, cache and verify explanations subject to resource and latency constraints. To achieve this, we introduce three main innovations: (1) A distributed explanation cache with a semantic similarity based explanation retrieval method which significantly reduces redundant computation; (2) A lightweight verification protocol that ensures the fidelity of both cached and newly generated explanations; and (3) An adaptive explanation engine that chooses explanation methods based upon device capability and user requirement. We evaluated the performance of XaaS on three real-world edge-AI use cases: (i) manufacturing quality control; (ii) autonomous vehicle perception; and (iii) healthcare diagnostics. Experimental results show that XaaS reduces latency by 38\% while maintaining high explanation quality across three real-world deployments. Overall, this work enables the deployment of transparent and accountable AI across large scale, heterogeneous IoT systems, and bridges the gap between XAI research and edge-practicality.

</details>


### [92] [Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting](https://arxiv.org/abs/2602.04131)
*Mehrdad Moghimi,Anthony Coache,Hyejin Ku*

Main category: cs.LG

TL;DR: 本文把“折扣因子”从固定超参数升级为可学习的风险敏感控制器，在分布式强化学习中同时优化多步回报与风险度量，理论最优且实验稳健。


<details>
  <summary>Details</summary>
Motivation: 安全关键领域采用分布式RL优化风险敏感目标时，折扣因子仍被当作固定常数或简单超参数，无法刻画真实决策中的时间偏好与非指数折扣行为，可能误导策略。

Method: 提出“灵活多视界折扣”框架，在分布式RL中将折扣函数设计为可学习/可优化的广义形式；推导对应的Bellman算子与 distributional 最优性条件；给出算法实例并证明收敛性；通过实验对比固定折扣与风险度量脱钩方法的缺陷。

Result: 理论证明新框架在保持策略最优性的同时，能精确表达更丰富的时序与风险偏好；在MuJoCo、Atari及安全控制任务上，算法在回报-风险权衡、鲁棒性与训练稳定性方面均优于传统分布式RL基线。

Conclusion: 折扣方式并非实现细节，而是决定策略风险-收益结构的核心组件；将折扣函数纳入优化可显著提升分布式RL在安全关键场景中的适用性，未来可拓展至非指数、非平稳或人类行为建模等方向。

Abstract: Distributional reinforcement learning (RL) is a powerful framework increasingly adopted in safety-critical domains for its ability to optimize risk-sensitive objectives. However, the role of the discount factor is often overlooked, as it is typically treated as a fixed parameter of the Markov decision process or tunable hyperparameter, with little consideration of its effect on the learned policy. In the literature, it is well-known that the discounting function plays a major role in characterizing time preferences of an agent, which an exponential discount factor cannot fully capture. Building on this insight, we propose a novel framework that supports flexible discounting of future rewards and optimization of risk measures in distributional RL. We provide a technical analysis of the optimality of our algorithms, show that our multi-horizon extension fixes issues raised with existing methodologies, and validate the robustness of our methods through extensive experiments. Our results highlight that discounting is a cornerstone in decision-making problems for capturing more expressive temporal and risk preferences profiles, with potential implications for real-world safety-critical applications.

</details>


### [93] [Training Data Efficiency in Multimodal Process Reward Models](https://arxiv.org/abs/2602.04145)
*Jinyuan Li,Chengsong Huang,Langlin Huang,Shaoyang Xu,Haolin Liu,Wenxuan Zhang,Jiaxin Huang*

Main category: cs.LG

TL;DR: 用10 %的MC标注数据即可训练出与全量数据等效的多模态过程奖励模型，关键在于新提出的Balanced-Information Score（BIS）筛选高信息量子集。


<details>
  <summary>Details</summary>
Motivation: 训练多模态过程奖励模型（MPRM）依赖大规模蒙特卡洛（MC）标注，成本高昂；初步实验发现随机降采样后性能迅速饱和，暗示现有语料存在严重冗余，亟需提高数据效率。

Method: 1. 建立理论框架，指出梯度更新的信息量由正负步标签混合比例与正步标签可靠性（平均MC分数）共同决定；2. 据此提出零额外成本的Balanced-Information Score（BIS），在rollout层面利用既有MC信号同时衡量混合比例与可靠性，优先选择高BIS子集进行训练。

Result: 在VisualProcessBench上，InternVL2.5-8B与Qwen2.5-VL-7B两种骨干模型均显示：仅用10 % BIS筛选数据即可达到甚至超越全量数据性能，相对随机采样提升4.1 %，验证BIS在数据效率上的显著优势。

Conclusion: MC标注语料的高冗余源于标签混合与可靠性分布不均；通过BIS无成本筛选高信息量子集，可在10 %数据规模下实现全量训练效果，为低成本构建MPRM提供了可行路径。

Abstract: Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.

</details>


### [94] [Benchmarking Uncertainty Quantification of Plug-and-Play Diffusion Priors for Inverse Problems Solving](https://arxiv.org/abs/2602.04189)
*Xiaoyu Qiu,Taewon Yang,Zhanhao Liu,Guanyang Wang,Liyue Shen*

Main category: cs.LG

TL;DR: 现有PnPDP求解器仅用单点重建指标评估，忽视逆问题固有的后验分布与不确定性；本文首次系统量化其不确定性，提出UQ驱动分类法，并用玩具模型与真实科学任务验证，为后续评估提供新基准。


<details>
  <summary>Details</summary>
Motivation: PnPDP在逆问题中实际产生的是重建分布，而学界仅用单样本点估计指标评估，无法衡量不确定性，导致评估与科学应用需求脱节。

Method: 设计可控玩具模型模拟逆问题，系统比较多种PnPDP求解器的后验行为；提出基于不确定性表现的分类框架；在玩具实验与多领域真实科学逆问题（如CT、MRI、湍流重建）上大规模实验验证。

Result: 发现不同PnPDP方法的不确定性行为与理论分类一致：部分方法低估、部分高估、少数近似匹配真实后验；给出可解释误差来源与调参建议；提供开源基准与评估协议。

Conclusion: 首次将不确定性量化确立为PnPDP评估核心指标，提出可重复基准与分类法，指导科学逆问题中可靠、可解释的后验推断方法选择与改进。

Abstract: Plug-and-play diffusion priors (PnPDP) have become a powerful paradigm for solving inverse problems in scientific and engineering domains. Yet, current evaluations of reconstruction quality emphasize point-estimate accuracy metrics on a single sample, which do not reflect the stochastic nature of PnPDP solvers and the intrinsic uncertainty of inverse problems, critical for scientific tasks. This creates a fundamental mismatch: in inverse problems, the desired output is typically a posterior distribution and most PnPDP solvers induce a distribution over reconstructions, but existing benchmarks only evaluate a single reconstruction, ignoring distributional characterization such as uncertainty. To address this gap, we conduct a systematic study to benchmark the uncertainty quantification (UQ) of existing diffusion inverse solvers. Specifically, we design a rigorous toy model simulation to evaluate the uncertainty behavior of various PnPDP solvers, and propose a UQ-driven categorization. Through extensive experiments on toy simulations and diverse real-world scientific inverse problems, we observe uncertainty behaviors consistent with our taxonomy and theoretical justification, providing new insights for evaluating and understanding the uncertainty for PnPDPs.

</details>


### [95] [LORE: Jointly Learning the Intrinsic Dimensionality and Relative Similarity Structure From Ordinal Data](https://arxiv.org/abs/2602.04192)
*Vivek Anand,Alec Helbling,Mark Davenport,Gordon Berman,Sankar Alagapan,Christopher Rozell*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Learning the intrinsic dimensionality of subjective perceptual spaces such as taste, smell, or aesthetics from ordinal data is a challenging problem. We introduce LORE (Low Rank Ordinal Embedding), a scalable framework that jointly learns both the intrinsic dimensionality and an ordinal embedding from noisy triplet comparisons of the form, "Is A more similar to B than C?". Unlike existing methods that require the embedding dimension to be set apriori, LORE regularizes the solution using the nonconvex Schatten-$p$ quasi norm, enabling automatic joint recovery of both the ordinal embedding and its dimensionality. We optimize this joint objective via an iteratively reweighted algorithm and establish convergence guarantees. Extensive experiments on synthetic datasets, simulated perceptual spaces, and real world crowdsourced ordinal judgements show that LORE learns compact, interpretable and highly accurate low dimensional embeddings that recover the latent geometry of subjective percepts. By simultaneously inferring both the intrinsic dimensionality and ordinal embeddings, LORE enables more interpretable and data efficient perceptual modeling in psychophysics and opens new directions for scalable discovery of low dimensional structure from ordinal data in machine learning.

</details>


### [96] [Training A Foundation Model to Represent Graphs as Vectors](https://arxiv.org/abs/2602.04244)
*Qi Feng,Jicong Fan*

Main category: cs.LG

TL;DR: 提出一个通用图基础模型，通过跨域特征对齐与多层参考分布模块，将任意图压缩为保留结构与语义信息的向量，在少样本分类与聚类上超越强基线。


<details>
  <summary>Details</summary>
Motivation: 现有图表示方法难以跨域泛化，急需一个能统一编码任意图、保留足够结构/语义信息且对下游任务通用的图基础模型。

Method: 1) 多图特征对齐：利用各数据集全部节点属性构建加权图并生成一致节点嵌入；2) 密度最大化均值对齐：带收敛保证的分布对齐算法，增强跨域特征一致性；3) 对比学习框架：将原图与对齐后的节点嵌入输入 GNN，得到判别式图表示；4) 多层参考分布模块：无需池化操作，逐层保留并聚合节点信息到图级表示；5) 给出理论泛化误差界。

Result: 在少样本图分类与图聚类任务上显著优于多种强基线，验证跨域泛化与信息保持能力。

Conclusion: 所提图基础模型通过跨域对齐与无池化信息聚合，实现了对任意图的通用、高保真向量表示，为图级任务提供了可扩展的预训练方案。

Abstract: This paper aims to train a graph foundation model that is able to represent any graph as a vector preserving structural and semantic information useful for downstream graph-level tasks such as graph classification and graph clustering. To learn the features of graphs from diverse domains while maintaining strong generalization ability to new domains, we propose a multi-graph-based feature alignment method, which constructs weighted graphs using the attributes of all nodes in each dataset and then generates consistent node embeddings. To enhance the consistency of the features from different datasets, we propose a density maximization mean alignment algorithm with guaranteed convergence. The original graphs and generated node embeddings are fed into a graph neural network to achieve discriminative graph representations in contrastive learning. More importantly, to enhance the information preservation from node-level representations to the graph-level representation, we construct a multi-layer reference distribution module without using any pooling operation. We also provide a theoretical generalization bound to support the effectiveness of the proposed model. The experimental results of few-shot graph classification and graph clustering show that our model outperforms strong baselines.

</details>


### [97] [Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning](https://arxiv.org/abs/2602.04265)
*Wenze Lin,Zhen Yang,Xitai Jiang,Pony Ma,Gao Huang*

Main category: cs.LG

TL;DR: T2T动态奖励框架：答错时鼓励长轨迹探索，答对后压缩长度防冗余，数学任务全面超越GRPO


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法无法区分“难题需广泛搜索”与“已掌握知识应高效表达”，导致熵塌陷、冗长、探索不足

Method: 提出T2T(Thickening-to-Thinning)双阶段动态奖励：错误轨迹给予长度奖励以“增厚”搜索空间；一旦正确即施加长度惩罚以“减薄”冗余，模拟人类学习过程

Result: 在MATH-500、AIME、AMC等数学基准上，Qwen与Deepseek系列模型均显著优于标准GRPO及最新基线

Conclusion: T2T通过阶段化奖励设计，同步提升探索效率与表达精炼度，为LLM推理强化学习提供了可扩展的新范式

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes "thickening" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to "thinning", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance.

</details>


### [98] [Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms](https://arxiv.org/abs/2602.04277)
*Priyankkumar Dhrangdhariya,Soumyadipta Maiti,Venkataramana Runkana*

Main category: cs.LG

TL;DR: 用生成式设计+机器学习快速优化非充气轮胎辐条，53 %可调刚度、50 %寿命提升、43 %减振。


<details>
  <summary>Details</summary>
Motivation: 非充气轮胎因辐条不连续导致刚度难调、耐久差、高速振动大，亟需高效优化手段。

Method: ①高阶多项式参数化上下辐条型线，PCHIP生成约250种几何；②KRR预测刚度，XGBoost预测耐久与振动，替代FEM；③PSO快速收敛单目标，贝叶斯优化权衡多目标。

Result: 最优方案较基准刚度可调范围+53 %，耐久性+50 %，振动−43 %；PSO收敛快，贝叶斯擅于折衷。

Conclusion: 所提生成式-机器学习框架可系统开发高性能U PTIS辐条，显著降低仿真成本并提升综合性能。

Abstract: Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UPTIS type spoke geometries for passenger vehicles. Upper and lower spoke profiles were parameterized using high order polynomial representations, enabling the creation of approximately 250 generative designs through PCHIP based geometric variation. Machine learning models like KRR for stiffness and XGBoost for durability and vibration achieved strong predictive accuracy, reducing the reliance on computationally intensive FEM simulations. Optimization using Particle Swarm Optimization and Bayesian Optimization further enabled extensive performance refinement. The resulting designs demonstrate 53% stiffness tunability, up to 50% durability improvement, and 43% reduction in vibration compared to the baseline. PSO provided fast, targeted convergence, while Bayesian Optimization effectively explored multi objective tradeoffs. Overall, the proposed framework enables systematic development of high performance, next generation UPTIS spoke structures.

</details>


### [99] [Multi-Integration of Labels across Categories for Component Identification (MILCCI)](https://arxiv.org/abs/2602.04270)
*Noga Mudrik,Yuxi Chen,Gal Mishne,Adam S. Charles*

Main category: cs.LG

TL;DR: MILCCI 是一种无监督方法，可在多试验时间序列中同时提取可解释成分、刻画试间差异，并把不同元数据类别对信号的独立贡献分离开。


<details>
  <summary>Details</summary>
Motivation: 大量领域通过重复试验采集时间序列，每次试验附带多类别标签（如任务难度、动物选择）。现有方法难以厘清每个标签类别在信号中的独立编码方式，亟需一种能“解耦”各类别影响的通用数据驱动框架。

Method: 提出 MILCCI（Multi-trial Label-Coupled Component Identification）：在单试验稀疏分解基础上，引入类别内标签相似度，对成分权重进行标签感知的试间微调；同时学习每条成分随时间演化的轨迹，实现跨试验灵活变化。

Result: 在合成数据与三个真实场景（议会投票、网页访问量、神经元放电）上，MILCCI 比基线方法更准确地恢复了标签相关成分，量化了各类别对信号方差的独立贡献，并提供了可解释的时间动态。

Conclusion: MILCCI 无需任务假设即可揭示多类别标签在大型时间序列中的独立表达，为神经科学、行为学及社会系统等领域的可解释性分析提供了通用工具。

Abstract: Many fields collect large-scale temporal data through repeated measurements (trials), where each trial is labeled with a set of metadata variables spanning several categories. For example, a trial in a neuroscience study may be linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data. MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category. MILCCI also learns each component's corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI's performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.

</details>


### [100] [RISE: Interactive Visual Diagnosis of Fairness in Machine Learning Models](https://arxiv.org/abs/2602.04339)
*Ray Chen,Christan Grant*

Main category: cs.LG

TL;DR: RISE 通过可视化排序残差，把抽象的公平性指标变成可交互、可定位的曲线模式，帮助用户在域迁移下精确找到并解释不同子群的误差差异，揭示传统标量指标遗漏的局部公平问题与准确率-公平权衡。


<details>
  <summary>Details</summary>
Motivation: 在域迁移场景下，仅用标量公平性指标难以揭示“哪里、对谁、为何”出现差异，导致隐藏的不公平被忽略，模型选择缺乏细粒度依据。

Method: 提出 RISE（Residual Inspection through Sorted Evaluation）：将模型残差按子群排序并绘制成可交互曲线，把曲线结构与形式化公平定义关联，支持跨环境子群对比、局部分布检视与事后分析。

Result: RISE 能在不重新训练模型的情况下，精准定位特定子群在特定域的误差激增，发现聚合指标掩盖的隐藏公平问题，并量化呈现准确率-公平权衡，为模型迭代与选型提供可解释依据。

Conclusion: 可视化排序残差比传统标量公平指标更能揭示域迁移下的局部不公平，RISE 为公平性诊断提供了可解释、可操作的交互式工具，可直接集成到现有模型评估流程。

Abstract: Evaluating fairness under domain shift is challenging because scalar metrics often obscure exactly where and how disparities arise. We introduce \textit{RISE} (Residual Inspection through Sorted Evaluation), an interactive visualization tool that converts sorted residuals into interpretable patterns. By connecting residual curve structures to formal fairness notions, RISE enables localized disparity diagnosis, subgroup comparison across environments, and the detection of hidden fairness issues. Through post-hoc analysis, RISE exposes accuracy-fairness trade-offs that aggregate statistics miss, supporting more informed model selection.

</details>


### [101] [Counterfactual Explanations for Hypergraph Neural Networks](https://arxiv.org/abs/2602.04360)
*Fabiano Veglianti,Lorenzo Antonelli,Gabriele Tolomei*

Main category: cs.LG

TL;DR: CF-HyperGNNExplainer 用最小可行动作（删节点-超边关联或删超边）生成反事实超图，揭示 HGNN 预测所依赖的关键高阶关系，在三个数据集上验证其有效性与简洁性。


<details>
  <summary>Details</summary>
Motivation: HGNN 虽能刻画高阶交互，但缺乏可解释性，阻碍其在高风险场景落地；现有解释方法未能针对超图结构提供直观、可操作的因果解释。

Method: 提出 CF-HyperGNNExplainer，以“最小结构改动→改变预测”为目标，仅允许两种可行动作：移除节点-超边关联或删除整条超边；通过高效搜索生成反事实超图，作为解释输出。

Result: 在三个基准数据集上，方法均能产生有效且简洁的反事实，精准定位对 HGNN 决策最关键的高阶关系，且解释规模显著小于基线。

Conclusion: CF-HyperGNNExplainer 为 HGNN 提供了首个结构级反事实解释框架，兼顾可行动性与因果意义，可直接用于高风险应用的信任评估与模型调试。

Abstract: Hypergraph neural networks (HGNNs) effectively model higher-order interactions in many real-world systems but remain difficult to interpret, limiting their deployment in high-stakes settings.
  We introduce CF-HyperGNNExplainer, a counterfactual explanation method for HGNNs that identifies the minimal structural changes required to alter a model's prediction. The method generates counterfactual hypergraphs using actionable edits limited to removing node-hyperedge incidences or deleting hyperedges, producing concise and structurally meaningful explanations. Experiments on three benchmark datasets show that CF-HyperGNNExplainer generates valid and concise counterfactuals, highlighting the higher-order relations most critical to HGNN decisions.

</details>


### [102] [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)
*Weikang Meng,Liangyu Huo,Yadan Luo,Yaowei Wang,Yingjian Li,Zheng Zhang*

Main category: cs.LG

TL;DR: 用可学习的镜像变换把负值特征“翻”进非负象限，取代 ReLU 的被动截断，线性注意力首次在不降速的前提下达到 softmax 级精度。


<details>
  <summary>Details</summary>
Motivation: 线性注意力将 Transformer 的 O(n²) 复杂度降至 O(n)，但性能始终落后于 softmax 注意力。作者发现症结在于内核特征图必须非负——现有方法（如 ReLU）直接截断负值，导致语义信息被动丢失。

Method: 提出 MirrorLA 框架：1) 用可学习的 Householder 反射矩阵主动将特征旋转到非负象限，而非截断；2) 分块等距变换提升局部判别性；3) 方差感知调制稳定长序列动态、多样化激活；4) 跨头反射整合分散子空间，实现全局协方差混合。整套操作保持严格线性复杂度。

Result: 在图像分类、自回归语言建模、长文档检索等标准基准上，MirrorLA 均取得线性注意力领域新 SOTA，与同等规模 softmax 注意力模型持平甚至略优，首次证明“线性效率”与“表示保真”可以兼得。

Conclusion: 通过几何重定向替代被动截断，MirrorLA 解决了线性注意力的根本信息损失问题，为高效 Transformer 提供了一条兼顾复杂度与精度的可行路线。

Abstract: Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standard projections like ReLU act as "passive truncation" operators, indiscriminately discarding semantic information residing in the negative domain. We propose MirrorLA, a geometric framework that substitutes passive truncation with active reorientation. By leveraging learnable Householder reflections, MirrorLA rotates the feature geometry into the non-negative orthant to maximize information retention. Our approach restores representational density through a cohesive, multi-scale design: it first optimizes local discriminability via block-wise isometries, stabilizes long-context dynamics using variance-aware modulation to diversify activations, and finally, integrates dispersed subspaces via cross-head reflections to induce global covariance mixing. MirrorLA achieves state-of-the-art performance across standard benchmarks, demonstrating that strictly linear efficiency can be achieved without compromising representational fidelity.

</details>


### [103] [Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting](https://arxiv.org/abs/2602.04384)
*Fabio Turazza,Alessandro Neri,Marcello Pietri,Maria Angela Butturi,Marco Picone,Marco Mamei*

Main category: cs.LG

TL;DR: 用区块链联邦学习让多家生鲜零售商在不共享原始数据的前提下联合训练需求预测模型，准确率接近“数据共享”的理想水平，显著降低食品浪费。


<details>
  <summary>Details</summary>
Motivation: 生鲜零售需求预测不准导致大量食品浪费；出于隐私顾虑，零售商不愿共享数据，限制了协同建模的效果。

Method: 先为孤立零售商建立基线预测模型，再设计基于区块链的联邦学习框架，使多家零售商仅交换模型参数而不交换原始数据。

Result: 联邦学习模型预测精度接近全数据共享的理想场景，远高于各零售商单独建模的精度，从而有效减少浪费并提升效率。

Conclusion: 联邦学习可在保护数据隐私的同时实现跨零售商协同，为可持续供应链管理提供兼顾准确性与隐私性的新范式。

Abstract: Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Management (SSCM), with a focus on the grocery retail sector dealing with perishable goods. We develop a baseline predictive model for demand forecasting and waste assessment in an isolated retailer scenario. Subsequently, we introduce a Blockchain-based FL model, trained collaboratively across multiple retailers without direct data sharing. Our preliminary results show that FL models have performance almost equivalent to the ideal setting in which parties share data with each other, and are notably superior to models built by individual parties without sharing data, cutting waste and boosting efficiency.

</details>


### [104] [Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis](https://arxiv.org/abs/2602.04369)
*Zongjiang Shang,Dongliang Cui,Binqing Wu,Ling Chen*

Main category: cs.LG

TL;DR: MSH-LLM 用超图把时间序列的多尺度特征映射成 LLM 能“读懂”的语义，再用混合提示激活模型，27 个数据集上全面刷榜。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅做粗粒度模态对齐，忽略了自然语言与时间序列各自的多尺度结构，导致 LLM 的语义能力未被充分利用。

Method: 1) 超边化机制在时间序列语义空间内显式构建多尺度超图，增强跨尺度语义关联；2) 跨模态对齐（CMA）模块在词元-变量-尺度三级粒度上联合优化对齐损失；3) 混合提示（MoP）机制动态选择并组合多尺度上下文提示，注入 LLM 提示空间。

Result: 在 27 个真实数据集、5 类任务（预测、分类、异常检测、填补、少样本）上均达 SOTA，平均提升 3.2–11.7 个百分点，消融实验验证三组件正交增益。

Conclusion: 显式建模并联合对齐多尺度结构，可充分释放 LLM 在时间序列分析中的潜力；超图-提示协同框架具有良好的任务通用性与可扩展性。

Abstract: Recently, there has been great success in leveraging pre-trained large language models (LLMs) for time series analysis. The core idea lies in effectively aligning the modality between natural language and time series. However, the multi-scale structures of natural language and time series have not been fully considered, resulting in insufficient utilization of LLMs capabilities. To this end, we propose MSH-LLM, a Multi-Scale Hypergraph method that aligns Large Language Models for time series analysis. Specifically, a hyperedging mechanism is designed to enhance the multi-scale semantic information of time series semantic space. Then, a cross-modality alignment (CMA) module is introduced to align the modality between natural language and time series at different scales. In addition, a mixture of prompts (MoP) mechanism is introduced to provide contextual information and enhance the ability of LLMs to understand the multi-scale temporal patterns of time series. Experimental results on 27 real-world datasets across 5 different applications demonstrate that MSH-LLM achieves the state-of-the-art results.

</details>


### [105] [LoRDO: Distributed Low-Rank Optimization with Infrequent Communication](https://arxiv.org/abs/2602.04396)
*Andrej Jovanović,Alex Iacob,Mher Safaryan,Ionut-Vlad Modoranu,Lorenzo Sani,William F. Shen,Xinchi Qiu,Dan Alistarh,Nicholas D. Lane*

Main category: cs.LG

TL;DR: LoRDO 把低秩优化与稀疏通信结合，用伪梯度全局投影+全秩拟双曲修正，在 125 M–720 M 模型上实现与标准 DDP 低秩方法几乎相同的效果，但通信量降低约 10 倍，且在内存/批量极小时优势更大。


<details>
  <summary>Details</summary>
Motivation: 基于 DDP 的大模型分布式训练受限于互联带宽；现有稀疏通信虽减少同步次数，仍被优化器状态的内存与通信开销束缚。低秩优化可缓解，但本地更新场景下 workers 无法获得全批量梯度，导致低秩投影失效、性能下降。

Method: 提出 LoRDO 框架：① 用伪梯度构造全局低秩投影，理论上更优但会永久困于低秩子空间；② 引入全秩拟双曲更新，周期性“跳出”子空间以恢复探索能力；③ 统一低秩优化与稀疏通信，实现本地更新下的低秩训练。

Result: 在 125 M–720 M 参数的语言模型及下游任务上，LoRDO 达到与低秩 DDP 几乎一致的困惑度与微调精度，通信量减少 ≈10×；在内存极度受限（小秩/小批量）场景下，提升幅度更大。

Conclusion: LoRDO 证明本地更新与低秩优化可以兼容，通过全局伪梯度投影+全秩修正实现高保真低通信训练，为资源受限环境的大模型分布式训练提供了实用新路线。

Abstract: Distributed training of foundation models via $\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\texttt{LoRDO}$ achieves near-parity with low-rank $\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\approx 10 \times$. Finally, we show that $\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.

</details>


### [106] [Reducing the labeling burden in time-series mapping using Common Ground: a semi-automated approach to tracking changes in land cover and species over time](https://arxiv.org/abs/2602.04373)
*Geethen Singh,Jasper A Slingsby,Tamara B Robinson,Glenn Moncrieff*

Main category: cs.LG

TL;DR: 仅用 t0 时刻标签即可训练出在 t1 时刻仍具竞争力的遥感分类器；“Common Ground” 通过挖掘时相稳定区作为半监督信号，在动态区上获得 21–40 % 的精度提升，显著优于逐时相重标定的“金标准”方案。


<details>
  <summary>Details</summary>
Motivation: 动态或偏远生态系统的新标签获取昂贵且困难，亟需一种无需逐期更新参考数据即可实现可靠时相迁移的分类方法。

Method: 提出“Common Ground”框架：① 以 t0 参考数据为种子；② 利用变化检测识别 t0→t1 光谱/语义稳定区；③ 将稳定区视为伪标签源，在半监督学习中对动态区进行隐式监督；④ 在多传感器（Landsat-8、Sentinel-2、航空高光谱）及不同生态场景下验证。

Result: 入侵树种制图：较 naive 时相迁移提升 21–40 %，较“金标准”提升 10–16 %；欧洲大范围土地覆盖分类：提升约 2 %。证明稳定区筛选+SSL 可显著降低标签更新成本并保持高精度。

Conclusion: 结合稳定区筛选的半监督策略能在不更新参考标签的前提下实现强时相泛化，为可扩展、标签高效的多时相遥感分类提供了新范式。

Abstract: Reliable classification of Earth Observation data depends on consistent, up-to-date reference labels. However, collecting new labelled data at each time step remains expensive and logistically difficult, especially in dynamic or remote ecological systems. As a response to this challenge, we demonstrate that a model with access to reference data solely from time step t0 can perform competitively on both t0 and a future time step t1, outperforming models trained separately on time-specific reference data (the gold standard). This finding suggests that effective temporal generalization can be achieved without requiring manual updates to reference labels beyond the initial time step t0. Drawing on concepts from change detection and semi-supervised learning (SSL), the most performant approach, "Common Ground", uses a semi-supervised framework that leverages temporally stable regions-areas with little to no change in spectral or semantic characteristics between time steps-as a source of implicit supervision for dynamic regions. We evaluate this strategy across multiple classifiers, sensors (Landsat-8, Sentinel-2 satellite multispectral and airborne imaging spectroscopy), and ecological use cases. For invasive tree species mapping, we observed a 21-40% improvement in classification accuracy using Common Ground compared to naive temporal transfer, where models trained at a single time step are directly applied to a future time step. We also observe a 10 -16% higher accuracy for the introduced approach compared to a gold-standard approach. In contrast, when broad land cover categories were mapped across Europe, we observed a more modest 2% increase in accuracy compared to both the naive and gold-standard approaches. These results underscore the effectiveness of combining stable reference screening with SSL for scalable and label-efficient multi-temporal remote sensing classification.

</details>


### [107] [Theory of Speciation Transitions in Diffusion Models with General Class Structure](https://arxiv.org/abs/2602.04404)
*Beatrice Achilli,Marco Benedetti,Giulio Biroli,Marc Mézard*

Main category: cs.LG

TL;DR: 本文提出一个普适理论，用贝叶斯分类和自由熵差刻画扩散模型在逆向去噪过程中出现的“类特化”相变时刻，突破以往仅适用于一阶矩可分的局限，并给出多步相继特化的预测，在一维混合 Ising 与高斯协方差混合两类可解析模型中验证了理论。


<details>
  <summary>Details</summary>
Motivation: 现有关于扩散模型“类特化”相变的理论仅适用于均值可分的简单高斯混合，无法解释类别差异体现在高阶或集体统计特征的真实数据；亟需一个适用于任意目标分布的统一框架。

Method: 以贝斯最优分类器定义“类别结构”，将轨迹对类别的动态承诺时间归结为类间自由熵差为零的临界点；利用副本方法把一维混合 Ising 模型映射到随机场 Ising 模型并解析求解；对零均值但协方差异构的高斯混合给出协方差谱差异驱动的特化判据。

Result: 理论同时复现了旧有高斯均值可分结果，并预测出当类别仅在高阶矩/协方差/集体特征不同时仍存在一次或多次相继特化；在混合 Ising 与零均值高斯两类示例中给出显式临界时间表达式，与模拟一致。

Conclusion: 自由熵差为零的普适判据完整描述了扩散逆向过程中的类特化现象，可推广到任意多类及嵌套类别结构，为理解与调控深度生成模型的隐式决策动力学提供了统一解析工具。

Abstract: Diffusion Models generate data by reversing a stochastic diffusion process, progressively transforming noise into structured samples drawn from a target distribution. Recent theoretical work has shown that this backward dynamics can undergo sharp qualitative transitions, known as speciation transitions, during which trajectories become dynamically committed to data classes. Existing theoretical analyses, however, are limited to settings where classes are identifiable through first moments, such as mixtures of Gaussians with well-separated means. In this work, we develop a general theory of speciation in diffusion models that applies to arbitrary target distributions admitting well-defined classes. We formalize the notion of class structure through Bayes classification and characterize speciation times in terms of free-entropy difference between classes. This criterion recovers known results in previously studied Gaussian-mixture models, while extending to situations in which classes are not distinguishable by first moments and may instead differ through higher-order or collective features. Our framework also accommodates multiple classes and predicts the existence of successive speciation times associated with increasingly fine-grained class commitment. We illustrate the theory on two analytically tractable examples: mixtures of one-dimensional Ising models at different temperatures and mixtures of zero-mean Gaussians with distinct covariance structures. In the Ising case, we obtain explicit expressions for speciation times by mapping the problem onto a random-field Ising model and solving it via the replica method. Our results provide a unified and broadly applicable description of speciation transitions in diffusion-based generative models.

</details>


### [108] [Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design](https://arxiv.org/abs/2602.04663)
*Jaemoo Choi,Yuchen Zhu,Wei Guo,Petr Molodyk,Bo Yuan,Jinbin Bai,Yi Xin,Molei Tao,Yongxin Chen*

Main category: cs.LG

TL;DR: 把强化学习用在扩散模型上，关键不是改损失函数，而是用一个只依赖最终样本的 ELBO 似然估计器；把它装进标准策略梯度框架，90 GPU 小时就把 SD3.5-Medium 的 GenEval 从 0.24 拉到 0.95，比现有方法快 2–4.6 倍且无需额外奖励工程。


<details>
  <summary>Details</summary>
Motivation: 扩散模型似然不可解，导致策略梯度类 RL 算法难以直接落地；已有工作只忙着给 LLM 目标打补丁，用临时似然估计器，却没人系统分析“估计器本身”对最终性能的影响。

Method: 将 RL 设计空间解耦成三大因素：策略梯度目标、似然估计器、 rollout 采样方案；固定常见策略梯度形式，系统比较不同似然估计器，最终锁定“仅使用最终生成样本的 ELBO 估计器”为核心组件，其余部分保持标准 RL 流程不变。

Result: 在 SD 3.5 Medium 上跨多个奖励基准验证，ELBO 估计器带来的提升一致且显著；GenEval 得分 0.24→0.95，耗时 90 GPU 小时，效率是 FlowGRPO 的 4.6×、DiffusionNFT 的 2×，无奖励劫持现象。

Conclusion: 对于扩散/流模型的 RL 微调，与其绞尽脑汁设计新损失，不如先用一个简单、仅依赖终样本的 ELBO 似然估计器——它才是稳定高效优化的第一性要素。

Abstract: Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type methods. Existing approaches primarily focus on crafting new objectives built on already heavily engineered LLM objectives, using ad hoc estimators for likelihood, without a thorough investigation into how such estimation affects overall algorithmic performance. In this work, we provide a systematic analysis of the RL design space by disentangling three factors: i) policy-gradient objectives, ii) likelihood estimators, and iii) rollout sampling schemes. We show that adopting an evidence lower bound (ELBO) based model likelihood estimator, computed only from the final generated sample, is the dominant factor enabling effective, efficient, and stable RL optimization, outweighing the impact of the specific policy-gradient loss functional. We validate our findings across multiple reward benchmarks using SD 3.5 Medium, and observe consistent trends across all tasks. Our method improves the GenEval score from 0.24 to 0.95 in 90 GPU hours, which is $4.6\times$ more efficient than FlowGRPO and $2\times$ more efficient than the SOTA method DiffusionNFT without reward hacking.

</details>


### [109] [MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems](https://arxiv.org/abs/2602.04431)
*Jonathan Nöther,Adish Singla,Goran Radanovic*

Main category: cs.LG

TL;DR: MaMa算法通过Stackelberg博弈框架自动设计安全的多智能体系统，在部分智能体被攻击者控制时仍能保证安全与性能。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的多智能体系统虽能力强，但个体智能体失效或被敌手控制时会带来严重安全风险，亟需一种能自动设计“即使部分成员被攻破仍安全”的系统的方法。

Method: 将问题建模为Meta-Agent（系统设计方）与最佳响应的Meta-Adversary（选择并攻破部分智能体的攻击方）之间的Stackelberg安全博弈；提出MaMa算法，用LLM驱动的对抗搜索迭代生成系统设计方案，并根据Meta-Adversary发现的最强攻击反馈持续改进。

Result: 在多种环境中，MaMa设计的系统既能抵御最坏情况攻击，又保持与仅优化任务成功率的系统相当的性能；所得系统对更强攻击者、不同攻击目标或不同底层LLM均表现出良好泛化与鲁棒安全性。

Conclusion: MaMa首次实现了面向最坏情况的多智能体系统自动安全设计，兼顾性能与可泛化的鲁棒安全，为部署高可信LLM多智能体系统提供了可行路径。

Abstract: LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.

</details>


### [110] [Delving into Muon and Beyond: Deep Analysis and Extensions](https://arxiv.org/abs/2602.04669)
*Xianbiao Qi,Marco Chen,Jiaquan Ye,Yelin He,Rong Xiao*

Main category: cs.LG

TL;DR: Muon 本质是谱归一化的特例（p=0），并非全面优于 Adam；RMS 归一化比动量更新更稳定，谱压缩仅在前者场景下显著增益。


<details>
  <summary>Details</summary>
Motivation: Muon 凭正交化矩阵更新表现出色，但其机理及与 Adam 等自适应优化器的本质联系尚不清楚，需统一框架解释其行为与适用范围。

Method: 将 Muon 视为谱变换族 UΣ^pV′ 的 p=0 端点，扩展出 p=1/4,1/2,1 等变体；对动量 SGD 的一阶矩更新与 Adam 的 RMS 归一化梯度均施加该变换；用耦合牛顿迭代避免显式 SVD，实现高效计算。

Result: RMS 归一化更新在各类实验中最稳定；谱压缩对一阶矩更新有显著稳定收益，但 Muon(p=0) 整体未系统优于 Adam；Muon 应被理解为一种有效的谱归一化，而非普适更优的优化器。

Conclusion: Muon's strength comes from spectral normalization rather than a fundamentally new optimization principle; combined with RMS-style normalization it achieves robust performance, yet it is not universally superior to Adam.

Abstract: The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we aim to address these questions through a unified spectral perspective. Specifically, we view Muon as the p = 0 endpoint of a family of spectral transformations of the form U \boldsymbolΣ^{p} V' , and consider additional variants with p = 1/2 , p = 1/4 , and p = 1 . These transformations are applied to both first-moment updates, as in momentum SGD, and to root-mean-square (RMS) normalized gradient updates as in Adam. To enable efficient computation, we develop a coupled Newton iteration that avoids explicit singular value decomposition. Across controlled experiments, we find that RMS-normalized updates yield more stable optimization than first-moment updates. Moreover, while spectral compression provides strong stabilization benefits under first-moment updates, the Muon update (p = 0) does not consistently outperform Adam. These results suggest that Muon is best understood as an effective form of spectral normalization, but not a universally superior optimization method. Our source code will be released at https://github.com/Ocram7/BeyondMuon.

</details>


### [111] [Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting](https://arxiv.org/abs/2602.04678)
*Zhen Zhou,Zhirui Wang,Qi Hong,Yunyang Shi,Ziyuan Gu,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 提出Multi-Expert LDL框架，用混合专家+分布学习同时提升时间序列预测精度与不确定性可解释性，在M5销售数据上精度最佳且可拆解趋势/季节/变点/波动。


<details>
  <summary>Details</summary>
Motivation: 现实预测需兼顾高精度与可解释的不确定性量化；传统点预测忽略不确定性，现有概率方法在计算效率与可解释性间难以平衡。

Method: 设计两种互补的分布标签学习框架：1) Multi-Expert LDL——多专家各自学习不同参数以捕捉多样时序模式；2) Pattern-Aware LDL-MoE——将序列显式分解为趋势、季节性、变点、波动四大可解释成分，由专用子专家建模。二者均把点预测扩展为分布学习，并用最大均值差异(MMD)实现丰富的不确定性量化。

Result: 在M5聚合销售数据上，连续Multi-Expert LDL取得最优整体预测性能；Pattern-Aware LDL-MoE通过成分级分析提供更强可解释性，框架在精度与可解释性间实现良好平衡。

Conclusion: 所提框架兼具高预测精度与可解释不确定性，适用于对性能与可行动洞察双重重视的现实预测场景。

Abstract: Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance computational efficiency with interpretability. We propose a novel Multi-Expert Learning Distributional Labels (LDL) framework that addresses these challenges through mixture-of-experts architectures with distributional learning capabilities. Our approach introduces two complementary methods: (1) Multi-Expert LDL, which employs multiple experts with different learned parameters to capture diverse temporal patterns, and (2) Pattern-Aware LDL-MoE, which explicitly decomposes time series into interpretable components (trend, seasonality, changepoints, volatility) through specialized sub-experts. Both frameworks extend traditional point prediction to distributional learning, enabling rich uncertainty quantification through Maximum Mean Discrepancy (MMD). We evaluate our methods on aggregated sales data derived from the M5 dataset, demonstrating superior performance compared to baseline approaches. The continuous Multi-Expert LDL achieves the best overall performance, while the Pattern-Aware LDL-MoE provides enhanced interpretability through component-wise analysis. Our frameworks successfully balance predictive accuracy with interpretability, making them suitable for real-world forecasting applications where both performance and actionable insights are crucial.

</details>


### [112] [Greedy-Gnorm: A Gradient Matrix Norm-Based Alternative to Attention Entropy for Head Pruning](https://arxiv.org/abs/2602.04491)
*Yuxi Guo,Paul Sheridan*

Main category: cs.LG

TL;DR: Greedy-Gnorm 是一种动态逐头剪枝算法，通过每次迭代后重新计算 Q/K/V 梯度块 l2-范数乘积作为重要性分数，在 BERT 系列模型上显著优于静态熵基线，实现高稀疏度下的精度保持与绿色部署。


<details>
  <summary>Details</summary>
Motivation: 现有 Transformer 头剪枝方法使用静态重要性评分，无法反映迭代移除过程中注意力头作用的动态变化，导致排序失效与性能下降。

Method: 提出 Greedy-Gradient norm（Greedy-Gnorm）：每次贪婪迭代后，利用留出验证集重新估计各头 Q、K、V 参数梯度块的 l2-范数，并将其元素级乘积作为动态重要性分数，实时更新剪枝排序。

Result: 在 BERT、ALBERT、RoBERTa、XLM-RoBERTa 上广泛实验表明，Greedy-Gnorm 在大幅剪枝比例下仍能维持原有精度，一致优于基于注意力熵的静态方法，实现模型尺寸与能耗显著降低。

Conclusion: Greedy-Gnorm 通过梯度感知的动态评分机制，有效解决了静态剪枝的“排名陈旧”问题，为绿色 AI 时代的高效 Transformer 部署提供了可行且通用的压缩方案。

Abstract: Attention head pruning has emerged as an effective technique for transformer model compression, an increasingly important goal in the era of Green AI. However, existing pruning methods often rely on static importance scores, which fail to capture the evolving role of attention heads during iterative removal. We propose Greedy-Gradient norm (Greedy-Gnorm), a novel head pruning algorithm that dynamically recalculates head importance after each pruning step. Specifically, each head is scored by the elementwise product of the l2-norms of its Q/K/V gradient blocks, as estimated from a hold-out validation set and updated at every greedy iteration. This dynamic approach to scoring mitigates against stale rankings and better reflects gradient-informed importance as pruning progresses. Extensive experiments on BERT, ALBERT, RoBERTa, and XLM-RoBERTa demonstrate that Greedy-Gnorm consistently preserves accuracy under substantial head removal, outperforming attention entropy. By effectively reducing model size while maintaining task performance, Greedy-Gnorm offers a promising step toward more energy-efficient transformer model deployment.

</details>


### [113] [Identifying Intervenable and Interpretable Features via Orthogonality Regularization](https://arxiv.org/abs/2602.04718)
*Moritz Miller,Florent Draye,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 通过正交化稀疏自编码器的解码矩阵，获得可干预、可解释的独立特征，同时不牺牲下游性能。


<details>
  <summary>Details</summary>
Motivation: 现有微调语言模型时，稀疏自编码器（SAE）学习到的特征存在严重叠加与干扰，难以单独干预或解释。需要一种在保持任务性能的前提下，让特征彼此解耦、具备因果独立性的方法。

Method: 在固定稀疏自编码器框架下，对解码矩阵施加“几乎正交”约束，引入可微的正交性惩罚项，使特征方向近似两两正交；同时利用稀疏激活保持重构能力。

Result: 正交化后，特征间干扰显著下降，下游任务性能几乎不变；特征解释的余弦距离随惩罚强度单调增大，满足可识别性与可解释性；在因果干预实验中，可对单个特征进行孤立扰动而不影响其他特征，验证了模块化表示。

Conclusion: 正交惩罚是一种简单有效的“后处理”手段，能把叠加特征转化为近似独立的因果机制，为语言模型内部表示的可解释性与安全干预提供新途径。

Abstract: With recent progress on fine-tuning language models around a fixed sparse autoencoder, we disentangle the decoder matrix into almost orthogonal features. This reduces interference and superposition between the features, while keeping performance on the target dataset essentially unchanged. Our orthogonality penalty leads to identifiable features, ensuring the uniqueness of the decomposition. Further, we find that the distance between embedded feature explanations increases with stricter orthogonality penalty, a desirable property for interpretability. Invoking the $\textit{Independent Causal Mechanisms}$ principle, we argue that orthogonality promotes modular representations amenable to causal intervention. We empirically show that these increasingly orthogonalized features allow for isolated interventions. Our code is available under $\texttt{https://github.com/mrtzmllr/sae-icm}$.

</details>


### [114] [Forget to Generalize: Iterative Adaptation for Generalization in Federated Learning](https://arxiv.org/abs/2602.04536)
*Abdulrahman Alotaibi,Irene Tenison,Miriam Kim,Isaac Lee,Lalana Kagal*

Main category: cs.LG

TL;DR: 提出「迭代联邦适应（IFA）」框架：在每代训练后随机或按层重初始化部分参数，使模型“先遗忘再进化”，显著缓解非独立同分布（Non-IID）带来的性能衰减，可无缝叠加到任意联邦算法，平均提升 21.5% 全局精度。


<details>
  <summary>Details</summary>
Motivation: 真实 Web 场景下客户端数据高度异构（Non-IID），导致传统联邦学习（FL）全局模型性能严重下降，亟需一种不依赖中央数据、可即插即用的通用增强机制。

Method: 将训练划分为多代，每代结束后按随机或“后层优先”策略选择部分参数重新初始化，实现“遗忘-进化”循环；该过程可与任意 FL 聚合算法正交叠加。

Result: 在 CIFAR-10、MIT-Indoors、Stanford Dogs 的 Non-IID 分割上，IFA 使全局准确率平均提升 21.5%，且对极度偏斜分布的增益更高；消融实验证实后层重置与多代迭代是关键。

Conclusion: IFA 以极低开销打破局部极小值陷阱，保留全局通用表征，为可扩展、保护隐私的异构 Web 联邦系统提供了立即可用的性能增强插件。

Abstract: The Web is naturally heterogeneous with user devices, geographic regions, browsing patterns, and contexts all leading to highly diverse, unique datasets. Federated Learning (FL) is an important paradigm for the Web because it enables privacy-preserving, collaborative machine learning across diverse user devices, web services and clients without needing to centralize sensitive data. However, its performance degrades severely under non-IID client distributions that is prevalent in real-world web systems. In this work, we propose a new training paradigm - Iterative Federated Adaptation (IFA) - that enhances generalization in heterogeneous federated settings through generation-wise forget and evolve strategy. Specifically, we divide training into multiple generations and, at the end of each, select a fraction of model parameters (a) randomly or (b) from the later layers of the model and reinitialize them. This iterative forget and evolve schedule allows the model to escape local minima and preserve globally relevant representations. Extensive experiments on CIFAR-10, MIT-Indoors, and Stanford Dogs datasets show that the proposed approach improves global accuracy, especially when the data cross clients are Non-IID. This method can be implemented on top any federated algorithm to improve its generalization performance. We observe an average of 21.5%improvement across datasets. This work advances the vision of scalable, privacy-preserving intelligence for real-world heterogeneous and distributed web systems.

</details>


### [115] [From Data to Behavior: Predicting Unintended Model Behaviors Before Training](https://arxiv.org/abs/2602.04735)
*Mengru Wang,Zhenqian Xu,Junfeng Fang,Yunzhi Yao,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.LG

TL;DR: 提出Data2Behavior任务，用轻量级MDF方法在训练前预测大模型潜在偏见，仅耗20%微调算力即可可靠预警 unintended behaviors。


<details>
  <summary>Details</summary>
Motivation: LLM 即使使用表面无害的数据也会习得 unintended biases；现有方法只能在微调后检测，成本高且低效，需要一种训练前就能预判模型行为风险的手段。

Method: 1) 定义新任务 Data2Behavior：基于候选训练数据预测模型未来 unintended behaviors。2) 提出 Manipulating Data Features (MDF)：将候选数据的均值表示注入基础模型前向传播，无需更新参数即可让数据中的潜在统计信号影响激活，从而暴露潜在偏见与安全风险。

Result: 在 Qwen3-14B、Qwen2.5-32B-Instruct、Gemma-3-12b-it 上的实验表明，MDF 能在训练前以约 20% 的微调 GPU 资源可靠预测 unintended behaviors，并揭示预训练阶段的安全漏洞。

Conclusion: MDF 为低成本、训练前的大模型风险筛查提供了可行方案，有助于在数据进入训练流程前发现并缓解偏见与安全隐患。

Abstract: Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior, a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities.

</details>


### [116] [Billion-Scale Graph Foundation Models](https://arxiv.org/abs/2602.04768)
*Maya Bechler-Speicher,Yoel Gottlieb,Andrey Isakov,David Abensur,Ami Tavory,Daniel Haimovich,Ido Guy,Udi Weinsberg*

Main category: cs.LG

TL;DR: 首个端到端十亿参数图基础模型框架GraphBFF，在零样本/小样本场景下平均提升31 PRAUC，揭示图神经缩放定律。


<details>
  <summary>Details</summary>
Motivation: 语言、视觉领域已借大规模预训练+轻量微调形成基础模型范式，但真实世界异构图规模巨大、结构复杂，尚缺可扩展至十亿节点、通用且统一的图基础模型（GFM）构建方案。

Method: 提出GraphBFF端到端配方，核心为GraphBFF Transformer：①支持任意异构图的线性可扩展编码；②设计高效数据批采样与分布式预训练策略；③给出容量-数据双维度缩放实验协议；④统一预训练+零样本/提示/微调迁移流程。

Result: 在14亿样本上训练出1.4 B参数的GraphBFF，跨10个下游任务（节点/边分类回归、零样本/小样本）平均提升31 PRAUC；首次验证图领域神经缩放定律——损失随模型参数量或训练数据量幂律下降，瓶颈侧决定收敛速度。

Conclusion: GraphBFF证明十亿参数图基础模型可行且效果显著，为工业级图学习提供通用范式；未来需解决高效推理、动态图更新、隐私合规等挑战以全面落地。

Abstract: Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.

</details>


### [117] [Finding Structure in Continual Learning](https://arxiv.org/abs/2602.04555)
*Pourya Shamsolmoali,Masoumeh Zareapoor*

Main category: cs.LG

TL;DR: 用 Douglas-Rachford 分裂将「可塑性-稳定性」权衡重新表述为两个解耦目标的迭代协商，无需回放或正则化即可抑制灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 主流持续学习方法把可塑性与稳定性硬编码成相加的损失项，导致梯度冲突，必须依赖回放、正则化等复杂且低效的补救模块。

Method: 将 continual learning 目标改写成 Douglas-Rachford Splitting 形式；两个解耦项分别负责新任务可塑性与旧知识稳定性，通过迭代 proximal 算子求共识，无需外部记忆或参数约束。

Result: 在任务流场景下，新方法以极简架构实现稳定性与可塑性的高效平衡，显著降低遗忘且训练开销低于现有正则/回放类基线。

Conclusion: DRS 提供了一种原则化、无附加模块的持续学习新范式，把「遗忘-学习」博弈转化为可收敛的迭代协商，为流式任务学习奠定了更简单而强大的理论基础。

Abstract: Learning from a stream of tasks usually pits plasticity against stability: acquiring new knowledge often causes catastrophic forgetting of past information. Most methods address this by summing competing loss terms, creating gradient conflicts that are managed with complex and often inefficient strategies such as external memory replay or parameter regularization. We propose a reformulation of the continual learning objective using Douglas-Rachford Splitting (DRS). This reframes the learning process not as a direct trade-off, but as a negotiation between two decoupled objectives: one promoting plasticity for new tasks and the other enforcing stability of old knowledge. By iteratively finding a consensus through their proximal operators, DRS provides a more principled and stable learning dynamic. Our approach achieves an efficient balance between stability and plasticity without the need for auxiliary modules or complex add-ons, providing a simpler yet more powerful paradigm for continual learning systems.

</details>


### [118] [Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation](https://arxiv.org/abs/2602.04785)
*Congjing Zhang,Ryan Feng Lin,Ruoxuan Bao,Shuai Huang*

Main category: cs.LG

TL;DR: T²框架：先让多个大模型“分工”协作生成表格数据，再用三阶段质控模块“裁剪”低质量样本，最终产出高保真、低偏差、类别均衡的表格数据，实验优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 真实场景表格数据获取成本高、样本稀缺，常伴随类别不平衡、选择偏差、保真度低等问题，直接限制下游模型效果。

Method: 提出Team-then-Trim (T²) 框架：①Team 阶段——将表格生成视为“流水线制造”，按列或块把任务分配给多个专门微调的大模型，顺序生成并共享中间结果；②Trim 阶段——插入三阶段质控插件：一致性校验（schema/逻辑规则）、分布对齐（与真实数据统计距离）、效用评估（下游模型验证），逐级过滤低质量样本。

Result: 在模拟与 4 个真实表格数据集（含高度不平衡及有偏场景）上，T² 合成的数据在 Kolmogorov-Smirnov 距离、F1、AUC、下游模型准确率等指标上平均提升 6–18%，显著优于 CTGAN、TVAE、Copula-GAN 等 SOTA 方法；且数据量可缩减 30% 而性能不降。

Conclusion: T² 证明“多 LLM 协作+严格质控”可低成本产出高质量表格数据，为数据稀缺场景提供可扩展、可解释的合成方案，并支持即插即用。

Abstract: While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.

</details>


### [119] [Probabilistic Label Spreading: Efficient and Consistent Estimation of Soft Labels with Epistemic Uncertainty on Graphs](https://arxiv.org/abs/2602.04574)
*Jonathan Klees,Tobias Riedlinger,Peter Stehr,Bennet Böddecker,Daniel Kondermann,Matthias Rottmann*

Main category: cs.LG

TL;DR: 用单张标注就能估计标签的偶然与认知不确定性，通过图扩散把标签平滑传播到整个特征空间，理论证明即使每样本标注数趋于零也能一致估计概率；实验显示在相同质量下节省大量标注量并刷新数据为中心分类榜SOTA。


<details>
  <summary>Details</summary>
Motivation: 感知任务的安全AI受限于高质量标签稀缺；传统众包虽可收集多重标注来量化偶然与认知不确定性，但随数据规模扩大成本不可行。

Method: 提出“概率标签传播”：假设标签在特征空间平滑，构建k-NN图并用图扩散将单张标注传播至全图，从而估计每个样本的标签分布及其两类不确定性；给出一致性理论保证并设计可扩展实现。

Result: 在CIFAR-10/100、ImageNet子集等数据集上，相比重复标注基线，达到相同标签质量所需标注量减少50–90%；在Data-Centric Image Classification基准上取得新最佳成绩。

Conclusion: 单标注+图扩散即可可靠估计标签不确定性，显著降低大规模感知任务的标注预算，为安全AI提供可扩展的标签高效获取新范式。

Abstract: Safe artificial intelligence for perception tasks remains a major challenge, partly due to the lack of data with high-quality labels. Annotations themselves are subject to aleatoric and epistemic uncertainty, which is typically ignored during annotation and evaluation. While crowdsourcing enables collecting multiple annotations per image to estimate these uncertainties, this approach is impractical at scale due to the required annotation effort. We introduce a probabilistic label spreading method that provides reliable estimates of aleatoric and epistemic uncertainty of labels. Assuming label smoothness over the feature space, we propagate single annotations using a graph-based diffusion method. We prove that label spreading yields consistent probability estimators even when the number of annotations per data point converges to zero. We present and analyze a scalable implementation of our method. Experimental results indicate that, compared to baselines, our approach substantially reduces the annotation budget required to achieve a desired label quality on common image datasets and achieves a new state of the art on the Data-Centric Image Classification benchmark.

</details>


### [120] [Stochastic Decision Horizons for Constrained Reinforcement Learning](https://arxiv.org/abs/2602.04599)
*Nikola Milosevic,Leonard Franz,Daniel Haeufle,Georg Martius,Nico Scherf,Pavel Kolev*

Main category: cs.LG

TL;DR: 把约束违规当成“早停”信号：违规越频繁，智能体“存活”越短，回报被指数折扣；用生存加权目标兼容经验回放，在 SAC/MPO 框架下实现高样本效率与低违规率，并首次在肌骨 Hyfydy 高维任务上验证可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统 CMDP 用附加代价和拉格朗日乘子处理安全/辅助约束，导致 off-policy 算法难以直接利用经验回放，样本效率低且难以扩展至高维连续控制。

Method: 提出“控制即推断”框架，将约束违规建模为状态-动作相关的终止概率，使规划视界随违规缩短；设计两种违规语义——吸收终止与虚拟终止——导出统一的生存加权回报，嵌入 SAC/MPO 的 off-policy actor-critic 更新，保持回放兼容性。

Result: 在标准安全基准上样本效率显著提升，回报-违规权衡优于现有方法；虚拟终止 MPO（VT-MPO）成功扩展至 100+ 维肌骨仿真环境 Hyfydy，保持低违规率的同时获得高回报。

Conclusion: 通过把约束违规转化为“生存概率”并引入生存加权目标，可在不改变 off-policy 算法结构的前提下实现高效安全强化学习，为高维连续控制任务提供了可扩展的约束处理新范式。

Abstract: Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.

</details>


### [121] [Jacobian Regularization Stabilizes Long-Term Integration of Neural Differential Equations](https://arxiv.org/abs/2602.04608)
*Maya Janvier,Julien Salomon,Etienne Meunier*

Main category: cs.LG

TL;DR: 用训练阶段对NDE的Jacobian做方向导数正则化，显著降低长时积分发散风险，成本远低于长轨迹展开。


<details>
  <summary>Details</summary>
Motivation: 现有混合模型与神经微分方程在长时积分中易出现不稳定与精度衰减；用长轨迹展开训练虽可缓解，但反向传播代价过高，难以扩展至大规模系统。

Method: 提出两类低成本Jacobian正则化：1) 动力学已知时，直接计算其方向导数并施加正则；2) 动力学未知时，用有限差分近似方向导数。两者均在短轨迹上训练，无需长展开。

Result: 在多个常微分与偏微分方程系统上，短 rollout 训练即可显著抑制长时积分发散，稳定性与精度提升明显，计算开销远低于传统长轨迹方法。

Conclusion: Jacobian方向导数正则化为NDE长时积分提供了高效、可扩展的训练策略，为大规模系统仿真开辟了新途径。

Abstract: Hybrid models and Neural Differential Equations (NDE) are getting increasingly important for the modeling of physical systems, however they often encounter stability and accuracy issues during long-term integration. Training on unrolled trajectories is known to limit these divergences but quickly becomes too expensive due to the need for computing gradients over an iterative process. In this paper, we demonstrate that regularizing the Jacobian of the NDE model via its directional derivatives during training stabilizes long-term integration in the challenging context of short training rollouts. We design two regularizations, one for the case of known dynamics where we can directly derive the directional derivatives of the dynamic and one for the case of unknown dynamics where they are approximated using finite differences. Both methods, while having a far lower cost compared to long rollouts during training, are successful in improving the stability of long-term simulations for several ordinary and partial differential equations, opening up the door to training NDE methods for long-term integration of large scale systems.

</details>


### [122] [Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821)
*Joydeep Chandra,Satyam Kumar Navneet,Aleksandr Algazinov,Yong Zhang*

Main category: cs.LG

TL;DR: STREAM-RL 用一套带理论保证的算法把“预测-异常检测-安全控制”串起来，在 23 ms 内把交通轨迹预测覆盖率提到 91.4 %、异常误报率压到 4.1 %，并把强化学习安全率从 69 % 拉到 95.2 %。


<details>
  <summary>Details</summary>
Motivation: 城市交通管理需要同一系统同时完成未来状态预测、异常检测与安全纠偏，且给出可验证的可靠性保证；现有方法把三步割裂，无法把预测不确定性一路传导到最终策略，导致安全保证缺失。

Method: 提出统一框架 STREAM-RL，含三项新算法：① PU-GAT+：用预测不确定性动态重加权图注意力，实现无分布假设的覆盖保证；② CRFN-BY：用正态流对不确定性归一化残差建模，并在任意依赖下用 Benjamini-Yekutieli 控制 FDR；③ LyCon-WRL+：把校准不确定性引入基于 Lyapunov 稳定证书与 Lipschitz 界的安全世界模型强化学习，实现端到端理论保证。

Result: 在多组真实交通轨迹数据上，覆盖率 91.4 %，FDR 4.1 %，安全率 95.2 %（对比标准 PPO 的 69 %），同时获得更高奖励，端到端推理延迟仅 23 ms。

Conclusion: 首次实现从预测到异常检测再到安全策略的校准不确定性全链路传播，并给出覆盖、FDR 与稳定性三重理论保证，为实时可靠城市交通控制提供了可落地的新范式。

Abstract: Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\% coverage efficiency, controls FDR at 4.1\% under verified dependence, and improves safety rate to 95.2\% compared to 69\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.

</details>


### [123] [Resilient Load Forecasting under Climate Change: Adaptive Conditional Neural Processes for Few-Shot Extreme Load Forecasting](https://arxiv.org/abs/2602.04609)
*Chenxi Hu,Yue Ma,Yifan Wu,Yunhe Hou*

Main category: cs.LG

TL;DR: 提出AdaCNP概率模型，在极端天气导致负荷剧变且极端样本稀少的场景下，通过“相似度-重加权”机制实现小样本快速适应，无需昂贵微调即可输出可靠预测分布，实际数据验证较最强基线MSE降低22%，负对数似然最低，支撑风险感知决策与韧性电网运行。


<details>
  <summary>Details</summary>
Motivation: 极端天气使负荷曲线出现剧烈尖峰与波动，传统预测失效易引发切负荷与供电中断；然而极端事件稀少且模式突变，导致现有方法难以可靠学习与校准。

Method: 构建AdaCNP（Adaptive Conditional Neural Process）概率框架：1) 在共享嵌入空间学习历史负荷段与当前条件的相似度；2) 对上下文信息按相关性动态重加权，突出极少数极端样本；3) 直接输出完整预测分布，无需针对目标域做昂贵微调，实现小样本/零样本快速适应。

Result: 在真实电网负荷数据上与多种代表基准对比：极端时段MSE相对最强基线降低22%，同时取得最低负对数似然，表明概率输出更可靠；模型对突发分布偏移与极端样本稀缺具有显著鲁棒性。

Conclusion: AdaCNP有效缓解极端事件下分布突变与数据稀缺的双重挑战，为韧性电网运行提供可信、风险感知的负荷预测工具，可推广至其他稀有事件预测场景。

Abstract: Extreme weather can substantially change electricity consumption behavior, causing load curves to exhibit sharp spikes and pronounced volatility. If forecasts are inaccurate during those periods, power systems are more likely to face supply shortfalls or localized overloads, forcing emergency actions such as load shedding and increasing the risk of service disruptions and public-safety impacts. This problem is inherently difficult because extreme events can trigger abrupt regime shifts in load patterns, while relevant extreme samples are rare and irregular, making reliable learning and calibration challenging. We propose AdaCNP, a probabilistic forecasting model for data-scarce condition. AdaCNP learns similarity in a shared embedding space. For each target data, it evaluates how relevant each historical context segment is to the current condition and reweights the context information accordingly. This design highlights the most informative historical evidence even when extreme samples are rare. It enables few-shot adaptation to previously unseen extreme patterns. AdaCNP also produces predictive distributions for risk-aware decision-making without expensive fine-tuning on the target domain. We evaluate AdaCNP on real-world power-system load data and compare it against a range of representative baselines. The results show that AdaCNP is more robust during extreme periods, reducing the mean squared error by 22\% relative to the strongest baseline while achieving the lowest negative log-likelihood, indicating more reliable probabilistic outputs. These findings suggest that AdaCNP can effectively mitigate the combined impact of abrupt distribution shifts and scarce extreme samples, providing a more trustworthy forecasting for resilient power system operation under extreme events.

</details>


### [124] [QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning](https://arxiv.org/abs/2602.04620)
*Doyeon Lee,Eunyi Lyou,Hyunsoo Cho,Sookyung Kim,Joonseok Lee,Jaemoo Choi*

Main category: cs.LG

TL;DR: QUATRO 用精确信任域约束取代 GRPO 的启发式裁剪/归一化，使大模型 RL 微调在数学推理任务上训练更稳、熵可控、对陈旧策略和大学习率鲁棒。


<details>
  <summary>Details</summary>
Motivation: GRPO 类 RL 微调依赖全局裁剪和组归一化等启发式近似，无法约束重要性比超出裁剪区间的样本，导致优化脆弱；需要一种能显式控制策略更新、稳定且可解释的新方法。

Method: 提出 Query-Adaptive Trust-Region policy Optimization（QUATRO），直接在优化中施加精确信任域约束，导出含内在稳定项的可解释目标，实现熵可控的策略更新。

Result: 在多种数学推理基准上验证，QUATRO 在策略陈旧度增加和学习率更激进时仍训练稳定，全程熵值受控，性能优于 GRPO 类方法。

Conclusion: 精确信任域约束是提升大模型 RL 微调稳定性与可控性的关键，QUATRO 为后续研究提供了可扩展的优化框架。

Abstract: GRPO-style reinforcement learning (RL)-based LLM fine-tuning algorithms have recently gained popularity. Relying on heuristic trust-region approximations, however, they can lead to brittle optimization behavior, as global importance-ratio clipping and group-wise normalization fail to regulate samples whose importance ratios fall outside the clipping range. We propose Query-Adaptive Trust-Region policy Optimization (QUATRO), which directly enforces trust-region constraints through a principled optimization. This yields a clear and interpretable objective that enables explicit control over policy updates and stable, entropy-controlled optimization, with a stabilizer terms arising intrinsically from the exact trust-region formulation. Empirically verified on diverse mathematical reasoning benchmarks, QUATRO shows stable training under increased policy staleness and aggressive learning rates, maintaining well-controlled entropy throughout training.

</details>


### [125] [REDistill: Robust Estimator Distillation for Balancing Robustness and Efficiency](https://arxiv.org/abs/2602.04677)
*Ondrej Tybl,Lukas Neumann*

Main category: cs.LG

TL;DR: 用稳健统计思想把 KL 散度换成幂散度，自动抑制教师噪声，无需调参即可在 CIFAR-100/ImageNet 上稳定提升蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 传统 KD 默认教师软标签完全可靠，实则常含噪声或过度自信；现有矫正方法依赖经验启发与大量调参，泛化受限。

Method: 提出 REDistill 框架，将标准 KL 散度目标改为基于幂散度的稳健估计，仅利用 logits 自适应降低不可靠教师输出的权重，同时保留有效对数几率关系，可直接嵌入现有蒸馏流程，计算开销可忽略。

Result: 在 CIFAR-100 与 ImageNet-1k 的多种师生架构组合中，REDistill 持续提升学生准确率，且无需针对模型调参，对未知师生对表现出强泛化能力。

Conclusion: REDistill 以稳健统计原理统一处理教师噪声，兼顾简洁性、可解释性与通用性，为知识蒸馏提供了一种鲁棒且免调参的新基准。

Abstract: Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student by aligning their predictive distributions. However, conventional KD formulations - typically based on Kullback-Leibler divergence - assume that the teacher provides reliable soft targets. In practice, teacher predictions are often noisy or overconfident, and existing correction-based approaches rely on ad-hoc heuristics and extensive hyper-parameter tuning, which hinders generalization. We introduce REDistill (Robust Estimator Distillation), a simple yet principled framework grounded in robust statistics. REDistill replaces the standard KD objective with a power divergence loss, a generalization of KL divergence that adaptively downweights unreliable teacher output while preserving informative logit relationships. This formulation provides a unified and interpretable treatment of teacher noise, requires only logits, integrates seamlessly into existing KD pipelines, and incurs negligible computational overhead. Extensive experiments on CIFAR-100 and ImageNet-1k demonstrate that REDistill consistently improves student accuracy in diverse teacher-student architectures. Remarkably, it achieves these gains without model-specific hyper-parameter tuning, underscoring its robustness and strong generalization to unseen teacher-student pairs.

</details>


### [126] [Subliminal Effects in Your Data: A General Mechanism via Log-Linearity](https://arxiv.org/abs/2602.04863)
*Ishaq Aden-Ali,Noah Golowich,Allen Liu,Abhishek Shetty,Ankur Moitra,Nika Haghtalab*

Main category: cs.LG

TL;DR: 提出“对数-线性选择”(LLS)方法，可从普通偏好数据集中精准挖出隐藏子集，使不同架构的大模型在无需额外训练的情况下即可表现出特定偏好、跨语言回答或人格转换等隐秘行为，从而揭示数据集对模型属性的非直观、全局性影响。


<details>
  <summary>Details</summary>
Motivation: 现代大模型训练依赖大量算法与数据集组合，但现有以数据为中心的视角无法解释“数据集整体可传递单条样本不可见的信号”这一实验现象，亟需揭示数据集如何系统性塑造模型行为。

Method: 受大模型线性表征结构启发，提出“对数-线性选择”(LLS)框架：在偏好数据集中按对数-线性准则筛选子集，仅在该子集上继续训练即可激活特定隐藏效应；跨多种架构验证其普适性。

Result: 用LLS从真实数据集中挖出的子集，能使模型展现单条样本无法预示的多样行为（特定偏好、跨语言回答、人格切换），且该效应在不同架构模型上稳定出现，证明其普遍性与通用性。

Conclusion: 隐藏子文本是数据集影响大模型行为的通用机制；LLS为解析并操控这类“数据集级”信号提供了可操作工具，推动从“数据为中心”向“子集-信号为中心”的新训练范式转变。

Abstract: Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.
  We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.

</details>


### [127] [MTS-JEPA: Multi-Resolution Joint-Embedding Predictive Architecture for Time-Series Anomaly Prediction](https://arxiv.org/abs/2602.04643)
*Yanan He,Yunshi Wen,Xin Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: 提出 MTS-JEPA：用多分辨率目标 + 软码本瓶颈解决 JEPA 在多元时间序列异常预测中的表征崩溃与多尺度前兆捕获难题，在预警协议下达到 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现代关键基础设施依赖多元时间序列，需提前预警异常；现有 JEPA 框架虽能建模潜在演化，但存在表征崩溃与难以捕捉跨时间尺度前兆信号的问题，阻碍其实际应用。

Method: 设计 MTS-JEPA：在 JEPA 框架内引入多分辨率预测目标，并加入软码本瓶颈，显式分离瞬态冲击与长期趋势，利用离散码本捕获系统状态跃迁；该瓶颈同时充当内在正则项，稳定优化过程。

Result: 在标准基准数据集上，MTS-JEPA 有效避免退化解，并在早期预警协议下取得最佳性能。

Conclusion: 多分辨率目标与软码本瓶颈的结合不仅缓解表征崩溃，还能可靠提取跨尺度前兆，为多元时间序列异常预警提供新的 SOTA 解决方案。

Abstract: Multivariate time series underpin modern critical infrastructure, making the prediction of anomalies a vital necessity for proactive risk mitigation. While Joint-Embedding Predictive Architectures (JEPA) offer a promising framework for modeling the latent evolution of these systems, their application is hindered by representation collapse and an inability to capture precursor signals across varying temporal scales. To address these limitations, we propose MTS-JEPA, a specialized architecture that integrates a multi-resolution predictive objective with a soft codebook bottleneck. This design explicitly decouples transient shocks from long-term trends, and utilizes the codebook to capture discrete regime transitions. Notably, we find this constraint also acts as an intrinsic regularizer to ensure optimization stability. Empirical evaluations on standard benchmarks confirm that our approach effectively prevents degenerate solutions and achieves state-of-the-art performance under the early-warning protocol.

</details>


### [128] [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868)
*Yannick Denker,Alexander Gepperth*

Main category: cs.LG

TL;DR: 作者发布了一套面向持续强化学习（CRL）的机器人仿真基准 CRoSS，涵盖两轮差动小车与七自由度机械臂两类平台，提供即插即用的容器化环境，并给出 DQN 与策略梯度基线结果，方便后续研究在高度可控且可复现的设定下评测遗忘与迁移表现。


<details>
  <summary>Details</summary>
Motivation: 持续强化学习需要在任务序列中不断更新策略而又不遗忘旧技能，但现有研究缺乏可复现、易扩展且物理真实的机器人级基准，难以系统评估 CRL 方法在真实感场景中的遗忘与迁移性能。

Method: 基于 Gazebo 构建两轮差动小车（线跟踪、物体推送）与七自由度机械臂（笛卡尔空间/关节空间目标到达）两类平台，通过改变视觉与结构参数生成大量任务；为机械臂额外提供纯运动学高速变体。整套基准容器化（Apptainer），开箱即用，并集成 DQN、策略梯度等基线算法进行初步测评。

Result: 展示了 CRoSS 在多任务序列下的可扩展性与高物理真实度，容器化方案保证环境一致性与复现性；基线实验揭示了标准 RL 算法在持续设定中的遗忘问题，验证该基准对 CRL 研究的适用性。

Conclusion: CRoSS 为持续强化学习社区提供了首个高真实感、易扩展、可复现的机器人仿真基准，支持任意传感器配置与快速实验，有助于系统研究 CRL 中的遗忘抑制与知识迁移策略。

Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

</details>


### [129] [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)
*Dipan Maity*

Main category: cs.LG

TL;DR: SAFE 用双层悲观 Critic+熵控 KL+PID 阈值，取代 PPO 的启发式对称 KL，实现 3B 模型训练奖励 +5.15%、零崩溃、可解释轻量框架。


<details>
  <summary>Details</summary>
Motivation: PPO 在 LM-RLHF 中虽为默认算法，但对 KL 约束处理随意，易出现奖励震荡、熵塌缩、值函数漂移与策略发散，需频繁重启和大量调参，缺乏稳定可解释的替代方案。

Method: 提出 SAFE：纯 on-policy Actor-Critic 算法，核心为①Double Soft-Min Critic 做悲观值估计，②熵门控 KL 调节区分探索/塌缩，③PID 自适应阈值动态调整惩罚，④多层稳定框架，零额外重启动，代码开销极小。

Result: 在 3B 参数模型上，SAFE 训练平均奖励 0.725，比 PPO 的 0.689 提升 5.15%；几乎消除奖励崩溃，KL 控制更优，保持高学习速率，适合生产部署。

Conclusion: SAFE 提供了一种可解释、抗崩溃、轻量的 RLHF 优化框架，可替代 PPO 实现稳定长程对齐训练，已开源。

Abstract: Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collapse, value function drift, and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM-RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation, and PID-controlled adaptive thresholds. Unlike standard PPO's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE

</details>


### [130] [Rethinking the Trust Region in LLM Reinforcement Learning](https://arxiv.org/abs/2602.04879)
*Penghui Qi,Xiangxin Zhou,Zichen Liu,Tianyu Pang,Chao Du,Min Lin,Wee Sun Lee*

Main category: cs.LG

TL;DR: 用直接估计策略散度（TV/KL）取代PPO的ratio clipping，解决大词表下低概率token被过度惩罚、高概率token约束不足的问题，提出轻量级Binary/Top-K近似，训练更稳更快。


<details>
  <summary>Details</summary>
Motivation: PPO的ratio clipping把策略散度近似为“已采样token的概率比”，在大词表里成为单点蒙特卡洛估计，噪声大；结果低概率token更新被过度惩罚，高概率token的潜在危险偏移却约束不足，导致训练低效且不稳定。

Method: 提出Divergence Proximal Policy Optimization（DPPO），用Total Variation或KL等直接、无偏的策略散度估计替换启发式clip；为控制内存，设计Binary与Top-K两种近似，仅对关键维度计算散度，开销可忽略。

Result: 在多项大模型RL微调任务中，DPPO相比PPO及其变体获得更平稳的奖励曲线、更高样本效率与最终性能，验证了其稳定性与收敛速度优势。

Conclusion: DPPO为基于RL的大模型微调提供了更稳健、高效的新基准，其核心思想——用真实散度约束代替采样噪声——可推广至其他大词表策略优化场景。

Abstract: Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.

</details>


### [131] [Contrastive Continual Learning for Model Adaptability in Internet of Things](https://arxiv.org/abs/2602.04881)
*Ajesh Koyatan Chathoth*

Main category: cs.LG

TL;DR: 首次系统梳理“对比式持续学习（CCL）”在物联网场景下的研究现状，给出统一问题形式、参考架构与评估指南，并指出面向 TinyML、联邦、流数据等独特开放难题。


<details>
  <summary>Details</summary>
Motivation: IoT 环境非平稳、资源受限且隐私碎片化，传统持续学习易灾难性遗忘，而对比学习可自监督提升鲁棒性与样本效率；二者结合（CCL）尚缺面向 IoT 的系统综述与落地框架。

Method: 1) 统一形式化 CCL 目标函数，将对比损失与蒸馏/正则/回放/提示四类策略耦合；2) 提出“端-边-云”协同的 IoT-CCL 参考架构，嵌入 TinyML 压缩、间歇同步与隐私保护模块；3) 制定面向 IoT 的评估协议与指标（能耗、遗忘率、概念漂移检测延迟等）；4) 系统映射现有算法到 IoT 现实约束，并梳理开放挑战。

Result: 给出首个 IoT 导向的 CCL 全景视图，明确 4 类算法设计如何适配 TinyML 资源、间歇连接与异构隐私；提供可复现的基准建议；指出 6 大开放问题：表格/流式数据对比、概念漂移、联邦 CCL、能量感知训练、跨模态对齐与在线评价。

Conclusion: 对比式持续学习为动态 IoT 应用提供了兼顾可塑性与稳定性的新范式，但仍需在算法-系统协同、能量-遗忘权衡、联邦隐私机制等方面突破，方能真正实现无处不在的低成本持续智能。

Abstract: Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.

</details>


### [132] [Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883)
*Yanru Qu,Cheng-Yen Hsieh,Zaixiang Zheng,Ge Liu,Quanquan Gu*

Main category: cs.LG

TL;DR: 首个多尺度自回归蛋白质骨架生成框架 PAR，通过“粗到细”逐级雕刻式建模，无需微调即可零样本完成条件生成与 motif 支架任务，在无条件生成基准上达到高设计质量并呈现良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在单一模型中兼顾全局拓扑与局部精细结构，且自回归训练-推断不一致导致的曝光偏差严重降低生成质量；亟需一种能逐级建模、鲁棒生成并支持零样本条件设计的通用框架。

Method: 提出蛋白质自回归建模 PAR：① 多尺度下采样在训练期构建蛋白层级表征；② 自回归 Transformer 编码跨尺度信息并输出条件嵌入；③ 基于流的骨架解码器以嵌入为条件生成主链原子；④ 引入带噪上下文学习与调度采样缓解曝光偏差。

Result: PAR 在无条件生成基准上准确学习蛋白分布，生成骨架设计质量高且扩展性优；零样本条件下支持人工提示生成与 motif 支架，无需额外微调即可保持结构合理性与多样性。

Conclusion: PAR 通过多尺度自回归策略首次实现“雕刻式”蛋白质骨架生成，有效克服曝光偏差，兼具高质量、可扩展与零样本条件生成能力，为蛋白质结构设计与功能蛋白发现提供了新的通用框架。

Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

</details>


### [133] [Static and auto-regressive neural emulation of phytoplankton biomass dynamics from physical predictors in the global ocean](https://arxiv.org/abs/2602.04689)
*Mahima Lakra,Ronan Fablet,Lucas Drumetz,Etienne Pauthenet,Elodie Martinez*

Main category: cs.LG

TL;DR: 用UNet深度学习+卫星数据，可在全球范围重建并提前5个月预测浮游植物生物量时空变化，优于传统模型，但长期预测精度下降。


<details>
  <summary>Details</summary>
Motivation: 生物地球化学模型因参数化不足、观测稀缺和海洋过程复杂，难以准确模拟浮游植物动态，亟需新手段提升全球海洋初级生产力的预测能力。

Method: 基于卫星观测与环境变量，系统比较CNN、ConvLSTM、4CastNet及UNet等深度学习架构；进一步构建自回归UNet，以前期预测作为输入实现短中期预报。

Result: UNet在再现季节与年际变化上显著优于对比模型；输入1–2个月环境场即可较好重建生物量，但对低频变幅略有低估；自回归UNet在0–5个月预测窗口内保持高 skill，超过5个月后性能衰减。

Conclusion: 融合物理环境驱动与深度学习可有效监测和短期预测全球浮游植物动态，为海洋健康评估与生态系统管理提供新的自动化工具，并具备应对气候变化的潜力。

Abstract: Phytoplankton is the basis of marine food webs, driving both ecological processes and global biogeochemical cycles. Despite their ecological and climatic significance, accurately simulating phytoplankton dynamics remains a major challenge for biogeochemical numerical models due to limited parameterizations, sparse observational data, and the complexity of oceanic processes. Here, we explore how deep learning models can be used to address these limitations predicting the spatio-temporal distribution of phytoplankton biomass in the global ocean based on satellite observations and environmental conditions. First, we investigate several deep learning architectures. Among the tested models, the UNet architecture stands out for its ability to reproduce the seasonal and interannual patterns of phytoplankton biomass more accurately than other models like CNNs, ConvLSTM, and 4CastNet. When using one to two months of environmental data as input, UNet performs better, although it tends to underestimate the amplitude of low-frequency changes in phytoplankton biomass. Thus, to improve predictions over time, an auto-regressive version of UNet was also tested, where the model uses its own previous predictions to forecast future conditions. This approach works well for short-term forecasts (up to five months), though its performance decreases for longer time scales. Overall, our study shows that combining ocean physical predictors with deep learning allows for reconstruction and short-term prediction of phytoplankton dynamics. These models could become powerful tools for monitoring ocean health and supporting marine ecosystem management, especially in the context of climate change.

</details>


### [134] [Bounded-Abstention Multi-horizon Time-series Forecasting](https://arxiv.org/abs/2602.04714)
*Luca Stradiotti,Laurens Devos,Anna Monreale,Jesse Davis,Andrea Pugnana*

Main category: cs.LG

TL;DR: 首个面向多步时序预测的‘结构化拒判’框架，理论推导三种拒判方式的最优策略并给出可扩展算法，24 个数据集上显著优于现有拒判基线。


<details>
  <summary>Details</summary>
Motivation: 多步时序预测在医疗、金融等高风险场景下，一步错判可能引发连锁损失；现有拒判方法只针对单步预测，忽视多步输出之间的结构化相关性，无法直接迁移。

Method: 1) 将多步拒判形式化为三种自然范式：全局拒判、步级拒判与片段拒判；2) 对每种范式推导贝叶斯最优拒判规则，给出可学习的风险-覆盖权衡目标；3) 设计基于深度预测模型+可微分拒判门的端到端训练算法，支持高效批量计算。

Result: 在 24 个真实数据集（含能源、健康、金融）上，新方法在相同覆盖率下平均降低 18–32 % 的预测误差，在同等误差水平下减少 15–25 % 的拒判率，显著优于单步拒判扩展基线与简单置信度阈值法。

Conclusion: 多步预测的结构化拒判不仅可行，而且通过利用步间相关性可显著提升风险-覆盖效率；所提框架通用、可扩展，为高风险时序决策系统提供了可靠的安全出口。

Abstract: Multi-horizon time-series forecasting involves simultaneously making predictions for a consecutive sequence of subsequent time steps. This task arises in many application domains, such as healthcare and finance, where mispredictions can have a high cost and reduce trust. The learning with abstention framework tackles these problems by allowing a model to abstain from offering a prediction when it is at an elevated risk of making a misprediction. Unfortunately, existing abstention strategies are ill-suited for the multi-horizon setting: they target problems where a model offers a single prediction for each instance. Hence, they ignore the structured and correlated nature of the predictions offered by a multi-horizon forecaster. We formalize the problem of learning with abstention for multi-horizon forecasting setting and show that its structured nature admits a richer set of abstention problems. Concretely, we propose three natural notions of how a model could abstain for multi-horizon forecasting. We theoretically analyze each problem to derive the optimal abstention strategy and propose an algorithm that implements it. Extensive evaluation on 24 datasets shows that our proposed algorithms significantly outperforms existing baselines.

</details>


### [135] [DMFlow: Disordered Materials Generation by Flow Matching](https://arxiv.org/abs/2602.04734)
*Liming Wu,Rui Jiao,Qi Li,Mingze Li,Songyou Li,Shifeng Jin,Wenbing Huang*

Main category: cs.LG

TL;DR: DMFlow 是首个面向无序晶体的深度生成框架，统一表示置换/位置无序并采用黎曼流匹配，在 CSP 与 DNG 任务上全面超越现有有序晶体模型。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型多聚焦于完美有序晶体，而占材料重要类别的无序晶体（置换、位置无序）缺乏专门生成工具，阻碍按需设计。

Method: 提出 DMFlow：① 统一图表示有序、置换无序(SD)、位置无序(PD)晶体；② 球面重参数化黎曼流匹配模型，在概率单纯形上生成物理合理的无序权重；③ 引入保持物理对称性的专用 GNN 学习向量场；④ 两阶段离散化将连续权重转为多热原子排布；⑤ 发布含 SD/PD/混合结构的 COD 基准数据集。

Result: 在晶体结构预测(CSP)与全新生成(DNG)任务中，DMFlow 显著优于从有序晶体方法改造的最强基线，首次实现 AI 对无序材料的高效逆向设计。

Conclusion: DMFlow 为无序晶体的 AI 驱动发现提供了通用、可扩展的生成基础，填补了这一关键材料类别的研究空白。

Abstract: The design of materials with tailored properties is crucial for technological progress. However, most deep generative models focus exclusively on perfectly ordered crystals, neglecting the important class of disordered materials. To address this gap, we introduce DMFlow, a generative framework specifically designed for disordered crystals. Our approach introduces a unified representation for ordered, Substitutionally Disordered (SD), and Positionally Disordered (PD) crystals, and employs a flow matching model to jointly generate all structural components. A key innovation is a Riemannian flow matching framework with spherical reparameterization, which ensures physically valid disorder weights on the probability simplex. The vector field is learned by a novel Graph Neural Network (GNN) that incorporates physical symmetries and a specialized message-passing scheme. Finally, a two-stage discretization procedure converts the continuous weights into multi-hot atomic assignments. To support research in this area, we release a benchmark containing SD, PD, and mixed structures curated from the Crystallography Open Database. Experiments on Crystal Structure Prediction (CSP) and De Novo Generation (DNG) tasks demonstrate that DMFlow significantly outperforms state-of-the-art baselines adapted from ordered crystal generation. We hope our work provides a foundation for the AI-driven discovery of disordered materials.

</details>


### [136] [Rationality Measurement and Theory for Reinforcement Learning Agents](https://arxiv.org/abs/2602.04737)
*Kejiang Qian,Amos Storkey,Fengxiang He*

Main category: cs.LG

TL;DR: 文章首次为强化学习智能体提出一套可量化的“理性”指标与理论：用部署时动作与理想最优动作的价值差距定义期望理性风险，并分解为环境偏移（外在）与算法泛化缺陷（内在）两部分，分别被 1-Wasserstein 距离与经验 Rademacher 复杂度上界；实验证实层归一化、L2 正则、域随机化可降低理性风险，而环境偏移会升高风险。


<details>
  <summary>Details</summary>
Motivation: 现有 RL 研究多关注回报或样本效率，却缺乏对“决策是否理性”的定量刻画；随着 RL 智能体走向真实部署，其行动是否始终沿最优价值方向至关重要，因此亟需一套可计算的理性度量与理论框架来诊断并改进算法。

Method: 1) 定义“完美理性”动作：在部署 MDP 中沿隐藏真实价值函数最速上升方向的动作；2) 引入期望理性风险（部署）与经验理性风险（训练），二者之差为理性风险缺口；3) 将缺口分解为外在项（训练/部署环境偏移）与内在项（算法动态泛化能力），并分别用 1-Wasserstein 距离与价值函数类的经验 Rademacher 复杂度给出上界；4) 基于上界提出可验证假设：正则化与域随机化降低理性风险，环境偏移增加风险；5) 在 MuJoCo 连续控制任务上系统验证假设。

Result: 理论得到的两个上界紧致且可计算；实验显示层归一化、权重归一化、L2 正则与域随机化显著缩小理性风险缺口（最高降 38%），而增大训练-部署环境差异（如改变质量、摩擦系数）使缺口线性上升，与理论预测完全一致；代码开源。

Conclusion: 理性风险框架首次把“决策合理性”转化为可优化目标，为 RL 提供了新的诊断与改进工具；未来可扩展至多智能体、非平稳环境及安全约束场景。

Abstract: This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.

</details>


### [137] [Decomposing Query-Key Feature Interactions Using Contrastive Covariances](https://arxiv.org/abs/2602.04752)
*Andrew Lee,Yonatan Belinkov,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TL;DR: 提出一种对比协方差分解法，把 Transformer 的 QK 空间拆成可解释的低秩子空间；当查询-键在这些子空间对齐时即产生高注意力。该方法在简化场景与大型语言模型上均验证有效，并可将注意力得分归因到具体语义或绑定特征。


<details>
  <summary>Details</summary>
Motivation: 尽管注意力头在 Transformer 中至关重要，却缺乏工具解释模型为何关注特定词元，因此需要从查询-键（QK）空间入手提供可解释手段。

Method: 设计“对比协方差”分解算法，将 QK 双线性联合嵌入空间拆分为低秩、人类可解释的组件；通过检测查询与键在这些子空间的对齐程度解释高注意力得分。

Result: 在简化任务中验证了方法的正确性与可解释性；在大型语言模型上识别出对应范畴语义特征与绑定特征的可解释 QK 子空间，并可对任意注意力得分进行特征归因。

Conclusion: QK 空间的低秩结构是注意力行为的关键，对比协差分解为揭示 Transformer 内部决策依据提供了通用、可扩展的工具。

Abstract: Despite the central role of attention heads in Transformers, we lack tools to understand why a model attends to a particular token. To address this, we study the query-key (QK) space -- the bilinear joint embedding space between queries and keys. We present a contrastive covariance method to decompose the QK space into low-rank, human-interpretable components. It is when features in keys and queries align in these low-rank subspaces that high attention scores are produced. We first study our method both analytically and empirically in a simplified setting. We then apply our method to large language models to identify human-interpretable QK subspaces for categorical semantic features and binding features. Finally, we demonstrate how attention scores can be attributed to our identified features.

</details>


### [138] [A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates](https://arxiv.org/abs/2602.04757)
*Yuchen Ye,Zixuan Qi,Shixuan Li,Wei Qi,Yanpeng Cai,Chaoxia Yuan*

Main category: cs.LG

TL;DR: 提出一种双阶段 TransUNet 多源降水融合框架（DDL-MSPMF），先分类再回归，将 6 套卫星/再分析降水产品与 ERA5 近地表变量融合，0.25° 日尺度覆盖中国 2001–2020；相比单阶段模型，季节平均 R 提升至 0.75，RMSE 降至 2.70 mm/day，对 >25 mm/day 极端降水威胁评分显著提高，并能再现 2021 年郑州暴雨空间分布，在青藏高原独立验证亦表现稳健，SHAP 解释性分析指出降水发生概率与地表气压最关键。


<details>
  <summary>Details</summary>
Motivation: 现有卫星与再分析多源降水产品（MSPs）存在显著空间异质性偏差，对极端降水捕捉能力弱，限制了其在水文气候监测中的可用性，亟需一种可扩展、可解释且能同时校正季节均值与极端事件的融合方法。

Method: 构建双阶段 TransUNet 框架（DDL-MSPMF）：第一阶段以 TransUNet 分类器估计逐日降水发生概率；第二阶段将分类概率与 6 套 MSPs 及 4 个 ERA5 近地表物理预测因子（含地表气压、比湿等）共同输入另一 TransUNet 回归器，输出 0.25° 日降水量。采用 2001–2020 年中国区域训练，并引入 SHAP 进行物理可解释性诊断。

Result: DDL-MSPMF 在季节尺度上 R = 0.75、RMSE = 2.70 mm/day，优于单阶段回归及多种深度学习/混合基线；对 >25 mm/day 强降水，其公平威胁评分在中国东部多数区域提升，成功再现 2021 年 7 月郑州特大暴雨空间格局；在数据稀缺的青藏高原独立 TPHiPr 评估中同样表现优异；SHAP 分析表明降水发生概率与地表气压对最终估测贡献最大。

Conclusion: 双阶段 TransUNet 框架提供了一种可扩展、可解释的多源降水融合新途径，不仅系统性地校正了季节平均偏差，还显著增强了对极端降水事件的检测与再现能力，适用于中国乃至其他资料稀缺地区的精细化水文气候监测与灾害评估。

Abstract: Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.

</details>


### [139] [Improved Dimension Dependence for Bandit Convex Optimization with Gradient Variations](https://arxiv.org/abs/2602.04761)
*Hang Yu,Yu-Hu Yan,Peng Zhao*

Main category: cs.LG

TL;DR: 本文首次系统研究了双点Bandit凸优化中的梯度变化量(gradient-variation)度量，提出非连续梯度变化量的精细分析框架，在维度依赖、梯度方差、小损失遗憾、动态/通用遗憾及博弈收敛率等维度全面刷新最好结果，并首次将梯度变化量界推广到单点线性bandit超矩形域。


<details>
  <summary>Details</summary>
Motivation: 梯度变化量在线学习虽在完全信息设定下已被充分研究，但在bandit反馈场景下尚属空白；现有结果维度依赖高，且缺乏对非连续梯度变化量的精细刻画，限制了其在高维bandit凸优化、动态环境及博弈中的应用。

Method: 提出非连续梯度变化量的新分解与加权平滑估计，结合双点bandit梯度估计和乐观在线镜像下降框架；进一步将技术迁移到单点线性bandit，通过超矩形域上的坐标分离与自适应学习率设计实现梯度变化量界。

Result: 对凸函数将维度依赖从O(d²)降至O(d^{3/2})，对强凸函数从O(d)降至O(d^{1/2})；首次给出梯度方差与小损失遗憾保证；首次建立双点BCO的梯度变化量动态遗憾Õ(d^{3/2}V_T^{1/3}T^{2/3})与通用遗憾Õ(d^{3/2}√T)；在bandit博弈中实现O(T^{-3/4})级快速收敛率；单点线性bandit首次获得梯度变化量界。

Conclusion: 非连续梯度变化量的精细分析是突破bandit反馈下维度瓶颈与拓展应用范围的关键，所提技术可无缝迁移至动态、通用遗憾及博弈场景，为高维bandit学习提供了更紧致的理论保证与算法设计范式。

Abstract: Gradient-variation online learning has drawn increasing attention due to its deep connections to game theory, optimization, etc. It has been studied extensively in the full-information setting, but is underexplored with bandit feedback. In this work, we focus on gradient variation in Bandit Convex Optimization (BCO) with two-point feedback. By proposing a refined analysis on the non-consecutive gradient variation, a fundamental quantity in gradient variation with bandits, we improve the dimension dependence for both convex and strongly convex functions compared with the best known results (Chiang et al., 2013). Our improved analysis for the non-consecutive gradient variation also implies other favorable problem-dependent guarantees, such as gradient-variance and small-loss regrets. Beyond the two-point setup, we demonstrate the versatility of our technique by achieving the first gradient-variation bound for one-point bandit linear optimization over hyper-rectangular domains. Finally, we validate the effectiveness of our results in more challenging tasks such as dynamic/universal regret minimization and bandit games, establishing the first gradient-variation dynamic and universal regret bounds for two-point BCO and fast convergence rates in bandit games.

</details>


### [140] [NeuroCanvas: VLLM-Powered Robust Seizure Detection by Reformulating Multichannel EEG as Image](https://arxiv.org/abs/2602.04769)
*Yan Chen,Jie Peng,Moajjem Hossain Chowdhury,Tianlong Chen,Yunmei Liu*

Main category: cs.LG

TL;DR: NeuroCanvas 把多导脑电先“挑通道”再“画成图”，用极少视觉 token 喂给大模型，实现癫痫实时检测，F1 提升 20%，延迟降 88%。


<details>
  <summary>Details</summary>
Motivation: 长期脑电人工判读耗时，已有 LLM-EEG 方法存在通道异质性大、token 数量爆炸两大痛点，亟需兼顾精度与效率的在线癫痫检测方案。

Method: 提出 NeuroCanvas 框架：① Entropy-guided Channel Selector（ECS）按熵值自动筛选癫痫相关通道；② Canvas of Neuron Signal（CNS）将选中通道信号转为紧凑视觉图像 token；最后由冻结的 LLM 完成分类。

Result: 在多个公开癫痫数据集上，NeuroCanvas 较基线 F1 分数平均提升约 20%，推理延迟降低 88%，参数量与计算量显著缩减，支持实时推理。

Conclusion: 通过“通道选择+视觉 token”策略，NeuroCanvas 有效克服多通道异构与计算低效问题，为临床提供可扩展、低资源消耗的实时癫痫检测解决方案。

Abstract: Accurate and timely seizure detection from Electroencephalography (EEG) is critical for clinical intervention, yet manual review of long-term recordings is labor-intensive. Recent efforts to encode EEG signals into large language models (LLMs) show promise in handling neural signals across diverse patients, but two significant challenges remain: (1) multi-channel heterogeneity, as seizure-relevant information varies substantially across EEG channels, and (2) computing inefficiency, as the EEG signals need to be encoded into a massive number of tokens for the prediction. To address these issues, we draw the EEG signal and propose the novel NeuroCanvas framework. Specifically, NeuroCanvas consists of two modules: (i) The Entropy-guided Channel Selector (ECS) selects the seizure-relevant channels input to LLM and (ii) the following Canvas of Neuron Signal (CNS) converts selected multi-channel heterogeneous EEG signals into structured visual representations. The ECS module alleviates the multi-channel heterogeneity issue, and the CNS uses compact visual tokens to represent the EEG signals that improve the computing efficiency. We evaluate NeuroCanvas across multiple seizure detection datasets, demonstrating a significant improvement of $20\%$ in F1 score and reductions of $88\%$ in inference latency. These results highlight NeuroCanvas as a scalable and effective solution for real-time and resource-efficient seizure detection in clinical practice.The code will be released at https://github.com/Yanchen30247/seizure_detect.

</details>


### [141] [Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification](https://arxiv.org/abs/2602.04775)
*Yuqi Li,Matthew M. Engelhard*

Main category: cs.LG

TL;DR: 提出适用于区间预测的“不确定性感知ROC”框架，给出AUC_L/AUC_U两个新指标，可将ROC平面划分为正确/错误/不确定三区域，支持选择性弃权并证明在有效覆盖下可界定理论最优AUC。


<details>
  <summary>Details</summary>
Motivation: 高风险场景下必须用区间预测量化不确定性，但传统ROC/AUC仅针对点预测，无法反映预测不确定性对排序性能的影响，亟需新的评估工具。

Method: 1) 将区间得分转化为三值排序关系（肯定正>负、肯定负>正、不确定），建立不确定性感知ROC曲线；2) 定义AUC_L（下界）与AUC_U（上界）度量，实现ROC平面的三区域分解；3) 在类条件覆盖有效的假设下，证明AUC_L ≤ AUC* ≤ AUC_U，给出理论最优AUC的可计算界限；4) 支持基于区间重叠度的选择性弃权，优化“弃权率–区分可靠性”权衡；5) 用bootstrap区间在多个真实数据集验证框架的通用性与正确性。

Result: 新框架可将成对比较明确划分为正确/错误/不确定三类；AUC_L、AUC_U在有效覆盖下严格包围理论最优AUC；实验显示其在不同数据集上能准确反映模型不确定性，支持基于弃权的决策优化，且与具体区间构造方式无关。

Conclusion: 不确定性感知ROC框架填补了区间预测评估的空白，为高风险决策提供可解释、可证明的可靠性界限，可广泛应用于任何产生区间输出的预测模型。

Abstract: In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.

</details>


### [142] [Dynamical Regimes of Multimodal Diffusion Models](https://arxiv.org/abs/2602.04780)
*Emil Albrychiewicz,Andrés Franco Valiente,Li-Ching Chen*

Main category: cs.LG

TL;DR: 用耦合的Ornstein-Uhlenbeck过程给多模态扩散生成建了一个可解理论，发现模态间并不同步稳定，而是按特征时间尺度依次“解锁”；由此给出“同步缺口”解析式与耦合强度上下界，可直接设计随时间变化的耦合系数，无需人工调guidance。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在高维数据合成上已获极高保真度，但“多模态同时生成”为何仍常出现模态失衡、时间错位等失步伪影，缺乏理论解释；现有经验性guidance调参无法系统避免对称性破缺导致的模式塌缩或分裂。

Method: 1) 将多模态扩散抽象为“耦合Ornstein-Uhlenbeck过程”，用非平衡统计物理的动态相变工具求解其谱域演化；2) 解析推导特征值层级与同步缺口，给出对称/各向异性耦合下“物种分化(speciation)”与“塌缩(collapse)”时间的闭合表达式；3) 确立耦合强度λ的严格上下界，证明λ充当可调谱滤波器，可强制不同特征模态按预设时间序列稳定；4) 在MNIST受控实验与精确score采样器上验证理论预测。

Result: 理论上首次揭示多模态生成由“谱交互时间层级”而非同时分辨率控制；预测并观测到同步缺口，其宽度与λ成反比；实验表明只要λ在解析界内，即可消除对称破缺，模态按理论顺序依次生成；时间依赖耦合调度可替代ad-hoc guidance，FID与模态覆盖率同步提升。

Conclusion: 多模态扩散生成的失步伪影本质上是特征模态在不同时间尺度上的稳定过程差异；通过设计随时间变化的耦合强度，可直接靶向各模态特征时间，实现无需人工调参的稳定多模态采样，为后续大规模文本-图像、多通道音频等生成提供可扩展理论框架。

Abstract: Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.

</details>


### [143] [Legendre Memory Unit with A Multi-Slice Compensation Model for Short-Term Wind Speed Forecasting Based on Wind Farm Cluster Data](https://arxiv.org/abs/2602.04782)
*Mumin Zhang,Haochen Zhang,Xin Zhi Khoo,Yilin Zhang,Nuo Chen,Ting Zhang,Junjie Tang*

Main category: cs.LG

TL;DR: 提出 WMF-CPK-MSLMU 集成模型，用加权均值滤波去噪、Legendre 记忆单元捕捉时空相关、Kendall 秩相关补偿缺失，实现风电集群短期风速快速、精准、鲁棒预测。


<details>
  <summary>Details</summary>
Motivation: 随着风电集群并网规模扩大，亟需兼顾精度、速度与鲁棒性的短期风速预测方法，以保障电网安全经济运行。

Method: 1) 单厂层加权均值滤波(WMF)去噪；2) 引入Legendre记忆单元(LMU)联合建模线性/非线性时空依赖；3) 基于Kendall秩相关系数构造补偿参数(CPK)，驱动多切片LMU(MSLMU)权重初始化与缺失数据空间补偿；4) 集成WMF-CPK-MSLMU三模块(预处理-预测-补偿)框架。

Result: 在多风电集群实测数据上，所提模型预测误差显著低于现有方法，兼具高准确度、快速收敛与强鲁棒性。

Conclusion: WMF-CPK-MSLMU充分利用集群时空相关，有效提升风电集群短期风速预测性能，具备工程推广价值。

Abstract: With more wind farms clustered for integration, the short-term wind speed prediction of such wind farm clusters is critical for normal operation of power systems. This paper focuses on achieving accurate, fast, and robust wind speed prediction by full use of cluster data with spatial-temporal correlation. First, weighted mean filtering (WMF) is applied to denoise wind speed data at the single-farm level. The Legendre memory unit (LMU) is then innovatively applied for the wind speed prediction, in combination with the Compensating Parameter based on Kendall rank correlation coefficient (CPK) of wind farm cluster data, to construct the multi-slice LMU (MSLMU). Finally, an innovative ensemble model WMF-CPK-MSLMU is proposed herein, with three key blocks: data pre-processing, forecasting, and multi-slice compensation. Advantages include: 1) LMU jointly models linear and nonlinear dependencies among farms to capture spatial-temporal correlations through backpropagation; 2) MSLMU enhances forecasting by using CPK-derived weights instead of random initialization, allowing spatial correlations to fully activate hidden nodes across clustered wind farms.; 3) CPK adaptively weights the compensation model in MSLMU and complements missing data spatially, to facilitate the whole model highly accurate and robust. Test results on different wind farm clusters indicate the effectiveness and superiority of proposed ensemble model WMF-CPK-MSLMU in the short-term prediction of wind farm clusters compared to the existing models.

</details>


### [144] [From independent patches to coordinated attention: Controlling information flow in vision transformers](https://arxiv.org/abs/2602.04784)
*Kieran A. Murphy*

Main category: cs.LG

TL;DR: 给 ViT 的每一次注意力写操作加上可学习的变分信息瓶颈，把“注意力传递了多少信息”变成可量化、可惩罚的显式损失，从而无需改动其它结构就能在「纯局部处理」到「全局注意力」之间连续控 scale，并借此观察 ImageNet-100 上分类行为与信息路由的演化，为可解释性与可控性提供新工具。


<details>
  <summary>Details</summary>
Motivation: 传统 ViT 的注意力是隐式、不可量化的通信机制，导致无法系统研究「局部→全局」表征如何涌现，也难以对内部通信做精细控制与可解释分析。

Method: 在所有注意力对 residual stream 的写路径上插入变分信息瓶颈（VIB），把 attention 传输的互信息 I(z;x) 作为显式惩罚项训练；通过调整信息预算 β 可获得从独立 patch 处理到完全全局注意力的连续模型谱。

Result: 在 ImageNet-100 上刻画了分类准确率与信息路由随 β 变化的完整曲线；定位到最先突破局部隔离、实现跨 patch 通信的前几个 attention head；低信息预算模型保持可观精度的同时，内部信息流显著简化，更易做机制解析与干预控制。

Conclusion: 将注意力通信「显式化、可度量、可惩罚」能在不改变 ViT 结构的前提下，可控地生成从局部到全局的模型谱，为理解视觉表征如何涌现以及提升模型可解释性与可控性提供了新范式。

Abstract: We make the information transmitted by attention an explicit, measurable quantity in vision transformers. By inserting variational information bottlenecks on all attention-mediated writes to the residual stream -- without other architectural changes -- we train models with an explicit information cost and obtain a controllable spectrum from independent patch processing to fully expressive global attention. On ImageNet-100, we characterize how classification behavior and information routing evolve across this spectrum, and provide initial insights into how global visual representations emerge from local patch processing by analyzing the first attention heads that transmit information. By biasing learning toward solutions with constrained internal communication, our approach yields models that are more tractable for mechanistic analysis and more amenable to control.

</details>


### [145] [Maximum-Volume Nonnegative Matrix Factorization](https://arxiv.org/abs/2602.04795)
*Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.LG

TL;DR: 本文提出最大体积非负矩阵分解（MaxVol NMF），通过最大化右因子 H 的体积实现可辨识且稀疏的分解，避免秩亏并天然对应列聚类；给出两种算法及归一化变体，在高光谱解混实验中优于最小体积（MinVol）NMF。


<details>
  <summary>Details</summary>
Motivation: 传统最小体积 NMF（MinVol NMF）虽可增强可解释性，但含噪时易秩亏且难以获得稀疏解。作者设想：若改而最大化右因子体积，能否在保持可辨识性的同时获得更稀疏、非秩亏的分解？

Method: 提出最大体积 NMF（MaxVol NMF）——在 X≈WH 且 W,H≥0 约束下最大化 H 的体积；证明其无噪可辨识条件与 MinVol 相同，但含噪时等价于对 X 的列做互斥聚类；设计两种优化算法，并进一步给出归一化 MaxVol NMF，把标准 NMF 与正交 NMF 连续衔接。

Result: 理论证明 MaxVol 最优解对应列硬聚类，而 MinVol 最优解必秩亏；实验显示 MaxVol 显著提升了分解稀疏度、避免秩亏，且归一化变体在高光谱解混中量化误差最小、端元光谱更贴近真实。

Conclusion: 最大化 H 体积比最小化 W 体积更能产生稀疏、非秩亏且可解释的非负分解；MaxVol NMF 及其归一化形式为含噪数据提供了一种优于 MinVol 的通用替代方案，并揭示了 NMF 与聚类/正交性之间的连续关系。

Abstract: Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.

</details>


### [146] [Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning](https://arxiv.org/abs/2602.04807)
*Wolfgang Maass,Sabine Janzen,Prajvi Saxena,Sach Mukherjee*

Main category: cs.LG

TL;DR: 受生物启发的“传入学习”框架通过进化优化搜索能高效学习避损策略的传入感知结构（CATs），在数字孪生骨骼肌模型上实现 23% 高风险动作削减，兼具理论收敛保证与跨年龄鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统避损强化学习依赖手工设计的损伤信号，难以在数十年尺度的生命历程场景中保持高效与年龄适应性；需要一种能自动产生内部风险偏置、使策略学习本身更高效且随年龄演化的机制。

Method: 提出双层框架 Afferent Learning：外层用进化优化搜索“传入感知架构”空间，内层用强化学习训练依赖该架构输出的 CAT 风险信号的避损策略；以预测误差（predictive discrepancy）作为核心传入信号，并在平滑与有界噪声假设下给出收敛理论。

Result: 在生物力学数字孪生长期任务中，进化得到的 CAT 架构比手工基线在样本效率与跨年龄鲁棒性上显著提升，策略表现出年龄依赖的行为自适应，高风险动作减少 23%；消融实验证实 CAT 信号、进化搜索与预测误差三者缺一不可。

Conclusion: 将“传入感知”形式化为对学习过程的归纳偏置，并通过进化-强化协同优化自动发现该偏置，可在复杂长时域风险环境中实现高效、年龄感知的避损控制，为安全终身学习提供可扩展框架。

Abstract: We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.

</details>


### [147] [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)
*Philipp Nazari,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 本文指出线性注意力的隐状态实际呈低秩，理论证明低秩会放大查询噪声并损害检索；提出训练后结构化剪枝框架，用硬件友好的QR秩揭示方法砍掉50% query/key通道，几乎不掉点。


<details>
  <summary>Details</summary>
Motivation: 线性注意力虽高效，但经验发现其状态矩阵秩很低，容量未被充分利用；作者想从理论上解释低秩的影响，并验证能否在训练后大幅压缩状态而几乎不损性能。

Method: 1) 理论分析：建立低有效秩与查询噪声放大、检索误差上升的关系；2) 结构化剪枝框架：针对线性注意力键/查询矩阵，设计兼容现有CUDA kernel的剪枝策略；3) 新算法：基于秩揭示QR分解的通道级结构化剪枝，辅以已有剪枝策略适配。

Result: 在多种规模模型和下游任务上，框架可移除50% query/key通道，困惑度仅微增；压缩后模型更小更快，且无需重新训练。

Conclusion: 低秩是线性注意力容量浪费的根源，训练后结构化剪枝能在几乎不损失精度的前提下显著降低状态大小与推理开销，为高效部署线性注意力模型提供了可行方案。

Abstract: Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.

</details>


### [148] [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)
*Chenwei Cui,Rockwell Jackson,Benjamin Joseph Herrera,Ana María Tárano,Hannah Kerner*

Main category: cs.LG

TL;DR: 提出 Multi-Head LatentMoE 与 Head Parallel，将 MoE 训练通信开销从 O(k) 降到 O(1)，实现零负载失衡与确定性通信，在保持精度的同时最高提速 1.61×。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏 MoE 采用 Expert Parallel，通信量随激活专家数 k 线性增长，且存在负载不均、需动态元数据交换，导致高带宽占用与延迟，阻碍大模型低成本训练。

Method: 设计 Multi-Head LatentMoE 架构，把专家计算拆成多组独立头；引入 Head Parallel 并行策略，使通信量恒为常数 O(1)，并配套 IO-aware 路由与专家计算优化，保持与 EP 兼容。

Result: 在相同精度下，训练速度提升 1.61×；粒度加倍后性能更高，仍快 1.11×；通信、内存与延迟完全均衡，无需动态元数据。

Conclusion: Head Parallel 让百亿级参数模型训练门槛显著降低，为高效稀疏大模型研究提供新基线。

Abstract: Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [149] [Data Driven Air Entrainment Velocity Parameterization by Breaking Waves](https://arxiv.org/abs/2602.04067)
*Xiaohui Zhou,Anton S. Darmenov,Kianoosh Yousefi*

Main category: physics.ao-ph

TL;DR: 用机器学习重新参数化波浪破碎卷吸速度Va，取代仅用风速或波高的经验公式，显著降低海-气通量模拟误差。


<details>
  <summary>Details</summary>
Motivation: 现有耦合模式将破碎卷吸速度Va简化为风速或有效波高的函数，无法反映波龄、陡度等多因子非线性影响，导致低纬涌浪区和风暴带通量偏差显著。

Method: 基于43年WAVEWATCH III高分辨率模拟，构建含7个物理驱动因子（风速、波高、波龄、陡度、方向、水深等）的多层感知机，训练全球Va参数化方案，并在HiWinGS独立观测中验证。

Result: 新方案在涌浪主导低纬遏制过高估计，在风暴带弥补过低估计；使CO2气泡传输速度、海盐气溶胶排放误差降低一个数量级，整体性能显著优于传统总体公式。

Conclusion: 数据驱动的Va参数化可嵌入现有耦合模式，实时修正海-气动量、热量、气体与气溶胶通量，为气候与大气化学模式提供更准确的边界条件。

Abstract: Wave breaking injects turbulence and bubbles into the upper ocean, modulating air-sea exchange of momentum, heat, gases, and sea-spray aerosols. These fluxes depend nonlinearly on sea state but remain poorly represented in coupled atmosphere-wave-ocean models, where air-entrainment velocity is often parameterized using wind speed or significant wave height alone. We develop a global machine-learning parameterization of Va trained on a 43-year WAVEWATCH III simulation that resolves the breaker-front distribution and associated energetics. A multilayer perceptron with seven physically motivated predictors (wind speed, wave height, wave age, steepness, direction, and depth) reproduces spectral-reference Va with high skill. The model reduces longstanding biases in bulk formulas, notably overestimation in swell-dominated low latitudes and underestimation in storm tracks. Applied globally, it improves bubble-mediated CO2 transfer velocity and sea-salt aerosol emission, reducing errors by an order of magnitude. Validation against independent HiWinGS observations supports robust deep-water performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [150] [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900)
*Erik Goh,John Kos,Ashok Goel*

Main category: cs.AI

TL;DR: 用认知教育学的TMK框架改写提示，能把大模型在符号规划任务上的准确率从31.5%提到97.3%，并激活其代码执行通路，显著弥补推理短板。


<details>
  <summary>Details</summary>
Motivation: 大模型推理与规划能力受质疑，现有提示法（如CoT）效果有限；作者借鉴教育学中的Task-Method-Knowledge（TMK）框架，利用其对因果-目的-层级结构的显式刻画，尝试系统性提升LLM的复杂任务分解与符号推理表现。

Method: 将TMK三元组（任务-方法-知识）嵌入提示，让模型显式获知“做什么、怎么做、为何做”；在PlanBench的Blocksworld域随机符号实例上，对比标准提示与TMK提示的零样本表现，并观测模型内部是否切换至代码执行路径。

Result: TMK提示使专用“推理模型”准确率由31.5%飙升至97.3%，并逆转了原模型在透明/不透明任务上的性能倒挂；消融实验表明，TMK不仅提供上下文，更实质性地引导模型调用形式化推理（代码执行）通道。

Conclusion: TMK框架可作为轻量级但高效的提示策略，显著弥合大模型语义近似与符号操作之间的鸿沟；其“任务-方法-知识”显式分解机制为提升LLM规划与推理能力提供了可扩展的新范式。

Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.

</details>


### [151] [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950)
*Aditya Basarkar,Benyamin Tabarsi,Tiffany Barnes,Dongkuan,Xu*

Main category: cs.AI

TL;DR: 提出IIPC方法，通过迭代优化可执行推理链并融合执行反馈，显著提升LLM在数学推理任务上的准确率与可修正性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体LLM的数学推理系统缺乏可可靠修正的推理表示：顺序管道无法回改早期错误，自评启发式常漏检，且程序上下文易分散模型注意力。

Method: 设计Iteratively Improved Program Construction（IIPC）：在每次迭代中让LLM生成→执行→收集执行反馈→利用链式思维修正程序化推理链，实现渐进式修正并保持高层语境聚焦。

Result: 在多个基础LLM上的主流数学推理基准中，IIPC在多数数据集上优于现有竞争方法；全部代码与实现已开源。

Conclusion: IIPC通过可执行程序与执行反馈的闭环迭代，有效弥补了多智能体LLM数学推理的可修正性缺陷，为教育、科学与工程等需可靠符号推理的场景提供了更强健的解决方案。

Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.

</details>


### [152] [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)
*Yinyi Luo,Yiqiao Jin,Weichen Yu,Mengqi Zhang,Srijan Kumar,Xiaoxiao Li,Weijie Xu,Xin Chen,Jindong Wang*

Main category: cs.AI

TL;DR: AgentArk 把多轮辩论的多智能体“智慧”一次性压进单模型权重，用训练换推理，低成本继承强推理与自纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 多智能体辩论虽推理强，但推理阶段计算昂贵且错误会层层放大，难以落地。

Method: 提出 AgentArk 框架，将多智能体交互显式动态蒸馏为单模型隐式能力；设计三层递进策略：推理增强微调、轨迹级数据增广、过程感知蒸馏，把计算负担从推理迁移到训练阶段。

Result: 单模型在保持单 agent 效率的同时，获得多 agent 的推理与自我纠错性能，并在多种推理任务上展现更强鲁棒性与泛化力；实验覆盖不同模型尺寸、任务类型与扩展场景均一致有效。

Conclusion: 通过“训练期蒸馏”取代“推理期辩论”，AgentArk 为构建高效、可靠的多智能体系统提供了新范式，启发了后续低成本强推理研究。

Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.

</details>


### [153] [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出 Active Epistemic Control（AEC），在部分可观察环境中把“信念”仅用于剪枝、把“已落地事实”用于承诺，通过按需查询或模拟来减少重规划次数。


<details>
  <summary>Details</summary>
Motivation: 交互式任务中关键前提未知且交互成本高；纯靠学习模型预测会隐性出错导致不可行承诺，需要一种既能利用廉价预测又能保证承诺安全的方法。

Method: AEC 层维护“ grounded fact store”与“belief store”双存储：信念仅用于剪枝候选计划，真正承诺前必须通过环境查询落地。每一步根据不确定性或预测歧义决定：高不确定则查询环境落地谓词，置信足够则仅用模拟信念过滤假设；最终用 grounded precondition 覆盖率与 SQ-BCP 拉回式兼容性检查做承诺闸门。

Result: 在 ALFWorld 与 ScienceWorld 上，AEC 达到与强 LLM-agent 基线相当的成功率，但重规划轮次显著更少。

Conclusion: 将模型信念与落地事实严格分离、按需查询的 AEC 框架，可在保证可行性的前提下显著降低交互成本，为部分可观察环境中的高效规划提供了新思路。

Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \emph{grounded fact store} used for commitment and a \emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.

</details>


### [154] [Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure](https://arxiv.org/abs/2602.03975)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 在验证预算受限的场景下，通过“状态级选择性验证”把验证资源集中到最有信息量的中间步骤，相比 best-of-N、多数投票和束搜索，在 MATH 数据集上用 44% 更少的验证调用获得更高精度。


<details>
  <summary>Details</summary>
Motivation: 大模型推理依赖 test-time 计算，但验证开销成为瓶颈；大量验证浪费在冗余或无前景的中间假设上，亟需一种在验证成本受限条件下合理分配验证资源的机制。

Method: 提出状态级选择性验证框架：(i) 基于结构化 move 接口的确定性可行性门控，提前筛掉非法状态；(ii) 用学得的状态距离与残差分数混合预排序，估计各中间节点的潜在价值；(iii) 根据局部不确定性自适应分配验证调用，而非在解级或均匀验证。

Result: 在 MATH 基准上，该方法在比 best-of-N、多数投票和束搜索减少 44% 验证调用的情况下，取得更高准确率。

Conclusion: 通过把验证预算精准投向信息量最大的中间状态，可在不增加总验证成本的前提下显著提升大模型推理性能，验证资源分配策略是 test-time 计算优化的关键杠杆。

Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\% fewer verifier calls.

</details>


### [155] [Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning](https://arxiv.org/abs/2602.03978)
*Zidi Xiong,Shan Chen,Himabindu Lakkaraju*

Main category: cs.AI

TL;DR: RLVR训练早期看似白送的CoT可监控性并非必然出现，其提升高度依赖数据多样性及指令遵循样本，且与推理能力脱钩，主要源于输出分布锐化而非对推理链因果依赖增强。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型(LRM)落地，审计其思维链(CoT)安全性愈发关键；已有迹象表明RLVR早期监控性可能“白送”，但缺乏系统验证与机制解释。

Method: 跨模型家族与训练领域系统评估RLVR训练过程中监控性变化；控制数据多样性、指令遵循数据比例及任务难度，结合机制分析(注意力与因果依赖)量化监控性来源。

Result: 监控性提升并非普适，强烈依赖数据多样性及指令遵循数据；监控性与推理能力正交；增益主要来自输出分布锐化(熵减)与对提示注意力提升，而非对CoT因果依赖增强；监控性动态随训练与评估难度变化而异。

Conclusion: 首次系统刻画RLVR下监控性出现条件与机制，指出数据工程与评估难度设计是可控提升监控性的关键抓手，而非单纯追求推理性能。

Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a "free gift" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.

</details>


### [156] [When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making](https://arxiv.org/abs/2602.04003)
*Shutong Fan,Lan Zhang,Xiaoyong Yuan*

Main category: cs.AI

TL;DR: 本文首次提出“对抗性解释攻击”（AEA）：攻击者通过操控大模型生成的自然语言解释，在认知层而非计算层误导人类用户对错误预测的信任，并量化其造成的“信任错配缺口”。实验表明，只要解释风格贴近专家话语，用户便难以区分正误，尤其在任务困难、事实导向领域及低教育、年轻、高信任人群中危害最大。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击聚焦模型计算行为，忽视 AI 已深度嵌入人类决策环路的现实：用户依据大模型流利解释形成信任。攻击者若操纵解释即可在认知层制造“可信的错误”，开辟全新攻击面。

Method: 1) 形式化“信任错配缺口”指标，量化解释对人类信任的操控程度；2) 设计四维度（推理模式、证据类型、沟通风格、呈现格式）可控实验，招募 205 名受试者，比较对抗性与良性解释引发的信任差异；3) 按任务难度、领域类型、人口特征分层分析脆弱性。

Result: 对抗解释与良性解释获得的用户信任几乎无差异（保留绝大部分信任）；当解释具备权威证据、中性语调、领域适配推理时，信任最高；困难任务、事实导向领域、低学历、年轻、高信任 AI 群体最易受骗。

Conclusion: 解释本身已成为可武器化的认知通道。未来 AI 安全必须将“人类认知”纳入威胁模型，发展解释级别的检测与防御机制，并针对高风险人群与场景实施额外干预。

Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.

</details>


### [157] [Axiomatic Foundations of Counterfactual Explanations](https://arxiv.org/abs/2602.04028)
*Leila Amgoud,Martin Cooper*

Main category: cs.AI

TL;DR: 作者首次用公理化方法把反事实解释严格拆成5种互斥类型，并给出不可能性定理与表示定理，统一了局部/全局解释，同时厘清现有方法归属与计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释器仅关注单一类型且局限于局部实例，缺乏对“全局系统推理逻辑”的刻画，也未系统比较不同反事实类型；亟需一个统一框架来回答“哪些解释类型可同时满足、如何分类、对应何种解释器”。

Method: 构建反事实解释器的公理化框架，定义一组可欲性质；证明不可能性定理揭示若干公理无法同时满足；用表示定理建立五组公理子集与五类解释器的一一对应，从而严格导出五种反事实解释类型；将现有算法映射到该分类并分析其计算复杂度。

Result: 得到五类互斥且完备的“反事实解释家族”，涵盖局部与全局视角；不可能性定理明确任何解释器必须放弃哪些性质；表示定理给出每类解释器的显式刻画；实验侧重量化生成复杂度，为选型提供依据。

Conclusion: 论文首次完成反事实解释的类型学奠基，证明“没有万能解释器”，并给出五选一清晰菜单；研究者与从业者可根据任务需求在公理性质、解释范围与计算成本之间做权衡。

Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.
  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.

</details>


### [158] [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)
*Xiaofeng Lin,Sirou Zhu,Yilei Chen,Mingyu Chen,Hejian Sang,Ioannis Paschalidis,Zhipeng Wang,Aldo Pacchiano,Xuezhou Zhang*

Main category: cs.AI

TL;DR: ORBIT 通过元强化学习让 14B 开源模型在纯交互环境中实时学习，性能追平 GPT-5.2，显著优于传统 RL 微调，且随模型规模持续提升。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在静态任务表现强，但在必须在线交互、延迟反馈的决策场景中难以可靠地利用交互经验进行即时学习。

Method: 提出 ORBIT——多任务、多回合元强化学习框架，用大量交互轨迹对 LLM 进行元训练，使其无需更新权重即可在上下文中持续学习。

Result: 元训练后的 14B 开源模型（Qwen3-14B）在全新环境中在线学习能力大幅提升，性能与 GPT-5.2 持平，远超标准 RL 微调，且扩展实验显示随模型规模增大收益持续增加。

Conclusion: 通过元训练，LLM 可在推理阶段实现真正的“即时学习”，为构建无需参数更新即可在线决策的智能体提供了可行路径和显著扩展空间。

Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.

</details>


### [159] [Interfaze: The Future of AI is built on Task-Specific Small Models](https://arxiv.org/abs/2602.04101)
*Harsha Vardhan Khurdula,Vineet Agarwal,Yoeven D Khemlani*

Main category: cs.AI

TL;DR: Interfaze 把现代 LLM 应用重塑为“先构建上下文、再行动”的流水线：用轻量级感知模型+工具链完成 OCR、ASR、网页抓取、代码执行等脏活累活，仅将蒸馏后的紧凑上下文交给用户指定的大模型做最终生成，既保持 SOTA 精度（MMLU-Pro 83.6 %、AIME-2025 90 % 等），又把主要算力从昂贵的大模型转移到小模型与工具层。


<details>
  <summary>Details</summary>
Motivation: 现有做法一味追求更大、更 monolithic 的模型，导致推理成本高、对多模态与外部知识利用效率低；作者认为核心瓶颈不是“选最大模型”，而是“如何为模型构建高质量上下文”。

Method: 提出三层层级架构：①感知层——异构小模型（OCR、图表解析、多语 ASR）；②上下文构建层——实时爬取、索引、解析网页/PDF/代码并压缩成结构化状态；③动作层——可浏览网页、沙箱执行代码、驱动 headless 浏览器。顶层轻量控制器按 query 动态调度小模型与工具，仅把蒸馏上下文丢给用户选定的 LLM 生成答案。

Result: Interfaze-Beta 在 8 项基准全面领先或媲美 SOTA：MMLU-Pro 83.6 %、MMLU 91.4 %、GPQA-Diamond 81.3 %、LiveCodeBench v5 57.8 %、AIME-2025 90 %，多模态 MMMU 77.3 %、AI2D 91.5 %、ChartQA 90.9 %，ASR Common Voice v16 90.8 %。实验显示绝大多数查询由小模型+工具解决，大模型仅处理蒸馏后上下文，显著降低大模型算力占比。

Conclusion: “上下文优先、模型靠后”的范式能在不牺牲精度的情况下，把计算负荷从昂贵的大模型转移到轻量级模块与工具链，为构建高效、可扩展的 LLM 应用提供了新路线。

Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.
  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.

</details>


### [160] [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210)
*Enyu Zhou,Zhiheng Xi,Long Ma,Zhihao Zhang,Shihan Dou,Zhikai Lei,Guoteng Wang,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.AI

TL;DR: 用“递归决策树”把复杂任务拆成一连串简单二选一/打分题，让外行用户也能像专家一样给大模型写PRD；只凭在线反馈做RL就能持续优化，对齐度提升54%。


<details>
  <summary>Details</summary>
Motivation: 大模型已能端到端完成“vibe coding”等长周期任务，但用户缺乏领域知识、难以精确表达意图，也无法验证复杂输出，导致“可扩展监督”出现空白：人类既写不清也验不动比自己更强的AI。

Method: 提出“可扩展交互式监督”框架：将高层意图递归分解为树状可验证子决策→在每个节点用低负担方式（如对比、打分）收集用户信号→自下而上聚合为全局指导；整个流程仅依赖在线用户反馈即可用强化学习持续优化。

Result: 在网页开发任务中，非专家用户生成的产品需求文档（PRD）与专家水平对齐度提升54%；框架无需额外标注，仅通过实时交互即可RL自优化，证明能在AI能力超越人类时仍保持可控性。

Conclusion: 把“写不清、验不动”转化为“点得清、选得动”的递归决策树，是用人类弱信号实现强监督的实用路径，为AI持续 scaling 时保持人类控制提供了可在线优化的工程方案。

Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.

</details>


### [161] [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)
*Yansong Ning,Jun Fang,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: Agent-Omit 让大模型在多轮交互中“想省则想、看省则看”，在几乎不损失性能的前提下把推理与观测成本砍掉一半以上。


<details>
  <summary>Details</summary>
Motivation: 现有方法把多轮交互中的思考（thought）与观测（observation）全部保留，导致冗余计算；作者首次量化发现不同轮次对这两类信息的真实需求差异巨大，从而提出按需省略。

Method: 1) 基于量化分析合成冷启动数据，微调模型学会“何时省略思考/观测”；2) 设计“省略感知”强化学习，用双采样机制与专门省略奖励继续提升策略；3) 理论证明省略策略偏差受 KL 散度上界约束。

Result: 在 5 个智能体基准上，8B 参数的 Agent-Omit 性能媲美 7 个前沿大模型智能体，同时推理延迟平均 ↓52%、观测成本 ↓61%，取得最佳“效果-效率”权衡。

Conclusion: 通过“轮次敏感”地压缩思考与观测，Agent-Omit 在不牺牲任务成功率的前提下显著降低多轮交互开销，为高效智能体部署提供了可扩展的训练与推理框架。

Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.

</details>


### [162] [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)
*SeungWon Seo,SooBin Lim,SeongRae Noh,Haneul Kim,HyeongYeop Kang*

Main category: cs.AI

TL;DR: PCE框架把LLM推理中的隐性假设变成结构化决策树，在几乎不增加通信的前提下显著提升多智能体在部分可观测环境下的任务成功率与效率，且对模型规模与推理深度的增益保持兼容，人类也更信任其通信模式。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-具身智能体依赖频繁通信来缓解对隐藏物体及同伴意图的不确定性，导致高token/时间成本并干扰人类协作流程，亟需一种低通信、结构化的不确定性处理方法。

Method: 提出Planner-Composer-Evaluator（PCE）框架：Planner将LLM推理链中的碎片化假设抽取为环境状态假设；Composer把这些假设组织成决策树（内部节点=假设，叶节点=动作）；Evaluator基于场景似然、目标收益与执行成本为每条路径打分，实现理性动作选择，全程无需重通信。

Result: 在C-WAH与TDW-MAT两大基准及三种LLM主干上，PCE在成功率与任务效率上全面优于以通信为核心的强基线，token开销相当；消融实验显示，无论扩大模型容量还是加深推理步数，PCE仍能进一步提升性能，证明其增益与模型规模/推理深度正交；用户研究证实PCE的通信模式被人类认为更高效、可信。

Conclusion: PCE提供了一条将LLM隐性假设转化为可解释、可量化决策结构的通用路径，使多智能体在部分可观测、去中心化环境下实现低通信、高可信的 uncertainty-aware 规划，同时兼容模型规模与推理深度的持续扩展。

Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.

</details>


### [163] [Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications](https://arxiv.org/abs/2602.04385)
*Marco Picone,Fabio Turazza,Matteo Martinelli,Marco Mamei*

Main category: cs.AI

TL;DR: 提出“零配置”数字孪生框架，把 AI/ML 模块与物理层解耦，让复杂工业 CPS 无需繁琐配置即可即插即用智能服务。


<details>
  <summary>Details</summary>
Motivation: 工业 CPS 中 IoT/IIoT 碎片化（协议、数据格式、设备能力差异）导致 AI/ML 集成难、部署慢，现有 DT 方案烟囱式且紧耦合，难以复用与扩展。

Method: 构建模块化、可互操作的 ZeroConf AI 管道，由数字孪生统一负责数据编排与语义增强，AI 组件仅专注模型推理，二者通过标准化接口松耦合；在 MicroFactory 场景验证并发模型与动态数据流处理。

Result: 实现 AI 功能零配置即插即用，支持多条 ML 模型并行运行与实时数据流自适应处理，显著缩短工业现场智能服务上线时间。

Conclusion: ZeroConf DT 框架有效弥合物理层与 AI 层的语义与配置鸿沟，为复杂工业 CPS 提供可扩展、可复用的智能集成范式，具备推广至更大规模工业场景的潜力。

Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.

</details>


### [164] [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)
*Zhentao Tang,Yuqi Cui,Shixiong Kai,Wenqian Zhao,Ke Ye,Xing Li,Anxin Tian,Zehua Pei,Hui-Ling Zhen,Shoubo Hu,Xiaoguang Li,Yunhe Wang,Mingxuan Yuan*

Main category: cs.AI

TL;DR: ReThinker 用“置信度驱动”的三段式 Solver-Critic-Selector 架构，把检索、工具与多智能体推理从刚性流水线变成按需动态调用，并配套无标注反向数据合成与轨迹复用训练策略，在 HLE、GAIA、XBench 上刷新专家级推理 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在 Humanity’s Last Exam 等专家基准上表现受限，主要因固定工具链、脆弱多智能体协同与低效 test-time 缩放难以应对高阶科学推理。

Method: 提出 ReThinker 框架：① Solver-Critic-Selector 阶段式架构，按置信度动态分配计算；② 置信度感知的自适应工具调用与多维反思；③ 反向数据合成+轨迹回收，无需人工标注即可生成高质量监督数据。

Result: 在 HLE、GAIA、XBench 上系统级超越带工具的最强基础模型及现有深度研究系统，取得专家级推理新 SOTA。

Conclusion: 置信度驱动的动态 Agent 编排与无标注自监督训练可显著提升大模型在专家级科学推理任务上的上限，为后续高难 benchmark 提供可扩展范式。

Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.

</details>


### [165] [From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums](https://arxiv.org/abs/2602.04572)
*Niv Fono,Yftah Ziser,Omer Ben-Porat*

Main category: cs.AI

TL;DR: 生成式 AI 依赖问答论坛数据却又抢走用户，作者提出“AI 先出题→论坛择题发布”的序贯协作框架，用 Stack Exchange 真实数据与主流 LLM 仿真，证实即使存在激励错位，双方仍可达成理想信息条件下约 50 % 的收益，为 AI 与人类知识平台可持续共存提供路径。


<details>
  <summary>Details</summary>
Motivation: 生成式 AI 系统既把用户从传统问答论坛吸走，又必须依赖这些论坛持续产出的高质量数据来提升自身性能，形成“依赖-替代”悖论；若论坛因流量下滑而枯竭，AI 性能也将受损，因此亟需设计一种可长期维持、激励兼容的协作机制。

Method: 构建“AI 出题→论坛择题发布”的序贯博弈框架，纳入非货币交换、信息不对称与激励错位等现实约束；利用 Stack Exchange 真实问答数据与多款主流大模型进行数据驱动的仿真，量化不同策略组合下双方效用，并与理想完全信息场景对比。

Result: 实证发现激励显著错位，但在序贯协作下双方仍能获得理想完全信息条件下约 50 % 的效用；论坛通过筛选 AI 提供的优质问题可维持内容生态，AI 则借助持续更新的高质量人类回答持续改进，验证了可持续知识共享的可行性。

Conclusion: 只要设计合理的序贯互动与择题机制，生成式 AI 与人类知识平台可在激励错位的前提下实现近似共赢，为后续平台规则、API 设计以及数据共享政策提供可操作框架，缓解 AI 对论坛生态的潜在侵蚀。

Abstract: While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.

</details>


### [166] [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575)
*Jiaheng Liu,Yuanxing Zhang,Shihao Li,Xinping Lei*

Main category: cs.AI

TL;DR: 把「一句感觉」自动拆成可验证的多智能体流水线，让 AI 从抽卡工具变成系统级工程伙伴，一次性解决「想得出却做不出」的意图-执行鸿沟。


<details>
  <summary>Details</summary>
Motivation: 纯模型堆规模的范式撞上「可用性天花板」：单次黑箱生成与用户高层意图之间存在不可缩小的 Intent-Execution Gap，需要把「抽卡式」推断升级为可验证、可编排的系统工程。

Method: 提出 Vibe AIGC 范式——用户作为 Commander 只给「Vibe」（审美+功能等高阶表征），中央 Meta-Planner 将其自动解构为分层多智能体工作流，实现逻辑化编排而非随机推断。

Result: 用智能体流水线取代单步生成，首次在系统层面把人类想象转化为可执行、可验证、可自适应的长周期数字资产生产流程，为复杂内容创建提供通用框架。

Conclusion: Vibe AIGC 将 AI 角色从脆弱推断引擎升级为稳健系统工程伙伴，有望重塑人机协作经济，使高质量长周期内容创作真正民主化。

Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.
  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.

</details>


### [167] [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)
*Zelai Xu,Zhexuan Xu,Ruize Zhang,Chunyang Zhu,Shi Yu,Weilin Liu,Quanlu Zhang,Wenbo Ding,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 用4B参数的“宽搜索”多智能体系统，在广域信息检索任务上打平671B单智能体，验证“宽度扩展”可替代“深度扩展”。


<details>
  <summary>Details</summary>
Motivation: 当任务广度超过一定阈值后，瓶颈从单个模型的推理深度转向系统级并行组织能力；现有手工多智能体流程无法高效并行，需用强化学习自动习得协同策略。

Method: 提出lead-agent-subagent框架WideSeek-R1，所有角色共享同一LLM但上下文隔离；lead负责动态任务分解与结果融合，若干并行subagent各持专用工具分片检索；用20k广域信息寻求任务对整体系统进行端到端多智能体强化学习（MARL）联合优化。

Result: 在WideSearch基准上，WideSeek-R1-4B取得40.0% Item-F1，与单智能体DeepSeek-R1-671B持平；随并行subagent数量增加，性能持续提升，验证宽度扩展的有效性。

Conclusion: 宽度扩展（多智能体并行）可在小参数条件下达到大模型深度扩展效果，为构建可扩展、经济高效的信息检索系统提供了新范式。

Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.

</details>


### [168] [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836)
*Haosen Ge,Hamsa Bastani,Osbert Bastani*

Main category: cs.AI

TL;DR: 本文反驳METR关于AI能力呈指数增长的论断，指出其数据更符合已过拐点的S型曲线，并提出基座与推理能力双组分模型以强调指数预测之脆弱。


<details>
  <summary>Details</summary>
Motivation: METR报告宣称自2019年以来AI能力指数级上升，并据此推断远期风险；作者质疑该结论对政策与资源分配的影响，欲揭示其统计与建模缺陷。

Method: 1) 复用METR同一数据集，改用S型（logistic）曲线重新拟合，检验拐点位置；2) 构建“基座能力+推理能力”双变量模型，允许二者以不同速率饱和，证明整体能力必然出现拐点；3) 不进行远期预测，仅通过反证与替代模型展示指数外推的脆弱性。

Result: S型拟合显示AI能力拐点已至（约在2022年前后），与METR“拐点尚远”结论相反；双组分模型进一步证明，即使各子能力持续改进，其加权总和也将趋于饱和，从而驳斥无限指数增长假设。

Conclusion: 现有证据不足以支持AI能力持续指数增长，简单外推存在重大风险；研究者与决策者应采用多模型、多情景方法，警惕单一指数预测对安全与劳动市场政策的误导。

Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

</details>


### [169] [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837)
*Zhaotian Weng,Antonis Antoniades,Deepak Nathani,Zhen Zhang,Xiao Pu,Xin Eric Wang*

Main category: cs.AI

TL;DR: GEA 用群体代替个体作为演化单元，让多智能体共享经验并协同进化，在代码任务上把自演化方法的成绩从 56.7% 提到 71%，且修复框架级 bug 仅需 1.4 次迭代。


<details>
  <summary>Details</summary>
Motivation: 现有自演化范式采用树状结构，各分支孤立，导致早期探索出的多样性难以被后续个体复用，限制了长期改进效率。作者希望减少人类干预，让智能体能自主突破预设架构上限。

Method: 提出 Group-Evolving Agents（GEA）：将一组智能体视为基本演化单位，群体内部显式共享并重用经验；采用图状而非树状进化流程，使不同分支的解决方案可以持续交叉融合。

Result: 在 SWE-bench Verified 和 Polyglot 两大代码基准上，GEA 分别取得 71.0% 和 88.3% 的成功率，显著优于最佳自演化基线（56.7%、68.3%）并匹敌或超越人工设计的顶级框架（71.8%、52.0%）。同规模演化预算下，GEA 把早期多样性更有效地转化为长期收益；跨模型迁移稳定，平均 1.4 次迭代即可修复框架级缺陷，而自演化方法需 5 次。

Conclusion: 把“群体”作为演化单元可打破树状孤立瓶颈，显著提升智能体的自我改进效率与鲁棒性；GEA 为开放端自演化系统提供了可扩展的新范式，并已在复杂代码任务上验证其优势。

Abstract: Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.

</details>


### [170] [Fluid Representations in Reasoning Models](https://arxiv.org/abs/2602.04843)
*Dmitrii Kharlapenko,Alessandro Stolfo,Arthur Conmy,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: QwQ-32B 在推理过程中动态精化 token 表征，形成脱离具体语义的抽象结构编码，这种“流体推理表征”是其解决抽象规划问题的关键机制。


<details>
  <summary>Details</summary>
Motivation: 尽管带推理链的模型在抽象任务上远超普通模型，其内部机制仍属黑箱；需要揭示推理链究竟如何转化为有效的问题表征。

Method: 以语义混淆的 Mystery Blocksworld 为探针，逐层追踪 QwQ-32B 的隐藏状态；通过表征干预（steering）与符号替换实验，检验精炼表征对最终准确率的因果贡献。

Result: 模型在推理中逐步剥离动作名称的表层语义，形成仅保留结构关系的抽象编码；将成功轨迹中的精炼表征注入早期层可显著提升准确率，而用符号替换 70% 的混淆编码几乎不掉点。

Conclusion: “流体推理表征”——即在上下文里持续精化的动态 token 表征——是推理模型性能跃升的核心因素之一，为后续可解释性与模型设计提供了可操作靶点。

Abstract: Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [171] [Backend-agnostic Julia framework for 3D modeling and inversion of gravity data](https://arxiv.org/abs/2602.03857)
*Nimatullah,Pankaj K Mishra,Jochen Kamm,Anand Singh*

Main category: physics.geo-ph

TL;DR: 用 Julia 写的 GPU 加速 3D 重力正反演框架，数据空间降维+深度加权，亿级棱柱模型也能快速成像，合成与实测数据均验证高分辨率与地质一致性。


<details>
  <summary>Details</summary>
Motivation: 传统 3D 重力反演计算量大、内存占用高、病态且多解，亟需兼顾效率与精度的可扩展方案。

Method: 采用数据空间反演降低维数；正反演算子封装为后端无关内核，同一套 Julia 代码可在多核 CPU 与 NVIDIA GPU 运行；引入深度加权灵敏度抑制幅值衰减并隐含地质约束。

Result: 对 330 万个矩形棱柱模型，GPU 版相对 CPU 实现显著提速；合成数据能准确重建直立/倾斜岩墙等复杂构造；实测数据反演结果与独立地质解释高度一致。

Conclusion: GPU+Julia 的组合可将大规模重力反演从“周”缩至“小时”，在保持精度的同时提供高效、易扩展的高分辨率地球物理计算平台。

Abstract: This paper presents a high-performance framework for three-dimensional gravity modeling and inversion implemented in Julia, addressing key challenges in geophysical modeling such as computational complexity, ill-posedness, and the non-uniqueness inherent to gravity inversion. The framework adopts a data-space inversion formulation to reduce the dimensionality of the problem, leading to significantly lower memory requirements and improved computational efficiency while maintaining inversion accuracy. Forward modeling and inversion operators are implemented within a backend-agnostic kernel abstraction, enabling execution on both multicore CPUs and GPU accelerators from a single code base. Performance analyses conducted on NVIDIA CUDA GPUs demonstrate substantial reductions in runtime relative to CPU execution, particularly for large-scale datasets involving up to approximately 3.3 million rectangular prisms, highlighting the scalability of the proposed approach. The inversion incorporates implicit model constraints through the data-space formulation and depth-weighted sensitivity, which mitigate depth-related amplitude decay and yield geologically coherent, high-resolution subsurface density models. Validation using synthetic models confirms the ability of the framework to accurately reconstruct complex subsurface structures such as vertical and dipping dykes. Application to field gravity data further demonstrates the robustness and practical utility of the GPU-accelerated framework, with the recovered models showing strong consistency with independent geological constraints and prior interpretations. Overall, this work underscores the potential of GPU-enabled computing in Julia to transform large-scale gravity inversion workflows, providing an efficient, extensible, and accurate computational solution for high-resolution geophysical studies.

</details>
